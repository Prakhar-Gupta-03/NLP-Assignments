{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER_TRAIN_JUDGEMENT.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER_TEST_JUDGEMENT.json') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIO Encoding of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CASE_NUMBER', 'PETITIONER', 'JUDGE', 'GPE', 'DATE', 'WITNESS', 'COURT', 'RESPONDENT', 'ORG', 'OTHER_PERSON', 'STATUTE', 'PRECEDENT', 'PROVISION'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for i in range(len(data)):\n",
    "    for annotation in data[i]['annotations'][0]['result']:\n",
    "        label = annotation['value']['labels'][0]\n",
    "        unique_labels.add(label)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data - Replacing escape sequences with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    special_chars = ['\\x05', '\\t', '\\n', '\\x0c', '\\x11', '\\x12', '\\x13', '\\x14', '\\x16', '\\x1a', '\\x80', '\\x9d', '\\xa0', '\\xad', '\\uf076']\n",
    "    for char in special_chars:\n",
    "        text = text.replace(char, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing all the label boundaries in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_index(annotations):\n",
    "    border_indices = []\n",
    "    for annotation in annotations[0]['result']:\n",
    "        start = annotation['value']['start']\n",
    "        end = annotation['value']['end']\n",
    "        label = annotation['value']['labels'][0]\n",
    "        label = label.upper()\n",
    "        border_indices.append([start, end, label])\n",
    "    border_indices.sort(key=lambda x: x[0])\n",
    "    return border_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding spaces on the boundaries of labels where there is no space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_spacing(text, border_indices):\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        for border in border_indices:\n",
    "            if (i==border[0] or i==border[1]):\n",
    "                index = border_indices.index(border)\n",
    "                if (i==border[0] and i!=0 and text[i-1]!=' '):\n",
    "                    text = text[:i] + ' ' + text[i:]\n",
    "                    for j in range(index, len(border_indices)):\n",
    "                        if border_indices[j][0] >= i:\n",
    "                            border_indices[j][0] += 1\n",
    "                        if border_indices[j][1] >= i:\n",
    "                            border_indices[j][1] += 1\n",
    "                if (i==border[1] and i!=len(text)-1 and text[i]!=' '):\n",
    "                    text = text[:i] + ' ' + text[i:]\n",
    "                    for j in range(index, len(border_indices)):\n",
    "                        if border_indices[j][0] >= i:\n",
    "                            border_indices[j][0] += 1\n",
    "                        if border_indices[j][1] >= i:\n",
    "                            border_indices[j][1] += 1\n",
    "                i += 1\n",
    "        i += 1\n",
    "    return text, border_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Tokenization by space and BIO Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_encoding(text, border_indices):\n",
    "    tokens = text.split(' ')\n",
    "    labels = ['O'] * len(tokens)\n",
    "    for annotation in border_indices:\n",
    "        start = annotation[0]\n",
    "        end = annotation[1]\n",
    "        label = annotation[2]\n",
    "        label = label.upper()\n",
    "        label_start_token = None\n",
    "        label_end_token = None\n",
    "        curr_token_index = 0\n",
    "        i = 0\n",
    "        while (i < len(text)):\n",
    "            if (text[i] == ' '):\n",
    "                i += 1\n",
    "            else:\n",
    "                curr_word = ''\n",
    "                if (i == start):\n",
    "                    label_start_token = curr_token_index\n",
    "                    while (i < end):\n",
    "                        current_word = ''\n",
    "                        if (text[i] == ' '):\n",
    "                            while (text[i] == ' '):\n",
    "                                i += 1\n",
    "                        else: \n",
    "                            while (i < len(text) and text[i] != ' '):\n",
    "                                current_word += text[i]\n",
    "                                i += 1\n",
    "                            if (tokens[curr_token_index] == current_word):\n",
    "                                curr_token_index += 1\n",
    "                    label_end_token = curr_token_index\n",
    "                else: \n",
    "                    while (i < len(text) and text[i] != ' '):\n",
    "                        curr_word += text[i]\n",
    "                        i += 1\n",
    "                    if (tokens[curr_token_index] == curr_word):\n",
    "                        curr_token_index += 1\n",
    "        if (label_end_token == None):\n",
    "            label_end_token = len(tokens) - 1\n",
    "        if (label_start_token == None):\n",
    "            continue\n",
    "        for i in range(label_start_token, label_end_token):\n",
    "            if i == label_start_token:\n",
    "                labels[i] = 'B_' + label\n",
    "            else:\n",
    "                labels[i] = 'I_' + label\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIO Encoding of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio(data):\n",
    "    processed_data = {}\n",
    "    for i in range(len(data)):\n",
    "        id = data[i]['id']\n",
    "        annotations = data[i]['annotations']\n",
    "        text = data[i]['data']['text']\n",
    "        text = clean_text(text)\n",
    "        border_indices = border_index(annotations)\n",
    "        text, border_indices = border_spacing(text, border_indices)\n",
    "        labels = bio_encoding(text, border_indices)\n",
    "        processed_data[id] = {'text': text, 'labels': labels}\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = convert_to_bio(train)\n",
    "processed_val = convert_to_bio(val)\n",
    "processed_test = convert_to_bio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the processed data\n",
    "with open('NER_TRAIN_JUDGEMENT_PROCESSED.json', 'w') as file:\n",
    "    json.dump(processed_train, file, indent=4)\n",
    "with open('NER_VAL_JUDGEMENT_PROCESSED.json', 'w') as file:\n",
    "    json.dump(processed_val, file, indent=4)\n",
    "with open('NER_TEST_JUDGEMENT_PROCESSED.json', 'w') as file:\n",
    "    json.dump(processed_test, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visiongpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
