{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### Importing required libraries"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:39.571338Z","iopub.status.busy":"2024-03-10T13:16:39.570878Z","iopub.status.idle":"2024-03-10T13:16:39.581136Z","shell.execute_reply":"2024-03-10T13:16:39.579527Z","shell.execute_reply.started":"2024-03-10T13:16:39.571303Z"},"trusted":true},"outputs":[],"source":["import json\n","import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from PIL import Image as im\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader, random_split, Subset, SubsetRandomSampler\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import train_test_split\n","from torchtext.vocab import GloVe\n","import tqdm"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:39.975285Z","iopub.status.busy":"2024-03-10T13:16:39.974028Z","iopub.status.idle":"2024-03-10T13:16:40.625053Z","shell.execute_reply":"2024-03-10T13:16:40.623598Z","shell.execute_reply.started":"2024-03-10T13:16:39.975239Z"},"trusted":true},"outputs":[],"source":["with open('NER_TRAIN_JUDGEMENT.json') as file:\n","    data = json.load(file)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:40.627518Z","iopub.status.busy":"2024-03-10T13:16:40.627133Z","iopub.status.idle":"2024-03-10T13:16:40.653193Z","shell.execute_reply":"2024-03-10T13:16:40.651743Z","shell.execute_reply.started":"2024-03-10T13:16:40.627487Z"},"trusted":true},"outputs":[],"source":["with open('NER_TEST_JUDGEMENT.json') as file:\n","    test_data = json.load(file)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:40.655184Z","iopub.status.busy":"2024-03-10T13:16:40.654851Z","iopub.status.idle":"2024-03-10T13:16:40.666478Z","shell.execute_reply":"2024-03-10T13:16:40.664990Z","shell.execute_reply.started":"2024-03-10T13:16:40.655156Z"},"trusted":true},"outputs":[],"source":["train, val = train_test_split(data, test_size=0.15, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["#### BIO Encoding of data"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:41.326377Z","iopub.status.busy":"2024-03-10T13:16:41.325955Z","iopub.status.idle":"2024-03-10T13:16:41.350156Z","shell.execute_reply":"2024-03-10T13:16:41.348909Z","shell.execute_reply.started":"2024-03-10T13:16:41.326344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'PROVISION', 'STATUTE', 'GPE', 'OTHER_PERSON', 'ORG', 'CASE_NUMBER', 'RESPONDENT', 'COURT', 'DATE', 'PRECEDENT', 'WITNESS', 'PETITIONER', 'JUDGE'}\n"]}],"source":["unique_labels = set()\n","for i in range(len(data)):\n","    for annotation in data[i]['annotations'][0]['result']:\n","        label = annotation['value']['labels'][0]\n","        unique_labels.add(label)\n","print(unique_labels)"]},{"cell_type":"markdown","metadata":{},"source":["#### Cleaning Data - Replacing escape sequences with spaces"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:42.289033Z","iopub.status.busy":"2024-03-10T13:16:42.288584Z","iopub.status.idle":"2024-03-10T13:16:42.295727Z","shell.execute_reply":"2024-03-10T13:16:42.294250Z","shell.execute_reply.started":"2024-03-10T13:16:42.288999Z"},"trusted":true},"outputs":[],"source":["def clean_text(text):\n","    special_chars = ['\\x05', '\\t', '\\n', '\\x0c', '\\x11', '\\x12', '\\x13', '\\x14', '\\x16', '\\x1a', '\\x80', '\\x9d', '\\xa0', '\\xad', '\\uf076']\n","    for char in special_chars:\n","        text = text.replace(char, ' ')\n","    return text"]},{"cell_type":"markdown","metadata":{},"source":["#### Storing all the label boundaries in a list"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:43.518125Z","iopub.status.busy":"2024-03-10T13:16:43.517571Z","iopub.status.idle":"2024-03-10T13:16:43.528045Z","shell.execute_reply":"2024-03-10T13:16:43.526422Z","shell.execute_reply.started":"2024-03-10T13:16:43.518084Z"},"trusted":true},"outputs":[],"source":["def border_index(annotations):\n","    border_indices = []\n","    for annotation in annotations[0]['result']:\n","        start = annotation['value']['start']\n","        end = annotation['value']['end']\n","        label = annotation['value']['labels'][0]\n","        label = label.upper()\n","        border_indices.append([start, end, label])\n","    border_indices.sort(key=lambda x: x[0])\n","    return border_indices"]},{"cell_type":"markdown","metadata":{},"source":["#### Adding spaces on the boundaries of labels where there is no space"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:44.295649Z","iopub.status.busy":"2024-03-10T13:16:44.295243Z","iopub.status.idle":"2024-03-10T13:16:44.310656Z","shell.execute_reply":"2024-03-10T13:16:44.309218Z","shell.execute_reply.started":"2024-03-10T13:16:44.295618Z"},"trusted":true},"outputs":[],"source":["def border_spacing(text, border_indices):\n","    i = 0\n","    while i < len(text):\n","        for border in border_indices:\n","            if (i==border[0] or i==border[1]):\n","                index = border_indices.index(border)\n","                if (i==border[0] and i!=0 and text[i-1]!=' '):\n","                    text = text[:i] + ' ' + text[i:]\n","                    for j in range(index, len(border_indices)):\n","                        if border_indices[j][0] >= i:\n","                            border_indices[j][0] += 1\n","                        if border_indices[j][1] >= i:\n","                            border_indices[j][1] += 1\n","                if (i==border[1] and i!=len(text)-1 and text[i]!=' '):\n","                    text = text[:i] + ' ' + text[i:]\n","                    for j in range(index, len(border_indices)):\n","                        if border_indices[j][0] >= i:\n","                            border_indices[j][0] += 1\n","                        if border_indices[j][1] >= i:\n","                            border_indices[j][1] += 1\n","                i += 1\n","        i += 1\n","    return text, border_indices"]},{"cell_type":"markdown","metadata":{},"source":["#### Performing Tokenization by space and BIO Encoding"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:45.063506Z","iopub.status.busy":"2024-03-10T13:16:45.063088Z","iopub.status.idle":"2024-03-10T13:16:45.078486Z","shell.execute_reply":"2024-03-10T13:16:45.077297Z","shell.execute_reply.started":"2024-03-10T13:16:45.063476Z"},"trusted":true},"outputs":[],"source":["def bio_encoding(text, border_indices):\n","    tokens = text.split()\n","    labels = ['O'] * len(tokens)\n","    for annotation in border_indices:\n","        start = annotation[0]\n","        end = annotation[1]\n","        label = annotation[2]\n","        label = label.upper()\n","        label_start_token = None\n","        label_end_token = None\n","        curr_token_index = 0\n","        i = 0\n","        while (i < len(text)):\n","            if (text[i] == ' '):\n","                i += 1\n","            else:\n","                curr_word = ''\n","                if (i == start):\n","                    label_start_token = curr_token_index\n","                    while (i < end):\n","                        current_word = ''\n","                        if (text[i] == ' '):\n","                            while (text[i] == ' '):\n","                                i += 1\n","                        else: \n","                            while (i < len(text) and text[i] != ' '):\n","                                current_word += text[i]\n","                                i += 1\n","                            if (tokens[curr_token_index] == current_word):\n","                                curr_token_index += 1\n","                    label_end_token = curr_token_index\n","                else: \n","                    while (i < len(text) and text[i] != ' '):\n","                        curr_word += text[i]\n","                        i += 1\n","                    if (tokens[curr_token_index] == curr_word):\n","                        curr_token_index += 1\n","        if (label_end_token == None):\n","            label_end_token = len(tokens) - 1\n","        if (label_start_token == None):\n","            continue\n","        for i in range(label_start_token, label_end_token):\n","            if i == label_start_token:\n","                labels[i] = 'B_' + label\n","            else:\n","                labels[i] = 'I_' + label\n","    return labels"]},{"cell_type":"markdown","metadata":{},"source":["#### BIO Encoding of data"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:45.783330Z","iopub.status.busy":"2024-03-10T13:16:45.782892Z","iopub.status.idle":"2024-03-10T13:16:45.791330Z","shell.execute_reply":"2024-03-10T13:16:45.789746Z","shell.execute_reply.started":"2024-03-10T13:16:45.783298Z"},"trusted":true},"outputs":[],"source":["def convert_to_bio(data):\n","    processed_data = {}\n","    for i in range(len(data)):\n","        id = data[i]['id']\n","        annotations = data[i]['annotations']\n","        text = data[i]['data']['text']\n","        text = clean_text(text)\n","        border_indices = border_index(annotations)\n","        text, border_indices = border_spacing(text, border_indices)\n","        labels = bio_encoding(text, border_indices)\n","        processed_data[id] = {'text': text, 'labels': labels}\n","    return processed_data"]},{"cell_type":"markdown","metadata":{},"source":["#### Saving the data"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:46.648594Z","iopub.status.busy":"2024-03-10T13:16:46.648181Z","iopub.status.idle":"2024-03-10T13:16:50.529917Z","shell.execute_reply":"2024-03-10T13:16:50.528751Z","shell.execute_reply.started":"2024-03-10T13:16:46.648563Z"},"trusted":true},"outputs":[],"source":["processed_train = convert_to_bio(train)\n","processed_val = convert_to_bio(val)\n","processed_test = convert_to_bio(test_data)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:50.531995Z","iopub.status.busy":"2024-03-10T13:16:50.531676Z","iopub.status.idle":"2024-03-10T13:16:51.014780Z","shell.execute_reply":"2024-03-10T13:16:51.013055Z","shell.execute_reply.started":"2024-03-10T13:16:50.531969Z"},"trusted":true},"outputs":[],"source":["# dumping the processed data\n","with open('NER_train.json', 'w') as file:\n","    json.dump(processed_train, file, indent=4)\n","with open('NER_val.json', 'w') as file:\n","    json.dump(processed_val, file, indent=4)\n","with open('NER_test.json', 'w') as file:\n","    json.dump(processed_test, file, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["#### Loading data"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:51.016982Z","iopub.status.busy":"2024-03-10T13:16:51.016463Z","iopub.status.idle":"2024-03-10T13:16:51.126994Z","shell.execute_reply":"2024-03-10T13:16:51.125868Z","shell.execute_reply.started":"2024-03-10T13:16:51.016938Z"},"trusted":true},"outputs":[],"source":["with open('NER_train.json') as file:\n","    train_data = json.load(file)\n","with open('NER_val.json') as file:\n","    val_data = json.load(file)\n","with open('NER_test.json') as file:\n","    test_data = json.load(file)"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the data"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:51.130231Z","iopub.status.busy":"2024-03-10T13:16:51.129634Z","iopub.status.idle":"2024-03-10T13:16:51.524560Z","shell.execute_reply":"2024-03-10T13:16:51.523396Z","shell.execute_reply.started":"2024-03-10T13:16:51.130187Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# plotting data distribution of number of tokens in each sentence\n","import matplotlib.pyplot as plt\n","label_counts = []\n","for key in train_data.keys():\n","    label_counts.append(len(train_data[key]['labels']))\n","plt.hist(label_counts, bins=30, alpha=0.5, color='b', edgecolor='black', linewidth=1.2, histtype='bar', align='mid', orientation='vertical', rwidth=0.8, label='Number of tokens')\n","plt.title('Distribution of number of tokens in each sentence')\n","plt.xlabel('Number of tokens')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:51.526621Z","iopub.status.busy":"2024-03-10T13:16:51.526262Z","iopub.status.idle":"2024-03-10T13:16:51.550659Z","shell.execute_reply":"2024-03-10T13:16:51.549011Z","shell.execute_reply.started":"2024-03-10T13:16:51.526592Z"},"trusted":true},"outputs":[],"source":["train, val, test = [], [], []\n","for i in train_data:\n","    train.append([train_data[i]['text'], train_data[i]['labels']])\n","for i in val_data:\n","    val.append([val_data[i]['text'], val_data[i]['labels']])\n","for i in test_data:\n","    test.append([test_data[i]['text'], test_data[i]['labels']])"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:53.664059Z","iopub.status.busy":"2024-03-10T13:16:53.663551Z","iopub.status.idle":"2024-03-10T13:16:53.670169Z","shell.execute_reply":"2024-03-10T13:16:53.668896Z","shell.execute_reply.started":"2024-03-10T13:16:53.664023Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data size: 8019\n","Validation data size: 1416\n","Test data size: 949\n"]}],"source":["print(f'Training data size: {len(train)}')\n","print(f'Validation data size: {len(val)}')\n","print(f'Test data size: {len(test)}')"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:54.862422Z","iopub.status.busy":"2024-03-10T13:16:54.862023Z","iopub.status.idle":"2024-03-10T13:16:54.870428Z","shell.execute_reply":"2024-03-10T13:16:54.868790Z","shell.execute_reply.started":"2024-03-10T13:16:54.862394Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Text: Therefore, while interpreting statutory provisions, the courts should keep in mind the objectives or purpose for which statute has been enacted.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The petitioner in W.P.No.15821 of 2008 was never considered for appointment under the National Rural Employment Guarantee Scheme either through Employment Exchange sponsorship or by Outsourcing Agencies.\n","Labels: ['O', 'O', 'O', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'I_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The factum of accident, allegation of rash and negligent driving causing death of Sukendra Pal Singh were denied.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_OTHER_PERSON', 'I_OTHER_PERSON', 'I_OTHER_PERSON', 'O', 'O']\n","\n","Text: ..36..    W.A.No.655/2012 & others Meaning thereby that except interview by the Commission, entire procedure for recruitment as emergency appointment was followed.\n","Labels: ['O', 'B_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The law on this issue is well settled and the law is that though the provisions of Evidence Act are not applicable, but in a given situation the help of the principles of Evidence Act in the proceedings before the assessing authorities can be taken.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n"]}],"source":["for i in range(5):\n","    text, labels = train[i][0], train[i][1]\n","    print(f\"Text: {text}\\nLabels: {labels}\\n\")"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:55.495162Z","iopub.status.busy":"2024-03-10T13:16:55.494707Z","iopub.status.idle":"2024-03-10T13:16:55.702970Z","shell.execute_reply":"2024-03-10T13:16:55.701727Z","shell.execute_reply.started":"2024-03-10T13:16:55.495126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset: 37866\n","Words and their counts: [('Therefore,', 97), ('while', 164), ('interpreting', 6), ('statutory', 76), ('provisions,', 10)]\n"]}],"source":["data = train + val + test\n","# Finding number of unique words in the dataset\n","word_count = {}\n","for i in range(len(data)):\n","    words = data[i][0].split()\n","    for word in words:\n","        if word not in word_count:\n","            word_count[word] = 1\n","        else:\n","            word_count[word] += 1\n","print(f\"Number of unique words in the dataset: {len(word_count)}\")\n","print(f\"Words and their counts: {list(word_count.items())[:5]}\")"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:57.809952Z","iopub.status.busy":"2024-03-10T13:16:57.809502Z","iopub.status.idle":"2024-03-10T13:16:57.819119Z","shell.execute_reply":"2024-03-10T13:16:57.817785Z","shell.execute_reply.started":"2024-03-10T13:16:57.809917Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset after adding 'PAD' and 'UNK': 37868\n"]}],"source":["word_list = list(word_count.keys())\n","# adding 'PAD' and 'UNK' to the word list\n","word_list.append('PAD')\n","word_list.append('UNK')\n","word_count['PAD'] = 0\n","word_count['UNK'] = 0\n","print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:16:59.552849Z","iopub.status.busy":"2024-03-10T13:16:59.551469Z","iopub.status.idle":"2024-03-10T13:16:59.586936Z","shell.execute_reply":"2024-03-10T13:16:59.585635Z","shell.execute_reply.started":"2024-03-10T13:16:59.552802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Word-to-index: [('Therefore,', 0), ('while', 1), ('interpreting', 2), ('statutory', 3), ('provisions,', 4)]\n","Index-to-word: [(0, 'Therefore,'), (1, 'while'), (2, 'interpreting'), (3, 'statutory'), (4, 'provisions,')]\n"]}],"source":["# Word-to-index and index-to-word mapping from the dataset\n","word_to_index = {word:idx for idx, word in enumerate(word_list)}\n","index_to_word = {idx:word for word, idx in word_to_index.items()}\n","print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n","print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:02.975143Z","iopub.status.busy":"2024-03-10T13:17:02.974681Z","iopub.status.idle":"2024-03-10T13:17:03.095198Z","shell.execute_reply":"2024-03-10T13:17:03.094328Z","shell.execute_reply.started":"2024-03-10T13:17:02.975107Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique labels in the dataset: 27\n","Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n","Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n","Label-to-index: [('O', 0), ('B_CASE_NUMBER', 1), ('I_CASE_NUMBER', 2), ('B_ORG', 3), ('I_ORG', 4), ('B_OTHER_PERSON', 5), ('I_OTHER_PERSON', 6), ('B_STATUTE', 7), ('I_STATUTE', 8), ('B_PROVISION', 9), ('I_PROVISION', 10), ('B_COURT', 11), ('I_COURT', 12), ('B_WITNESS', 13), ('B_PRECEDENT', 14), ('I_PRECEDENT', 15), ('B_DATE', 16), ('B_PETITIONER', 17), ('I_PETITIONER', 18), ('I_WITNESS', 19), ('B_GPE', 20), ('B_RESPONDENT', 21), ('I_RESPONDENT', 22), ('I_DATE', 23), ('B_JUDGE', 24), ('I_JUDGE', 25), ('I_GPE', 26)]\n","Index-to-label: [(0, 'O'), (1, 'B_CASE_NUMBER'), (2, 'I_CASE_NUMBER'), (3, 'B_ORG'), (4, 'I_ORG'), (5, 'B_OTHER_PERSON'), (6, 'I_OTHER_PERSON'), (7, 'B_STATUTE'), (8, 'I_STATUTE'), (9, 'B_PROVISION'), (10, 'I_PROVISION'), (11, 'B_COURT'), (12, 'I_COURT'), (13, 'B_WITNESS'), (14, 'B_PRECEDENT'), (15, 'I_PRECEDENT'), (16, 'B_DATE'), (17, 'B_PETITIONER'), (18, 'I_PETITIONER'), (19, 'I_WITNESS'), (20, 'B_GPE'), (21, 'B_RESPONDENT'), (22, 'I_RESPONDENT'), (23, 'I_DATE'), (24, 'B_JUDGE'), (25, 'I_JUDGE'), (26, 'I_GPE')]\n"]}],"source":["# finding all the unique labels in the dataset\n","label_count = {}\n","for i in range(len(data)):\n","    labels = data[i][1]\n","    for label in labels:\n","        if label not in label_count:\n","            label_count[label] = 1\n","        else:\n","            label_count[label] += 1\n","print(f\"Number of unique labels in the dataset: {len(label_count)}\")\n","print(f\"Labels and their counts: {list(label_count.items())}\")\n","print(f\"Labels and their counts: {list(label_count.items())}\")\n","label_to_idx = {label:idx for idx, label in enumerate(label_count.keys())}\n","idx_to_label = {idx:label for label, idx in label_to_idx.items()}\n","print(f\"Label-to-index: {list(label_to_idx.items())}\")\n","print(f\"Index-to-label: {list(idx_to_label.items())}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:02:29.306826Z","iopub.status.busy":"2024-03-10T13:02:29.306363Z","iopub.status.idle":"2024-03-10T13:02:34.770524Z","shell.execute_reply":"2024-03-10T13:02:34.768868Z","shell.execute_reply.started":"2024-03-10T13:02:29.306791Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":[".vector_cache/glove.6B.zip:   2%|▏         | 18.2M/862M [00:03<03:03, 4.60MB/s]   \n","\n","KeyboardInterrupt\n","\n"]}],"source":["from torchtext.vocab import GloVe\n","glove_vectors = GloVe(name='6B', dim=300)\n","word_embeddings = np.zeros((len(word_list), 300))\n","for i in range(len(word_list)):\n","    word = word_list[i]\n","    idx = word_to_index[word]\n","    if word in glove_vectors.stoi:\n","        word_embeddings[idx] = glove_vectors[word]\n","    else:\n","        word_embeddings[idx] = glove_vectors['unk']\n","print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:29.211221Z","iopub.status.busy":"2024-03-10T13:18:29.210682Z","iopub.status.idle":"2024-03-10T13:18:29.295924Z","shell.execute_reply":"2024-03-10T13:18:29.294806Z","shell.execute_reply.started":"2024-03-10T13:18:29.211188Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of word vectors: (37868, 300)\n"]}],"source":["# List of word vectors\n","word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n","word_vectors = np.array(word_vectors)\n","print(f\"Shape of word vectors: {word_vectors.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Setting up DataLoaders"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:29.830878Z","iopub.status.busy":"2024-03-10T13:18:29.830424Z","iopub.status.idle":"2024-03-10T13:18:29.841752Z","shell.execute_reply":"2024-03-10T13:18:29.840375Z","shell.execute_reply.started":"2024-03-10T13:18:29.830845Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    \"\"\"\n","        Padding the sequences to the maximum length sequence in the batch\n","        Args:\n","            batch: list of individual elements of the dataset\n","        Returns:\n","            {'text' : padded_texts, 'labels' : padded_labels}\n","    \"\"\"\n","    texts, labels = [item['text'] for item in batch], [item['labels'] for item in batch]\n","    max_len = max([len(text) for text in texts])\n","    padded_texts, padded_labels = [], []\n","    for i in range(len(texts)):\n","        text, label = texts[i], labels[i]\n","        # padding text and label sequences\n","        text = text + [word_to_index['PAD']] * (max_len - len(text))\n","        label = label + [label_to_idx['O']] * (max_len - len(label))\n","        padded_texts.append(text)\n","        padded_labels.append(label)\n","    return {'text': torch.tensor(padded_texts), 'labels': torch.tensor(padded_labels)}"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:30.448105Z","iopub.status.busy":"2024-03-10T13:18:30.446246Z","iopub.status.idle":"2024-03-10T13:18:30.459220Z","shell.execute_reply":"2024-03-10T13:18:30.457970Z","shell.execute_reply.started":"2024-03-10T13:18:30.448055Z"},"trusted":true},"outputs":[],"source":["class NERDataset(Dataset):\n","    \"\"\"\n","        Custom Dataset to load the Laptop Review dataset\n","        Args:\n","            data: list of tuples (text, labels)\n","            vocab_size: size of the vocabulary\n","            embedding_size: size of the word embeddings\n","            word_to_index: word-to-index mapping\n","            index_to_word: index-to-word mapping\n","            label_to_idx: label-to-index mapping\n","    \"\"\"\n","    def __init__(self, data, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx):\n","        self.data = data\n","        self.vocab_size = vocab_size\n","        self.embedding_size = embedding_size\n","        self.word_to_index = word_to_index\n","        self.index_to_word = index_to_word\n","        self.label_to_idx = label_to_idx \n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        text, labels = self.data[idx][0], self.data[idx][1]\n","        words = text.split()\n","        # converting words and labels to indices\n","        word_indices = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index['UNK'] for word in words]\n","        label_indices = [self.label_to_idx[label] for label in labels]\n","        sample = {'text' : word_indices, 'labels' : label_indices}\n","        return sample"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:31.569913Z","iopub.status.busy":"2024-03-10T13:18:31.569471Z","iopub.status.idle":"2024-03-10T13:18:31.574802Z","shell.execute_reply":"2024-03-10T13:18:31.573585Z","shell.execute_reply.started":"2024-03-10T13:18:31.569879Z"},"trusted":true},"outputs":[],"source":["# constants\n","vocab_size = len(word_to_index)\n","embedding_size = 300"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:33.664195Z","iopub.status.busy":"2024-03-10T13:18:33.663677Z","iopub.status.idle":"2024-03-10T13:18:33.671831Z","shell.execute_reply":"2024-03-10T13:18:33.670081Z","shell.execute_reply.started":"2024-03-10T13:18:33.664158Z"},"trusted":true},"outputs":[],"source":["train_dataset = NERDataset(train, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","val_dataset = NERDataset(val, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","test_dataset = NERDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:18:34.002890Z","iopub.status.busy":"2024-03-10T13:18:34.002099Z","iopub.status.idle":"2024-03-10T13:18:34.011605Z","shell.execute_reply":"2024-03-10T13:18:34.010086Z","shell.execute_reply.started":"2024-03-10T13:18:34.002837Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":119,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:50:04.472204Z","iopub.status.busy":"2024-03-10T13:50:04.471760Z","iopub.status.idle":"2024-03-10T13:50:04.491822Z","shell.execute_reply":"2024-03-10T13:50:04.490259Z","shell.execute_reply.started":"2024-03-10T13:50:04.472174Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch 1\n","Text shape: torch.Size([32, 68])\n","Labels shape: torch.Size([32, 68])\n","\n","Text: The firm was dissolved and its business was discontinued with effect from February 1, 1948. PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O O O O O O O O O O O O B_DATE I_DATE I_DATE O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n","\n","Text: This was followed by a letter of intent dated Nov. 4, 1980 issued by the CMDA incorporating therein the terms and conditions agreed upon by the parties and in reply thereto the petitioner on behalf of the firm wrote a letter on Nov. 6, 1980 accepting the terms and conditions. PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O O O O O O O O O B_DATE I_DATE I_DATE O O O B_ORG O O O O O O O O O O O O O O O O O O O O O O O O O O B_DATE I_DATE I_DATE O O O O O O O O O O O O O O O O O O O O O O O\n","\n"]}],"source":["for i, data in enumerate(train_dataloader, 0):\n","    print(f\"Batch {i+1}\\nText shape: {data['text'].size()}\\nLabels shape: {data['labels'].size()}\\n\")\n","    for j in range(2):\n","        text = data['text'][j]\n","        labels = data['labels'][j]\n","        text_str = ' '.join([index_to_word[idx.item()] for idx in text])\n","        labels_str = ' '.join([list(label_to_idx.keys())[idx.item()] for idx in labels])\n","        print(f\"Text: {text_str}\\nLabels: {labels_str}\\n\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: RNN + GloVe"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup\n"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\prakh\\.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["import tqdm\n","import wandb   \n","wandb.login(relogin=True)"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'RNN',\n","    embed_size = 300,\n","    embedding = 'GloVe',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprakhar432\u001b[0m (\u001b[33mnlp-assignments\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0578327e230340d78738e6821699cc34","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture\n"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:27:43.207965Z","iopub.status.busy":"2024-03-10T13:27:43.207490Z","iopub.status.idle":"2024-03-10T13:27:43.362484Z","shell.execute_reply":"2024-03-10T13:27:43.361624Z","shell.execute_reply.started":"2024-03-10T13:27:43.207930Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["37868 37868 300 128\n","Input shape: torch.Size([32, 61])\n","Label shape: torch.Size([32, 61])\n","Output shape: torch.Size([32, 61, 27])\n","Hidden shape: torch.Size([1, 32, 128])\n","\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/1076253624.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  word_vectors = torch.tensor(word_vectors)\n"]}],"source":["class RNNModel(nn.Module):\n","    \"\"\"\n","        Model architecture to perform Sequence Labeling on the Laptop Review dataset. RNN, LSTM or GRU model is initialized based on the model configuration parameters.\n","        Args: \n","            vocab_size: size of the vocabulary\n","            embed_size: size of the word embeddings\n","            hidden_size: size of the hidden state\n","            pretrained_embeddings: pre-trained word embeddings\n","            model_config: dictionary containing model configuration parameters\n","    \"\"\"\n","    def __init__(self, vocab_size, embed_size, hidden_size, pretrained_embeddings, model_config):\n","        super(RNNModel, self).__init__()\n","        self.embedding = nn.Embedding.from_pretrained(embeddings=pretrained_embeddings, freeze=True)\n","        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], nonlinearity=model_config['activation'], batch_first=True, dropout=model_config['dropout'])\n","        if (model_config['model'] == 'LSTM'):\n","            self.rnn = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n","        if (model_config['model'] == 'GRU'):\n","            self.rnn = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n","        self.fc = nn.Linear(hidden_size, 27)\n","        \n","    def forward(self, x):\n","        x = self.embedding(x)\n","        output, hidden = self.rnn(x)\n","        output = self.fc(output)\n","        return output, hidden\n","\n","# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:22.457094Z","iopub.status.busy":"2024-03-10T13:48:22.456664Z","iopub.status.idle":"2024-03-10T13:48:22.467947Z","shell.execute_reply":"2024-03-10T13:48:22.466950Z","shell.execute_reply.started":"2024-03-10T13:48:22.457062Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, dataloader, criterion):\n","    model.eval()\n","    loss = 0\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for i, data in enumerate(dataloader, 0):\n","            text, labels = data['text'], data['labels']\n","            output, hidden = model(text)\n","            output = output.view(-1, 27)\n","            labels = labels.view(-1)\n","            loss += criterion(output, labels).item()\n","            y_true += labels.tolist()\n","            y_pred += torch.argmax(output, 1).tolist()\n","    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n","    macro_f1 = f1_score(y_true, y_pred, average='macro')\n","    return accuracy, macro_f1, loss"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:22.955653Z","iopub.status.busy":"2024-03-10T13:48:22.955004Z","iopub.status.idle":"2024-03-10T13:48:22.973154Z","shell.execute_reply":"2024-03-10T13:48:22.971987Z","shell.execute_reply.started":"2024-03-10T13:48:22.955619Z"},"trusted":true},"outputs":[],"source":["def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config):\n","    wandb.define_metric('epoch')\n","    wandb.define_metric('minibatch_epoch')\n","    wandb.define_metric('train_loss', step_metric='epoch')\n","    wandb.define_metric('val_loss', step_metric='epoch')    \n","    wandb.define_metric('train_f1', step_metric='epoch')\n","    wandb.define_metric('val_f1', step_metric='epoch')\n","    wandb.define_metric('train_acc', step_metric='epoch')\n","    wandb.define_metric('val_acc', step_metric='epoch')\n","    wandb.define_metric('minibatch_loss', step_metric='minibatch_epoch')\n","    wandb.define_metric('minibatch_acc', step_metric='minibatch_epoch')\n","    wandb.define_metric('minibatch_f1', step_metric='minibatch_epoch')\n","    minibatch = 0\n","    for epoch in tqdm.tqdm(range(model_config['epochs'])):\n","        model.train()\n","        for i, data in enumerate(train_dataloader, 0):\n","            text, labels = data['text'], data['labels']\n","            optimizer.zero_grad()\n","            outputs, hidden = model(text)\n","            outputs = outputs.view(-1, 27)\n","            labels = labels.view(-1)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            y_true = labels.tolist()\n","            y_pred = torch.argmax(outputs, 1).tolist()\n","            minibatch_acc = (np.array(y_true) == np.array(y_pred)).mean()\n","            minibatch_f1 = f1_score(y_true, y_pred, average='weighted')\n","            # logging\n","            log = {}\n","            log[\"minibatch_epoch\"] = minibatch\n","            log[\"minibatch_loss\"] = loss.item()\n","            log[\"minibatch_acc\"] = minibatch_acc\n","            log[\"minibatch_f1\"] = minibatch_f1\n","            wandb.log(log)\n","            minibatch += 1\n","        # logging\n","        accuracy, f1, loss = evaluate_model(model, train_dataloader, criterion)\n","        epoch_log = {}\n","        epoch_log[\"epoch\"] = epoch\n","        epoch_log[\"train_loss\"] = loss\n","        epoch_log[\"train_f1\"] = f1\n","        epoch_log[\"train_acc\"] = accuracy\n","        accuracy, f1, loss = evaluate_model(model, val_dataloader, criterion)\n","        epoch_log[\"val_loss\"] = loss\n","        epoch_log[\"val_f1\"] = f1\n","        epoch_log[\"val_acc\"] = accuracy\n","        wandb.log(epoch_log)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":115,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:25.273231Z","iopub.status.busy":"2024-03-10T13:48:25.272346Z","iopub.status.idle":"2024-03-10T13:48:25.284948Z","shell.execute_reply":"2024-03-10T13:48:25.283518Z","shell.execute_reply.started":"2024-03-10T13:48:25.273197Z"},"trusted":true},"outputs":[],"source":["def evaluation(model, dataloader, criterion):\n","    model.eval()\n","    loss = 0\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for i, data in enumerate(dataloader, 0):\n","            text, labels = data['text'], data['labels']\n","            outputs, hidden = model(text)\n","            outputs = outputs.view(-1, 27)\n","            labels = labels.view(-1)\n","            loss += criterion(outputs, labels).item()\n","            y_true += labels.tolist()\n","            y_pred += torch.argmax(outputs, 1).tolist()\n","    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    macro_f1 = f1_score(y_true, y_pred, average='macro')\n","    from sklearn.metrics import classification_report\n","    classification_report = classification_report(y_true, y_pred)\n","    return accuracy, precision, macro_f1, loss, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model1_glove.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: GRU + GloVe"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprakhar432\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["import tqdm\n","import wandb   \n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'GRU',\n","    embed_size = 300,\n","    embedding = 'GloVe',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model3_glove.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: LSTM + GloVe"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'LSTM',\n","    embed_size = 300,\n","    embedding = 'GloVe',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model2_glove.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: RNN + FastText"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train, val, test = [], [], []\n","for i in train_data:\n","    train.append([train_data[i]['text'], train_data[i]['labels']])\n","for i in val_data:\n","    val.append([val_data[i]['text'], val_data[i]['labels']])\n","for i in test_data:\n","    test.append([test_data[i]['text'], test_data[i]['labels']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data size: 8019\n","\n","Validation data size: 1416\n","\n","Test data size: 949\n"]}],"source":["print(f'Training data size: {len(train)}')\n","print(f'Validation data size: {len(val)}')\n","print(f'Test data size: {len(test)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Text: Therefore, while interpreting statutory provisions, the courts should keep in mind the objectives or purpose for which statute has been enacted.\n","\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","\n","\n","Text: The petitioner in W.P.No.15821 of 2008 was never considered for appointment under the National Rural Employment Guarantee Scheme either through Employment Exchange sponsorship or by Outsourcing Agencies.\n","\n","Labels: ['O', 'O', 'O', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'I_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","\n","\n","Text: The factum of accident, allegation of rash and negligent driving causing death of Sukendra Pal Singh were denied.\n","\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_OTHER_PERSON', 'I_OTHER_PERSON', 'I_OTHER_PERSON', 'O', 'O']\n","\n","\n","\n","Text: ..36..    W.A.No.655/2012 & others Meaning thereby that except interview by the Commission, entire procedure for recruitment as emergency appointment was followed.\n","\n","Labels: ['O', 'B_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","\n","\n","Text: The law on this issue is well settled and the law is that though the provisions of Evidence Act are not applicable, but in a given situation the help of the principles of Evidence Act in the proceedings before the assessing authorities can be taken.\n","\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","\n"]}],"source":["for i in range(5):\n","    text, labels = train[i][0], train[i][1]\n","    print(f\"Text: {text}\\nLabels: {labels}\\n\")"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:23:54.442407Z","iopub.status.busy":"2024-03-10T13:23:54.441999Z","iopub.status.idle":"2024-03-10T13:23:54.639008Z","shell.execute_reply":"2024-03-10T13:23:54.637649Z","shell.execute_reply.started":"2024-03-10T13:23:54.442378Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset: 37866\n","Words and their counts: [('Therefore,', 97), ('while', 164), ('interpreting', 6), ('statutory', 76), ('provisions,', 10)]\n"]}],"source":["data = train + val + test\n","# Finding number of unique words in the dataset\n","word_count = {}\n","for i in range(len(data)):\n","    words = data[i][0].split()\n","    for word in words:\n","        if word not in word_count:\n","            word_count[word] = 1\n","        else:\n","            word_count[word] += 1\n","print(f\"Number of unique words in the dataset: {len(word_count)}\")\n","print(f\"Words and their counts: {list(word_count.items())[:5]}\")"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:23:54.676098Z","iopub.status.busy":"2024-03-10T13:23:54.675434Z","iopub.status.idle":"2024-03-10T13:23:54.684939Z","shell.execute_reply":"2024-03-10T13:23:54.683737Z","shell.execute_reply.started":"2024-03-10T13:23:54.676064Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset after adding 'PAD' and 'UNK': 37868\n"]}],"source":["word_list = list(word_count.keys())\n","# adding 'PAD' and 'UNK' to the word list\n","word_list.append('PAD')\n","word_list.append('UNK')\n","word_count['PAD'] = 0\n","word_count['UNK'] = 0\n","print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:23:56.934472Z","iopub.status.busy":"2024-03-10T13:23:56.934092Z","iopub.status.idle":"2024-03-10T13:23:57.077041Z","shell.execute_reply":"2024-03-10T13:23:57.075590Z","shell.execute_reply.started":"2024-03-10T13:23:56.934443Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Word-to-index: [('Therefore,', 0), ('while', 1), ('interpreting', 2), ('statutory', 3), ('provisions,', 4)]\n","Index-to-word: [(0, 'Therefore,'), (1, 'while'), (2, 'interpreting'), (3, 'statutory'), (4, 'provisions,')]\n","Number of unique labels in the dataset: 27\n","Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n","Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n","Label-to-index: [('O', 0), ('B_CASE_NUMBER', 1), ('I_CASE_NUMBER', 2), ('B_ORG', 3), ('I_ORG', 4), ('B_OTHER_PERSON', 5), ('I_OTHER_PERSON', 6), ('B_STATUTE', 7), ('I_STATUTE', 8), ('B_PROVISION', 9), ('I_PROVISION', 10), ('B_COURT', 11), ('I_COURT', 12), ('B_WITNESS', 13), ('B_PRECEDENT', 14), ('I_PRECEDENT', 15), ('B_DATE', 16), ('B_PETITIONER', 17), ('I_PETITIONER', 18), ('I_WITNESS', 19), ('B_GPE', 20), ('B_RESPONDENT', 21), ('I_RESPONDENT', 22), ('I_DATE', 23), ('B_JUDGE', 24), ('I_JUDGE', 25), ('I_GPE', 26)]\n","Index-to-label: [(0, 'O'), (1, 'B_CASE_NUMBER'), (2, 'I_CASE_NUMBER'), (3, 'B_ORG'), (4, 'I_ORG'), (5, 'B_OTHER_PERSON'), (6, 'I_OTHER_PERSON'), (7, 'B_STATUTE'), (8, 'I_STATUTE'), (9, 'B_PROVISION'), (10, 'I_PROVISION'), (11, 'B_COURT'), (12, 'I_COURT'), (13, 'B_WITNESS'), (14, 'B_PRECEDENT'), (15, 'I_PRECEDENT'), (16, 'B_DATE'), (17, 'B_PETITIONER'), (18, 'I_PETITIONER'), (19, 'I_WITNESS'), (20, 'B_GPE'), (21, 'B_RESPONDENT'), (22, 'I_RESPONDENT'), (23, 'I_DATE'), (24, 'B_JUDGE'), (25, 'I_JUDGE'), (26, 'I_GPE')]\n"]}],"source":["# Word-to-index and index-to-word mapping from the dataset\n","word_to_index = {word:idx for idx, word in enumerate(word_list)}\n","index_to_word = {idx:word for word, idx in word_to_index.items()}\n","print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n","print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")\n","# finding all the unique labels in the dataset\n","label_count = {}\n","for i in range(len(data)):\n","    labels = data[i][1]\n","    for label in labels:\n","        if label not in label_count:\n","            label_count[label] = 1\n","        else:\n","            label_count[label] += 1\n","print(f\"Number of unique labels in the dataset: {len(label_count)}\")\n","print(f\"Labels and their counts: {list(label_count.items())}\")\n","print(f\"Labels and their counts: {list(label_count.items())}\")\n","label_to_idx = {label:idx for idx, label in enumerate(label_count.keys())}\n","idx_to_label = {idx:label for label, idx in label_to_idx.items()}\n","print(f\"Label-to-index: {list(label_to_idx.items())}\")\n","print(f\"Index-to-label: {list(idx_to_label.items())}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of word_embeddings: (37868, 300)\n"]}],"source":["from torchtext.vocab import FastText\n","fasttext_vectors = FastText(language=\"en\")\n","word_embeddings = np.zeros((len(word_list), 300))\n","for i in range(len(word_list)):\n","    word = word_list[i]\n","    idx = word_to_index[word]\n","    if word in glove_vectors.stoi:\n","        word_embeddings[idx] = fasttext_vectors[word]\n","    else:\n","        word_embeddings[idx] = fasttext_vectors['unk']\n","print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of word vectors: (37868, 300)\n"]}],"source":["# List of word vectors\n","word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n","word_vectors = np.array(word_vectors)\n","print(f\"Shape of word vectors: {word_vectors.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# constants\n","vocab_size = len(word_to_index)\n","embedding_size = 300"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:19.077054Z","iopub.status.busy":"2024-03-10T13:24:19.076610Z","iopub.status.idle":"2024-03-10T13:24:19.084153Z","shell.execute_reply":"2024-03-10T13:24:19.082885Z","shell.execute_reply.started":"2024-03-10T13:24:19.077015Z"},"trusted":true},"outputs":[],"source":["train_dataset = NERDataset(train, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","val_dataset = NERDataset(val, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","test_dataset = NERDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:20.413987Z","iopub.status.busy":"2024-03-10T13:24:20.413537Z","iopub.status.idle":"2024-03-10T13:24:20.420836Z","shell.execute_reply":"2024-03-10T13:24:20.419622Z","shell.execute_reply.started":"2024-03-10T13:24:20.413956Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:20.869268Z","iopub.status.busy":"2024-03-10T13:24:20.868870Z","iopub.status.idle":"2024-03-10T13:24:20.901305Z","shell.execute_reply":"2024-03-10T13:24:20.900404Z","shell.execute_reply.started":"2024-03-10T13:24:20.869238Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch 1\n","Text shape: torch.Size([32, 68])\n","Labels shape: torch.Size([32, 68])\n","\n","Text: As Criminal Appeal No.472 of 1992 has been allowed by us, we do not see any reason, at this point of time, to enhance the sentence awarded to accused no.1 by the trial Court for the offence punishable under Section 498-A of IPC. PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O B_CASE_NUMBER I_CASE_NUMBER I_CASE_NUMBER I_CASE_NUMBER I_CASE_NUMBER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B_PROVISION I_PROVISION O B_STATUTE O O O O O O O O O O O O O O O O O O O O O O O O O\n","\n","Text: Even before this court there has been no controversy raised with regard to any such distinction at the Bar. PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n","\n"]}],"source":["for i, data in enumerate(train_dataloader, 0):\n","    print(f\"Batch {i+1}\\nText shape: {data['text'].size()}\\nLabels shape: {data['labels'].size()}\\n\")\n","    for j in range(2):\n","        text = data['text'][j]\n","        labels = data['labels'][j]\n","        text_str = ' '.join([index_to_word[idx.item()] for idx in text])\n","        labels_str = ' '.join([list(label_to_idx.keys())[idx.item()] for idx in labels])\n","        print(f\"Text: {text_str}\\nLabels: {labels_str}\\n\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","import wandb   \n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'RNN',\n","    embed_size = 300,\n","    embedding = 'FastText',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model1_fasttext.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: GRU + FastText"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'GRU',\n","    embed_size = 300,\n","    embedding = 'FastText',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model3_fasttext.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: LSTM + FastText"]},{"cell_type":"markdown","metadata":{},"source":["#### WandB Setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'LSTM',\n","    embed_size = 300,\n","    embedding = 'FastText',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model2_fasttext.pth')"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the data"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:28.436036Z","iopub.status.busy":"2024-03-10T13:17:28.435622Z","iopub.status.idle":"2024-03-10T13:17:28.457241Z","shell.execute_reply":"2024-03-10T13:17:28.456154Z","shell.execute_reply.started":"2024-03-10T13:17:28.436006Z"},"trusted":true},"outputs":[],"source":["train, val, test = [], [], []\n","for i in train_data:\n","    train.append([train_data[i]['text'], train_data[i]['labels']])\n","for i in val_data:\n","    val.append([val_data[i]['text'], val_data[i]['labels']])\n","for i in test_data:\n","    test.append([test_data[i]['text'], test_data[i]['labels']])"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:28.909036Z","iopub.status.busy":"2024-03-10T13:17:28.908616Z","iopub.status.idle":"2024-03-10T13:17:28.914755Z","shell.execute_reply":"2024-03-10T13:17:28.913370Z","shell.execute_reply.started":"2024-03-10T13:17:28.908997Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data size: 8019\n","Validation data size: 1416\n","Test data size: 949\n"]}],"source":["print(f'Training data size: {len(train)}')\n","print(f'Validation data size: {len(val)}')\n","print(f'Test data size: {len(test)}')"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:30.237512Z","iopub.status.busy":"2024-03-10T13:17:30.236665Z","iopub.status.idle":"2024-03-10T13:17:30.244844Z","shell.execute_reply":"2024-03-10T13:17:30.243375Z","shell.execute_reply.started":"2024-03-10T13:17:30.237477Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Text: Therefore, while interpreting statutory provisions, the courts should keep in mind the objectives or purpose for which statute has been enacted.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The petitioner in W.P.No.15821 of 2008 was never considered for appointment under the National Rural Employment Guarantee Scheme either through Employment Exchange sponsorship or by Outsourcing Agencies.\n","Labels: ['O', 'O', 'O', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'I_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'I_ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The factum of accident, allegation of rash and negligent driving causing death of Sukendra Pal Singh were denied.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_OTHER_PERSON', 'I_OTHER_PERSON', 'I_OTHER_PERSON', 'O', 'O']\n","\n","Text: ..36..    W.A.No.655/2012 & others Meaning thereby that except interview by the Commission, entire procedure for recruitment as emergency appointment was followed.\n","Labels: ['O', 'B_CASE_NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n","Text: The law on this issue is well settled and the law is that though the provisions of Evidence Act are not applicable, but in a given situation the help of the principles of Evidence Act in the proceedings before the assessing authorities can be taken.\n","Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_STATUTE', 'I_STATUTE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","\n"]}],"source":["for i in range(5):\n","    text, labels = train[i][0], train[i][1]\n","    print(f\"Text: {text}\\nLabels: {labels}\\n\")"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:31.216412Z","iopub.status.busy":"2024-03-10T13:17:31.215915Z","iopub.status.idle":"2024-03-10T13:17:31.409341Z","shell.execute_reply":"2024-03-10T13:17:31.408161Z","shell.execute_reply.started":"2024-03-10T13:17:31.216374Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset: 37866\n","Words and their counts: [('Therefore,', 97), ('while', 164), ('interpreting', 6), ('statutory', 76), ('provisions,', 10)]\n"]}],"source":["data = train + val + test\n","# Finding number of unique words in the dataset\n","word_count = {}\n","for i in range(len(data)):\n","    words = data[i][0].split()\n","    for word in words:\n","        if word not in word_count:\n","            word_count[word] = 1\n","        else:\n","            word_count[word] += 1\n","print(f\"Number of unique words in the dataset: {len(word_count)}\")\n","print(f\"Words and their counts: {list(word_count.items())[:5]}\")"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:32.390866Z","iopub.status.busy":"2024-03-10T13:17:32.389675Z","iopub.status.idle":"2024-03-10T13:17:32.401548Z","shell.execute_reply":"2024-03-10T13:17:32.399993Z","shell.execute_reply.started":"2024-03-10T13:17:32.390820Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of unique words in the dataset after adding 'PAD' and 'UNK': 37868\n"]}],"source":["word_list = list(word_count.keys())\n","# adding 'PAD' and 'UNK' to the word list\n","word_list.append('PAD')\n","word_list.append('UNK')\n","word_count['PAD'] = 0\n","word_count['UNK'] = 0\n","print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:17:33.558939Z","iopub.status.busy":"2024-03-10T13:17:33.558502Z","iopub.status.idle":"2024-03-10T13:17:33.598390Z","shell.execute_reply":"2024-03-10T13:17:33.597035Z","shell.execute_reply.started":"2024-03-10T13:17:33.558906Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Word-to-index: [('Therefore,', 0), ('while', 1), ('interpreting', 2), ('statutory', 3), ('provisions,', 4)]\n","Index-to-word: [(0, 'Therefore,'), (1, 'while'), (2, 'interpreting'), (3, 'statutory'), (4, 'provisions,')]\n"]}],"source":["# Word-to-index and index-to-word mapping from the dataset\n","word_to_index = {word:idx for idx, word in enumerate(word_list)}\n","index_to_word = {idx:word for word, idx in word_to_index.items()}\n","label_to_idx = {'O': 0, 'B': 1, 'I': 2}\n","print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n","print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:54.233643Z","iopub.status.busy":"2024-03-10T13:24:54.233213Z","iopub.status.idle":"2024-03-10T13:24:54.447115Z","shell.execute_reply":"2024-03-10T13:24:54.445750Z","shell.execute_reply.started":"2024-03-10T13:24:54.233609Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of word embeddings: (37868, 300)\n"]}],"source":["import gensim\n","import torch\n","import gensim.downloader as api\n","wv = api.load('word2vec-google-news-300')\n","\n","# Load word embeddings\n","word_embeddings = []\n","for word in word_list:\n","    try:\n","        word_embeddings.append(wv[word])\n","    except:\n","        word_embeddings.append(wv['unk'])\n","word_embeddings = np.array(word_embeddings)\n","print(f\"Shape of word embeddings: {word_embeddings.shape}\")\n"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:54.817380Z","iopub.status.busy":"2024-03-10T13:24:54.816963Z","iopub.status.idle":"2024-03-10T13:24:54.895628Z","shell.execute_reply":"2024-03-10T13:24:54.894265Z","shell.execute_reply.started":"2024-03-10T13:24:54.817350Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of word vectors: (37868, 300)\n"]}],"source":["# List of word vectors\n","word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n","word_vectors = np.array(word_vectors)\n","print(f\"Shape of word vectors: {word_vectors.shape}\")"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:57.004258Z","iopub.status.busy":"2024-03-10T13:24:57.003467Z","iopub.status.idle":"2024-03-10T13:24:57.009909Z","shell.execute_reply":"2024-03-10T13:24:57.008719Z","shell.execute_reply.started":"2024-03-10T13:24:57.004223Z"},"trusted":true},"outputs":[],"source":["# constants\n","vocab_size = len(word_to_index)\n","embedding_size = 300"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:57.253798Z","iopub.status.busy":"2024-03-10T13:24:57.253393Z","iopub.status.idle":"2024-03-10T13:24:57.259943Z","shell.execute_reply":"2024-03-10T13:24:57.258654Z","shell.execute_reply.started":"2024-03-10T13:24:57.253767Z"},"trusted":true},"outputs":[],"source":["train_dataset = NERDataset(train, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","val_dataset = NERDataset(val, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)\n","test_dataset = NERDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:59.119775Z","iopub.status.busy":"2024-03-10T13:24:59.119320Z","iopub.status.idle":"2024-03-10T13:24:59.125789Z","shell.execute_reply":"2024-03-10T13:24:59.124522Z","shell.execute_reply.started":"2024-03-10T13:24:59.119741Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:24:59.714369Z","iopub.status.busy":"2024-03-10T13:24:59.713906Z","iopub.status.idle":"2024-03-10T13:24:59.729398Z","shell.execute_reply":"2024-03-10T13:24:59.727867Z","shell.execute_reply.started":"2024-03-10T13:24:59.714332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch 1\n","Text shape: torch.Size([32, 54])\n","Labels shape: torch.Size([32, 54])\n","\n","Text: He knows the objector and belongs to the same State ( Kerala ). PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O O O O O O O O O O O B_GPE O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n","\n","Text: The material placed on record fully establishes that the assessment of the petitioner's work and conduct was bad and the adverse remarks for the year 1994-95 were sufficient for the impugned action. PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n","Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n","\n"]}],"source":["for i, data in enumerate(train_dataloader, 0):\n","    print(f\"Batch {i+1}\\nText shape: {data['text'].size()}\\nLabels shape: {data['labels'].size()}\\n\")\n","    for j in range(2):\n","        text = data['text'][j]\n","        labels = data['labels'][j]\n","        text_str = ' '.join([index_to_word[idx.item()] for idx in text])\n","        labels_str = ' '.join([list(label_to_idx.keys())[idx.item()] for idx in labels])\n","        print(f\"Text: {text_str}\\nLabels: {labels_str}\\n\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["### Task1: RNN + Word2Vec"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:26:44.770729Z","iopub.status.busy":"2024-03-10T13:26:44.770317Z","iopub.status.idle":"2024-03-10T13:26:48.315503Z","shell.execute_reply":"2024-03-10T13:26:48.314123Z","shell.execute_reply.started":"2024-03-10T13:26:44.770671Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["import tqdm\n","import wandb   \n","wandb.login(relogin=True)"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:26:50.718222Z","iopub.status.busy":"2024-03-10T13:26:50.717818Z","iopub.status.idle":"2024-03-10T13:26:50.724967Z","shell.execute_reply":"2024-03-10T13:26:50.723762Z","shell.execute_reply.started":"2024-03-10T13:26:50.718193Z"},"trusted":true},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'RNN',\n","    embed_size = 300,\n","    embedding = 'Word2Vec',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:26:53.246549Z","iopub.status.busy":"2024-03-10T13:26:53.245341Z","iopub.status.idle":"2024-03-10T13:27:24.318528Z","shell.execute_reply":"2024-03-10T13:27:24.317333Z","shell.execute_reply.started":"2024-03-10T13:26:53.246495Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahcir\u001b[0m (\u001b[33mnlp-assignments\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240310_132653-9wxu3st8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8' target=\"_blank\">comfy-capybara-29</a></strong> to <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7aa2079adf90>"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:28:27.779815Z","iopub.status.busy":"2024-03-10T13:28:27.779401Z","iopub.status.idle":"2024-03-10T13:28:27.838180Z","shell.execute_reply":"2024-03-10T13:28:27.837244Z","shell.execute_reply.started":"2024-03-10T13:28:27.779783Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["37868 37868 300 128\n","Input shape: torch.Size([32, 66])\n","Label shape: torch.Size([32, 66])\n","Output shape: torch.Size([32, 66, 27])\n","Hidden shape: torch.Size([1, 32, 128])\n","\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/532150329.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  word_vectors = torch.tensor(word_vectors)\n"]}],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:28:29.999501Z","iopub.status.busy":"2024-03-10T13:28:29.998857Z","iopub.status.idle":"2024-03-10T13:28:30.006949Z","shell.execute_reply":"2024-03-10T13:28:30.005333Z","shell.execute_reply.started":"2024-03-10T13:28:29.999467Z"},"trusted":true},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:28:58.735626Z","iopub.status.busy":"2024-03-10T13:28:58.735194Z","iopub.status.idle":"2024-03-10T13:47:58.987268Z","shell.execute_reply":"2024-03-10T13:47:58.985902Z","shell.execute_reply.started":"2024-03-10T13:28:58.735590Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [19:00<00:00, 11.40s/it]\n"]}],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:38.857073Z","iopub.status.busy":"2024-03-10T13:48:38.856647Z","iopub.status.idle":"2024-03-10T13:48:39.480184Z","shell.execute_reply":"2024-03-10T13:48:39.478786Z","shell.execute_reply.started":"2024-03-10T13:48:38.857044Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.9517\n","Test precision: 0.9485\n","Test macro F1: 0.5221\n","Test loss: 9.7472\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98     57483\n","           1       0.40      0.26      0.31       121\n","           2       0.61      0.47      0.53       344\n","           3       0.43      0.31      0.36       159\n","           4       0.43      0.29      0.35       310\n","           5       0.55      0.57      0.56       276\n","           6       0.59      0.59      0.59       195\n","           7       0.69      0.60      0.64       222\n","           8       0.75      0.68      0.71       383\n","           9       0.90      0.86      0.88       258\n","          10       0.86      0.77      0.82       439\n","          11       0.83      0.73      0.78       178\n","          12       0.84      0.73      0.78       326\n","          13       0.44      0.48      0.46        58\n","          14       0.50      0.37      0.42       177\n","          15       0.85      0.63      0.72      1793\n","          16       0.80      0.78      0.79       222\n","          17       0.25      0.44      0.32         9\n","          18       0.24      0.45      0.31        11\n","          19       0.55      0.39      0.46        54\n","          20       0.43      0.45      0.44       183\n","          21       0.22      0.40      0.29         5\n","          22       0.17      0.22      0.19         9\n","          23       0.69      0.67      0.68       102\n","          24       0.08      0.25      0.12         8\n","          25       0.27      0.57      0.36         7\n","          26       0.23      0.23      0.23        47\n","\n","    accuracy                           0.95     63379\n","   macro avg       0.54      0.53      0.52     63379\n","weighted avg       0.95      0.95      0.95     63379\n","\n"]}],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":117,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:47.102086Z","iopub.status.busy":"2024-03-10T13:48:47.100926Z","iopub.status.idle":"2024-03-10T13:48:53.178163Z","shell.execute_reply":"2024-03-10T13:48:53.177222Z","shell.execute_reply.started":"2024-03-10T13:48:47.102044Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Test loss</td><td>▁</td></tr><tr><td>Test macro F1</td><td>▁</td></tr><tr><td>Test precision</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_acc</td><td>▁▁▂▃▅▂▄▅▆▄▃▅▅▄▇▅▇▆▆▇▇▇▇▇█▇▇▇███▇██▇██▇██</td></tr><tr><td>minibatch_epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_f1</td><td>▁▃▃▄▆▄▅▆▆▅▄▆▆▅▇▆▇▇▆▇▇▇▇▇█▇█████▇████████</td></tr><tr><td>minibatch_loss</td><td>█▆▆▄▃▅▄▃▃▄▄▃▃▄▂▃▂▂▃▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇███████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇█▇██████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▅▆▆▇▇█████████████████████▇▇█▇▇█▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▄▅▅▅▅▅▅▅▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.9517</td></tr><tr><td>Test loss</td><td>9.74718</td></tr><tr><td>Test macro F1</td><td>0.5221</td></tr><tr><td>Test precision</td><td>0.94852</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>minibatch_acc</td><td>0.99458</td></tr><tr><td>minibatch_epoch</td><td>25099</td></tr><tr><td>minibatch_f1</td><td>0.9946</td></tr><tr><td>minibatch_loss</td><td>0.01763</td></tr><tr><td>train_acc</td><td>0.9963</td></tr><tr><td>train_f1</td><td>0.95753</td></tr><tr><td>train_loss</td><td>3.57693</td></tr><tr><td>val_acc</td><td>0.95793</td></tr><tr><td>val_f1</td><td>0.54738</td></tr><tr><td>val_loss</td><td>11.39213</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">comfy-capybara-29</strong> at: <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/9wxu3st8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240310_132653-9wxu3st8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:48:53.179982Z","iopub.status.busy":"2024-03-10T13:48:53.179605Z","iopub.status.idle":"2024-03-10T13:48:53.246211Z","shell.execute_reply":"2024-03-10T13:48:53.244927Z","shell.execute_reply.started":"2024-03-10T13:48:53.179951Z"},"trusted":true},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model1_word2vec.pth')"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 1: GRU + Word2Vec"]},{"cell_type":"code","execution_count":120,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:50:44.198761Z","iopub.status.busy":"2024-03-10T13:50:44.198321Z","iopub.status.idle":"2024-03-10T13:51:01.193338Z","shell.execute_reply":"2024-03-10T13:51:01.192007Z","shell.execute_reply.started":"2024-03-10T13:50:44.198728Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["import tqdm\n","import wandb\n","wandb.login(relogin=True)"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:51:17.196851Z","iopub.status.busy":"2024-03-10T13:51:17.196383Z","iopub.status.idle":"2024-03-10T13:51:17.203983Z","shell.execute_reply":"2024-03-10T13:51:17.202641Z","shell.execute_reply.started":"2024-03-10T13:51:17.196815Z"},"trusted":true},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'GRU',\n","    embed_size = 300,\n","    embedding = 'Word2Vec',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:51:30.295067Z","iopub.status.busy":"2024-03-10T13:51:30.294582Z","iopub.status.idle":"2024-03-10T13:52:07.431433Z","shell.execute_reply":"2024-03-10T13:52:07.430432Z","shell.execute_reply.started":"2024-03-10T13:51:30.295032Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7e46711c1284c8195b57b9a02c909df","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113899888889339, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240310_135130-y99dqwt4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4' target=\"_blank\">denim-monkey-30</a></strong> to <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7aa2079ac640>"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:52:07.433605Z","iopub.status.busy":"2024-03-10T13:52:07.433103Z","iopub.status.idle":"2024-03-10T13:52:07.519434Z","shell.execute_reply":"2024-03-10T13:52:07.518510Z","shell.execute_reply.started":"2024-03-10T13:52:07.433576Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["37868 37868 300 128\n","Input shape: torch.Size([32, 68])\n","Label shape: torch.Size([32, 68])\n","Output shape: torch.Size([32, 68, 27])\n","Hidden shape: torch.Size([1, 32, 128])\n","\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/532150329.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  word_vectors = torch.tensor(word_vectors)\n"]}],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\\nHidden shape: {hidden.size()}\\n\")\n","    break"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:52:07.521768Z","iopub.status.busy":"2024-03-10T13:52:07.521053Z","iopub.status.idle":"2024-03-10T13:52:07.533250Z","shell.execute_reply":"2024-03-10T13:52:07.531668Z","shell.execute_reply.started":"2024-03-10T13:52:07.521734Z"},"trusted":true},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T13:52:07.537123Z","iopub.status.busy":"2024-03-10T13:52:07.535969Z","iopub.status.idle":"2024-03-10T14:25:55.001096Z","shell.execute_reply":"2024-03-10T14:25:54.999777Z","shell.execute_reply.started":"2024-03-10T13:52:07.537086Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [33:47<00:00, 20.27s/it]\n"]}],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:25:55.003649Z","iopub.status.busy":"2024-03-10T14:25:55.002804Z","iopub.status.idle":"2024-03-10T14:25:55.849678Z","shell.execute_reply":"2024-03-10T14:25:55.847512Z","shell.execute_reply.started":"2024-03-10T14:25:55.003605Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.9527\n","Test precision: 0.9514\n","Test macro F1: 0.5482\n","Test loss: 12.0151\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.98     57483\n","           1       0.48      0.43      0.45       121\n","           2       0.63      0.53      0.58       344\n","           3       0.34      0.32      0.33       159\n","           4       0.50      0.40      0.44       310\n","           5       0.57      0.53      0.55       276\n","           6       0.59      0.52      0.55       195\n","           7       0.64      0.65      0.65       222\n","           8       0.79      0.68      0.73       383\n","           9       0.86      0.88      0.87       258\n","          10       0.88      0.76      0.81       439\n","          11       0.81      0.75      0.78       178\n","          12       0.83      0.70      0.76       326\n","          13       0.35      0.50      0.41        58\n","          14       0.49      0.47      0.48       177\n","          15       0.84      0.69      0.76      1793\n","          16       0.73      0.81      0.77       222\n","          17       0.21      0.44      0.29         9\n","          18       0.35      0.55      0.43        11\n","          19       0.40      0.39      0.40        54\n","          20       0.48      0.51      0.50       183\n","          21       0.21      0.60      0.32         5\n","          22       0.17      0.33      0.22         9\n","          23       0.66      0.76      0.71       102\n","          24       0.19      0.50      0.28         8\n","          25       0.38      0.71      0.50         7\n","          26       0.28      0.26      0.27        47\n","\n","    accuracy                           0.95     63379\n","   macro avg       0.54      0.58      0.55     63379\n","weighted avg       0.95      0.95      0.95     63379\n","\n"]}],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:25:55.851722Z","iopub.status.busy":"2024-03-10T14:25:55.851258Z","iopub.status.idle":"2024-03-10T14:26:00.842964Z","shell.execute_reply":"2024-03-10T14:26:00.841890Z","shell.execute_reply.started":"2024-03-10T14:25:55.851651Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Test loss</td><td>▁</td></tr><tr><td>Test macro F1</td><td>▁</td></tr><tr><td>Test precision</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_acc</td><td>▁▃▄▅▅▄▆▆▆▇▆▆▆▆▇▇▇███████████▇▇████████▇█</td></tr><tr><td>minibatch_epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_f1</td><td>▁▄▅▅▅▅▆▇▆▇▆▇▆▇▇█▇████████████▇██████████</td></tr><tr><td>minibatch_loss</td><td>█▆▄▄▃▄▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇██████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇▇██████▇▇▇▇▇▇▇▇▇▆▇▇▇▆▆▆▇▆▇▆▆▇▆▇▆▇▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▅▆▆▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▆▂▂▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▅▆▅▆▆▆▆▇▆▇▇▇▇███▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.95267</td></tr><tr><td>Test loss</td><td>12.01513</td></tr><tr><td>Test macro F1</td><td>0.54819</td></tr><tr><td>Test precision</td><td>0.95142</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>minibatch_acc</td><td>0.99774</td></tr><tr><td>minibatch_epoch</td><td>25099</td></tr><tr><td>minibatch_f1</td><td>0.99747</td></tr><tr><td>minibatch_loss</td><td>0.00808</td></tr><tr><td>train_acc</td><td>0.99877</td></tr><tr><td>train_f1</td><td>0.98755</td></tr><tr><td>train_loss</td><td>1.1196</td></tr><tr><td>val_acc</td><td>0.95793</td></tr><tr><td>val_f1</td><td>0.55559</td></tr><tr><td>val_loss</td><td>15.17349</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">denim-monkey-30</strong> at: <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/y99dqwt4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240310_135130-y99dqwt4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:26:00.921297Z","iopub.status.busy":"2024-03-10T14:26:00.920528Z","iopub.status.idle":"2024-03-10T14:26:00.990273Z","shell.execute_reply":"2024-03-10T14:26:00.989120Z","shell.execute_reply.started":"2024-03-10T14:26:00.921260Z"},"trusted":true},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model3_word2vec.pth')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Task 1: LSTM + Word2Vec"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:30:31.295873Z","iopub.status.busy":"2024-03-10T14:30:31.295403Z","iopub.status.idle":"2024-03-10T14:31:04.885752Z","shell.execute_reply":"2024-03-10T14:31:04.884226Z","shell.execute_reply.started":"2024-03-10T14:30:31.295841Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["import tqdm\n","import wandb\n","wandb.login(relogin=True)"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:31:26.324020Z","iopub.status.busy":"2024-03-10T14:31:26.323564Z","iopub.status.idle":"2024-03-10T14:31:26.331166Z","shell.execute_reply":"2024-03-10T14:31:26.329861Z","shell.execute_reply.started":"2024-03-10T14:31:26.323988Z"},"trusted":true},"outputs":[],"source":["model_config = dict(\n","    task = 1, \n","    model = 'LSTM',\n","    embed_size = 300,\n","    embedding = 'Word2Vec',\n","    hidden_size = 128,\n","    learning_rate = 0.001,\n","    batch_size = 32,\n","    epochs = 100, \n","    padding = 'max_post', \n","    loss = 'CrossEntropyLoss',\n","    optimizer = 'Adam',\n","    num_hidden = 1,\n","    dropout = 0, \n","    activation = 'tanh'\n",")"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:31:36.384875Z","iopub.status.busy":"2024-03-10T14:31:36.384403Z","iopub.status.idle":"2024-03-10T14:32:08.291097Z","shell.execute_reply":"2024-03-10T14:32:08.290144Z","shell.execute_reply.started":"2024-03-10T14:31:36.384841Z"},"trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.16.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240310_143136-gwfjrogd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd' target=\"_blank\">generous-leaf-31</a></strong> to <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/nlp-assignments/assignment-2' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7aa207ac2c80>"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"assignment-2\", entity=\"nlp-assignments\", config=model_config)"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:32:08.293730Z","iopub.status.busy":"2024-03-10T14:32:08.293064Z","iopub.status.idle":"2024-03-10T14:32:08.520550Z","shell.execute_reply":"2024-03-10T14:32:08.519278Z","shell.execute_reply.started":"2024-03-10T14:32:08.293680Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/36252246.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  word_vectors = torch.tensor(word_vectors)\n"]},{"name":"stdout","output_type":"stream","text":["37868 37868 300 128\n","Input shape: torch.Size([32, 68])\n","Label shape: torch.Size([32, 68])\n","Output shape: torch.Size([32, 68, 27])\n"]}],"source":["# Initialize the model\n","vocab_size = len(word_to_index)\n","embed_size = model_config['embed_size'] # Size of the word embeddings\n","hidden_size = model_config['hidden_size'] # Size of the hidden state\n","word_vectors = torch.tensor(word_vectors)\n","word_vectors = word_vectors.float()\n","print(vocab_size, len(word_vectors), embed_size, hidden_size)\n","model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n","for i, data in enumerate(train_dataloader, 0):\n","    text = data['text']\n","    print(f\"Input shape: {text.size()}\")\n","    print(f\"Label shape: {data['labels'].size()}\")\n","    output, hidden = model(text)\n","    print(f\"Output shape: {output.size()}\")\n","    break"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:32:08.523101Z","iopub.status.busy":"2024-03-10T14:32:08.522230Z","iopub.status.idle":"2024-03-10T14:32:08.538042Z","shell.execute_reply":"2024-03-10T14:32:08.536522Z","shell.execute_reply.started":"2024-03-10T14:32:08.523057Z"},"trusted":true},"outputs":[],"source":["# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T14:32:08.542263Z","iopub.status.busy":"2024-03-10T14:32:08.541181Z","iopub.status.idle":"2024-03-10T15:07:30.086575Z","shell.execute_reply":"2024-03-10T15:07:30.085421Z","shell.execute_reply.started":"2024-03-10T14:32:08.542213Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [35:21<00:00, 21.22s/it]\n"]}],"source":["model = train_model(model, train_dataloader, val_dataloader, criterion, optimizer, model_config)"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T15:07:30.089290Z","iopub.status.busy":"2024-03-10T15:07:30.088812Z","iopub.status.idle":"2024-03-10T15:07:30.990131Z","shell.execute_reply":"2024-03-10T15:07:30.988745Z","shell.execute_reply.started":"2024-03-10T15:07:30.089247Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.9531\n","Test precision: 0.9504\n","Test macro F1: 0.5455\n","Test loss: 10.7841\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98     57483\n","           1       0.41      0.30      0.34       121\n","           2       0.63      0.48      0.55       344\n","           3       0.37      0.31      0.34       159\n","           4       0.48      0.32      0.38       310\n","           5       0.58      0.58      0.58       276\n","           6       0.58      0.57      0.58       195\n","           7       0.73      0.65      0.69       222\n","           8       0.80      0.67      0.73       383\n","           9       0.87      0.86      0.87       258\n","          10       0.87      0.74      0.80       439\n","          11       0.86      0.77      0.81       178\n","          12       0.85      0.75      0.80       326\n","          13       0.45      0.40      0.42        58\n","          14       0.49      0.41      0.45       177\n","          15       0.83      0.67      0.74      1793\n","          16       0.82      0.80      0.81       222\n","          17       0.25      0.56      0.34         9\n","          18       0.43      0.55      0.48        11\n","          19       0.55      0.39      0.46        54\n","          20       0.47      0.51      0.49       183\n","          21       0.20      0.40      0.27         5\n","          22       0.14      0.22      0.17         9\n","          23       0.62      0.69      0.65       102\n","          24       0.21      0.62      0.31         8\n","          25       0.21      0.57      0.31         7\n","          26       0.39      0.36      0.37        47\n","\n","    accuracy                           0.95     63379\n","   macro avg       0.56      0.56      0.55     63379\n","weighted avg       0.95      0.95      0.95     63379\n","\n"]}],"source":["accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n","print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n","print(f\"Classification report:\\n{classification_report}\")\n","wandb.log({\"Test accuracy\": accuracy, \"Test precision\": precision, \"Test macro F1\": macro_f1, \"Test loss\": loss})"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T15:07:30.991956Z","iopub.status.busy":"2024-03-10T15:07:30.991501Z","iopub.status.idle":"2024-03-10T15:07:39.179897Z","shell.execute_reply":"2024-03-10T15:07:39.178916Z","shell.execute_reply.started":"2024-03-10T15:07:30.991923Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Test loss</td><td>▁</td></tr><tr><td>Test macro F1</td><td>▁</td></tr><tr><td>Test precision</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_acc</td><td>▁▅▄▄▄▆▅▃▅▆▅▆▆▆▆▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>minibatch_epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>minibatch_f1</td><td>▁▅▅▅▄▇▆▄▆▇▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>minibatch_loss</td><td>█▄▄▄▅▂▃▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▅▆▆▆▇▇████████████████▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test accuracy</td><td>0.95312</td></tr><tr><td>Test loss</td><td>10.78413</td></tr><tr><td>Test macro F1</td><td>0.54553</td></tr><tr><td>Test precision</td><td>0.95039</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>minibatch_acc</td><td>1.0</td></tr><tr><td>minibatch_epoch</td><td>25099</td></tr><tr><td>minibatch_f1</td><td>1.0</td></tr><tr><td>minibatch_loss</td><td>0.00152</td></tr><tr><td>train_acc</td><td>0.99895</td></tr><tr><td>train_f1</td><td>0.98898</td></tr><tr><td>train_loss</td><td>1.23548</td></tr><tr><td>val_acc</td><td>0.95881</td></tr><tr><td>val_f1</td><td>0.55594</td></tr><tr><td>val_loss</td><td>13.18905</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">generous-leaf-31</strong> at: <a href='https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-2/runs/gwfjrogd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240310_143136-gwfjrogd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T15:07:39.182552Z","iopub.status.busy":"2024-03-10T15:07:39.181770Z","iopub.status.idle":"2024-03-10T15:07:39.252000Z","shell.execute_reply":"2024-03-10T15:07:39.250787Z","shell.execute_reply.started":"2024-03-10T15:07:39.182515Z"},"trusted":true},"outputs":[],"source":["# saving the model\n","torch.save(model.state_dict(), 't1_model2_word2vec.pth')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4567922,"sourceId":7801151,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
