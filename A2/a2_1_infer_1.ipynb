{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import GloVe\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Laptop_Review_Train.json') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Laptop_Review_Val.json') as f:\n",
    "    val_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Laptop_Review_Test.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_label_encoding(tokens, aspects):\n",
    "    labels = ['O'] * len(tokens)\n",
    "    for aspect in aspects: \n",
    "        start = aspect['from']\n",
    "        end = aspect['to']\n",
    "        labels[start] = 'B'\n",
    "        for i in range(start+1, end):\n",
    "            labels[i] = 'I'\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio(data):\n",
    "    processed_data = {}\n",
    "    for i in range(len(data)):\n",
    "        words = data[i]['words']\n",
    "        text = data[i]['raw_words']\n",
    "        aspects = data[i]['aspects']\n",
    "        labels = bio_label_encoding(words, aspects)\n",
    "        processed_data[i] = {\n",
    "            'text': text,\n",
    "            'labels': labels\n",
    "        }\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = convert_to_bio(train_data)\n",
    "processed_val_data = convert_to_bio(val_data)\n",
    "processed_test_data = convert_to_bio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the processed data\n",
    "with open('ATE_train.json', 'w') as f:\n",
    "    json.dump(processed_train_data, f, indent=4)\n",
    "with open('ATE_val.json', 'w') as f:\n",
    "    json.dump(processed_val_data, f, indent=4)\n",
    "with open('ATE_test.json', 'w') as f:\n",
    "    json.dump(processed_test_data, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ATE_train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('ATE_val.json') as f:\n",
    "    val_data = json.load(f)\n",
    "with open('ATE_test.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting data distribution of number of tokens in each sentence\n",
    "import matplotlib.pyplot as plt\n",
    "label_counts = []\n",
    "for key in train_data.keys():\n",
    "    label_counts.append(len(train_data[key]['labels']))\n",
    "plt.hist(label_counts, bins=30, alpha=0.5, color='b', edgecolor='black', linewidth=1.2, histtype='bar', align='mid', orientation='vertical', rwidth=0.8, label='Number of tokens')\n",
    "plt.title('Distribution of number of tokens in each sentence')\n",
    "plt.xlabel('Number of tokens')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = [], [], []\n",
    "for i in train_data:\n",
    "    train.append([train_data[i]['text'], train_data[i]['labels']])\n",
    "for i in val_data:\n",
    "    val.append([val_data[i]['text'], val_data[i]['labels']])\n",
    "for i in test_data:\n",
    "    test.append([test_data[i]['text'], test_data[i]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 3495\n",
      "Words and their counts: [('I', 637), ('charge', 10), ('it', 499), ('at', 70), ('night', 5)]\n"
     ]
    }
   ],
   "source": [
    "data = train + val + test\n",
    "# Finding number of unique words in the dataset\n",
    "word_count = {}\n",
    "for i in range(len(data)):\n",
    "    words = data[i][0].split()\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "print(f\"Number of unique words in the dataset: {len(word_count)}\")\n",
    "print(f\"Words and their counts: {list(word_count.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset after adding 'PAD' and 'UNK': 3497\n"
     ]
    }
   ],
   "source": [
    "word_list = list(word_count.keys())\n",
    "# adding 'PAD' and 'UNK' to the word list\n",
    "word_list.append('PAD')\n",
    "word_list.append('UNK')\n",
    "word_count['PAD'] = 0\n",
    "word_count['UNK'] = 0\n",
    "print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-to-index: [('I', 0), ('charge', 1), ('it', 2), ('at', 3), ('night', 4)]\n",
      "Index-to-word: [(0, 'I'), (1, 'charge'), (2, 'it'), (3, 'at'), (4, 'night')]\n"
     ]
    }
   ],
   "source": [
    "# Word-to-index and index-to-word mapping from the dataset\n",
    "word_to_index = {word:idx for idx, word in enumerate(word_list)}\n",
    "index_to_word = {idx:word for word, idx in word_to_index.items()}\n",
    "label_to_idx = {'O': 0, 'B': 1, 'I': 2}\n",
    "print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n",
    "print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word_embeddings: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "glove_vectors = GloVe(name='6B', dim=300)\n",
    "word_embeddings = np.zeros((len(word_list), 300))\n",
    "for i in range(len(word_list)):\n",
    "    word = word_list[i]\n",
    "    idx = word_to_index[word]\n",
    "    if word in glove_vectors.stoi:\n",
    "        word_embeddings[idx] = glove_vectors[word]\n",
    "    else:\n",
    "        word_embeddings[idx] = glove_vectors['unk']\n",
    "print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "        Padding the sequences to the maximum length sequence in the batch\n",
    "        Args:\n",
    "            batch: list of individual elements of the dataset\n",
    "        Returns:\n",
    "            {'text' : padded_texts, 'labels' : padded_labels}\n",
    "    \"\"\"\n",
    "    texts, labels = [item['text'] for item in batch], [item['labels'] for item in batch]\n",
    "    max_len = max([len(text) for text in texts])\n",
    "    padded_texts, padded_labels = [], []\n",
    "    for i in range(len(texts)):\n",
    "        text, label = texts[i], labels[i]\n",
    "        # padding text and label sequences\n",
    "        text = text + [word_to_index['PAD']] * (max_len - len(text))\n",
    "        label = label + [label_to_idx['O']] * (max_len - len(label))\n",
    "        padded_texts.append(text)\n",
    "        padded_labels.append(label)\n",
    "    return {'text': torch.tensor(padded_texts), 'labels': torch.tensor(padded_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaptopReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Custom Dataset to load the Laptop Review dataset\n",
    "        Args:\n",
    "            data: list of tuples (text, labels)\n",
    "            vocab_size: size of the vocabulary\n",
    "            embedding_size: size of the word embeddings\n",
    "            word_to_index: word-to-index mapping\n",
    "            index_to_word: index-to-word mapping\n",
    "            label_to_idx: label-to-index mapping\n",
    "    \"\"\"\n",
    "    def __init__(self, data, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx):\n",
    "        self.data = data\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = index_to_word\n",
    "        self.label_to_idx = label_to_idx \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text, labels = self.data[idx][0], self.data[idx][1]\n",
    "        words = text.split()\n",
    "        # converting words and labels to indices\n",
    "        word_indices = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index['UNK'] for word in words]\n",
    "        label_indices = [self.label_to_idx[label] for label in labels]\n",
    "        sample = {'text' : word_indices, 'labels' : label_indices}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LaptopReviewDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            text, labels = data['text'], data['labels']\n",
    "            output, hidden = model(text)\n",
    "            output = output.view(-1, 3)\n",
    "            labels = labels.view(-1)\n",
    "            loss += criterion(output, labels).item()\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += torch.argmax(output, 1).tolist()\n",
    "    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return accuracy, macro_f1, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            text, labels = data['text'], data['labels']\n",
    "            outputs, hidden = model(text)\n",
    "            outputs = outputs.view(-1, 3)\n",
    "            labels = labels.view(-1)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += torch.argmax(outputs, 1).tolist()\n",
    "    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    from sklearn.metrics import classification_report\n",
    "    classification_report = classification_report(y_true, y_pred)\n",
    "    return accuracy, precision, macro_f1, loss, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "        Model architecture to perform Sequence Labeling on the Laptop Review dataset. RNN, LSTM or GRU model is initialized based on the model configuration parameters.\n",
    "        Args: \n",
    "            vocab_size: size of the vocabulary\n",
    "            embed_size: size of the word embeddings\n",
    "            hidden_size: size of the hidden state\n",
    "            pretrained_embeddings: pre-trained word embeddings\n",
    "            model_config: dictionary containing model configuration parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, pretrained_embeddings, model_config):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings=pretrained_embeddings, freeze=True)\n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], nonlinearity=model_config['activation'], batch_first=True, dropout=model_config['dropout'])\n",
    "        if (model_config['model'] == 'LSTM'):\n",
    "            self.rnn = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n",
    "        if (model_config['model'] == 'GRU'):\n",
    "            self.rnn = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n",
    "        self.fc = nn.Linear(hidden_size, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + GloVe for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2112311114.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model1_glove.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9653\n",
      "Test precision: 0.9603\n",
      "Test macro F1: 0.6546\n",
      "Test loss: 2.5851\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.65      0.49      0.56       463\n",
      "           2       0.63      0.32      0.42       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.75      0.60      0.65     15480\n",
      "weighted avg       0.96      0.97      0.96     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model1_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + GloVe for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\531312971.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3100204358.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model2_glove.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9651\n",
      "Test precision: 0.9609\n",
      "Test macro F1: 0.6636\n",
      "Test loss: 2.5930\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.62      0.52      0.57       463\n",
      "           2       0.65      0.33      0.44       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.75      0.61      0.66     15480\n",
      "weighted avg       0.96      0.97      0.96     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model2_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU + GloVe for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\1939184259.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3727799638.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model3_glove.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9691\n",
      "Test precision: 0.9649\n",
      "Test macro F1: 0.6841\n",
      "Test loss: 2.2265\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14774\n",
      "           1       0.70      0.52      0.60       463\n",
      "           2       0.72      0.35      0.47       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.80      0.62      0.68     15480\n",
      "weighted avg       0.96      0.97      0.97     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\GloVe\\\\t2_model3_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: RNN + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = [], [], []\n",
    "for i in train_data:\n",
    "    train.append([train_data[i]['text'], train_data[i]['labels']])\n",
    "for i in val_data:\n",
    "    val.append([val_data[i]['text'], val_data[i]['labels']])\n",
    "for i in test_data:\n",
    "    test.append([test_data[i]['text'], test_data[i]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 906\n",
      "Validation data size: 219\n",
      "Test data size: 328\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size: {len(train)}')\n",
    "print(f'Validation data size: {len(val)}')\n",
    "print(f'Test data size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 3495\n",
      "Words and their counts: [('I', 637), ('charge', 10), ('it', 499), ('at', 70), ('night', 5)]\n"
     ]
    }
   ],
   "source": [
    "data = train + val + test\n",
    "# Finding number of unique words in the dataset\n",
    "word_count = {}\n",
    "for i in range(len(data)):\n",
    "    words = data[i][0].split()\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "print(f\"Number of unique words in the dataset: {len(word_count)}\")\n",
    "print(f\"Words and their counts: {list(word_count.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset after adding 'PAD' and 'UNK': 3497\n"
     ]
    }
   ],
   "source": [
    "word_list = list(word_count.keys())\n",
    "# adding 'PAD' and 'UNK' to the word list\n",
    "word_list.append('PAD')\n",
    "word_list.append('UNK')\n",
    "word_count['PAD'] = 0\n",
    "word_count['UNK'] = 0\n",
    "print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-to-index: [('I', 0), ('charge', 1), ('it', 2), ('at', 3), ('night', 4)]\n",
      "Index-to-word: [(0, 'I'), (1, 'charge'), (2, 'it'), (3, 'at'), (4, 'night')]\n"
     ]
    }
   ],
   "source": [
    "# Word-to-index and index-to-word mapping from the dataset\n",
    "word_to_index = {word:idx for idx, word in enumerate(word_list)}\n",
    "index_to_word = {idx:word for word, idx in word_to_index.items()}\n",
    "label_to_idx = {'O': 0, 'B': 1, 'I': 2}\n",
    "print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n",
    "print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word embeddings: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import torch\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Load word embeddings\n",
    "word_embeddings = []\n",
    "for word in word_list:\n",
    "    try:\n",
    "        word_embeddings.append(wv[word])\n",
    "    except:\n",
    "        word_embeddings.append(wv['unk'])\n",
    "word_embeddings = np.array(word_embeddings)\n",
    "print(f\"Shape of word embeddings: {word_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497 3497 300 128\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()\n",
    "print(vocab_size, len(word_vectors), embed_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9661\n",
      "Test precision: 0.9633\n",
      "Test macro F1: 0.6907\n",
      "Test loss: 2.8735\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.62      0.58      0.60       463\n",
      "           2       0.64      0.39      0.49       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.75      0.65      0.69     15480\n",
      "weighted avg       0.96      0.97      0.96     15480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2393678249.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model1_word2vec.pth\"\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model1_word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: GRU + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3104698454.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model3_word2vec.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9705\n",
      "Test precision: 0.9680\n",
      "Test macro F1: 0.7259\n",
      "Test loss: 2.6822\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14774\n",
      "           1       0.70      0.64      0.67       463\n",
      "           2       0.69      0.42      0.53       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.79      0.68      0.73     15480\n",
      "weighted avg       0.97      0.97      0.97     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model3_word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: LSTM + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9702\n",
      "Test precision: 0.9681\n",
      "Test macro F1: 0.7210\n",
      "Test loss: 2.3645\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14774\n",
      "           1       0.67      0.65      0.66       463\n",
      "           2       0.71      0.40      0.51       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.79      0.68      0.72     15480\n",
      "weighted avg       0.97      0.97      0.97     15480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\1822750133.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model2_word2vec.pth\"\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Word2vec\\\\t2_model2_word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: RNN + FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\wiki.en.vec: 6.60GB [10:09, 10.8MB/s]                               \n",
      "  0%|          | 0/2519370 [00:00<?, ?it/s]Skipping token b'2519370' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|| 2519370/2519370 [06:38<00:00, 6315.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word_embeddings: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import FastText\n",
    "fasttext_vectors = FastText(language=\"en\")\n",
    "word_embeddings = np.zeros((len(word_list), 300))\n",
    "for i in range(len(word_list)):\n",
    "    word = word_list[i]\n",
    "    idx = word_to_index[word]\n",
    "    if word in glove_vectors.stoi:\n",
    "        word_embeddings[idx] = fasttext_vectors[word]\n",
    "    else:\n",
    "        word_embeddings[idx] = fasttext_vectors['unk']\n",
    "print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (3497, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LaptopReviewDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497 3497 300 128\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()\n",
    "print(vocab_size, len(word_vectors), embed_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9640\n",
      "Test precision: 0.9585\n",
      "Test macro F1: 0.6402\n",
      "Test loss: 2.4762\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     14774\n",
      "           1       0.63      0.48      0.54       463\n",
      "           2       0.58      0.30      0.40       243\n",
      "\n",
      "    accuracy                           0.96     15480\n",
      "   macro avg       0.73      0.59      0.64     15480\n",
      "weighted avg       0.96      0.96      0.96     15480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2128703935.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model1_fasttext.pth\"\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model1_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2677083102.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model3_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9686\n",
      "Test precision: 0.9650\n",
      "Test macro F1: 0.6925\n",
      "Test loss: 2.3416\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.67      0.56      0.61       463\n",
      "           2       0.71      0.37      0.48       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.79      0.64      0.69     15480\n",
      "weighted avg       0.97      0.97      0.97     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model3_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: LSTM + FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3628936752.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model2_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9670\n",
      "Test precision: 0.9625\n",
      "Test macro F1: 0.6696\n",
      "Test loss: 2.5365\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.67      0.53      0.59       463\n",
      "           2       0.64      0.33      0.43       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.76      0.62      0.67     15480\n",
      "weighted avg       0.96      0.97      0.96     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model2_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: GRU + FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 2, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2677083102.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model3_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9686\n",
      "Test precision: 0.9650\n",
      "Test macro F1: 0.6925\n",
      "Test loss: 2.3416\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     14774\n",
      "           1       0.67      0.56      0.61       463\n",
      "           2       0.71      0.37      0.48       243\n",
      "\n",
      "    accuracy                           0.97     15480\n",
      "   macro avg       0.79      0.64      0.69     15480\n",
      "weighted avg       0.97      0.97      0.97     15480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 2\\Fasttext\\\\t2_model3_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER_TRAIN_JUDGEMENT.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER_TEST_JUDGEMENT.json') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG', 'JUDGE', 'STATUTE', 'WITNESS', 'COURT', 'PETITIONER', 'CASE_NUMBER', 'DATE', 'GPE', 'RESPONDENT', 'PRECEDENT', 'OTHER_PERSON', 'PROVISION'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for i in range(len(data)):\n",
    "    for annotation in data[i]['annotations'][0]['result']:\n",
    "        label = annotation['value']['labels'][0]\n",
    "        unique_labels.add(label)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    special_chars = ['\\x05', '\\t', '\\n', '\\x0c', '\\x11', '\\x12', '\\x13', '\\x14', '\\x16', '\\x1a', '\\x80', '\\x9d', '\\xa0', '\\xad', '\\uf076']\n",
    "    for char in special_chars:\n",
    "        text = text.replace(char, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_index(annotations):\n",
    "    border_indices = []\n",
    "    for annotation in annotations[0]['result']:\n",
    "        start = annotation['value']['start']\n",
    "        end = annotation['value']['end']\n",
    "        label = annotation['value']['labels'][0]\n",
    "        label = label.upper()\n",
    "        border_indices.append([start, end, label])\n",
    "    border_indices.sort(key=lambda x: x[0])\n",
    "    return border_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_spacing(text, border_indices):\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        for border in border_indices:\n",
    "            if (i==border[0] or i==border[1]):\n",
    "                index = border_indices.index(border)\n",
    "                if (i==border[0] and i!=0 and text[i-1]!=' '):\n",
    "                    text = text[:i] + ' ' + text[i:]\n",
    "                    for j in range(index, len(border_indices)):\n",
    "                        if border_indices[j][0] >= i:\n",
    "                            border_indices[j][0] += 1\n",
    "                        if border_indices[j][1] >= i:\n",
    "                            border_indices[j][1] += 1\n",
    "                if (i==border[1] and i!=len(text)-1 and text[i]!=' '):\n",
    "                    text = text[:i] + ' ' + text[i:]\n",
    "                    for j in range(index, len(border_indices)):\n",
    "                        if border_indices[j][0] >= i:\n",
    "                            border_indices[j][0] += 1\n",
    "                        if border_indices[j][1] >= i:\n",
    "                            border_indices[j][1] += 1\n",
    "                i += 1\n",
    "        i += 1\n",
    "    return text, border_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_encoding(text, border_indices):\n",
    "    tokens = text.split()\n",
    "    labels = ['O'] * len(tokens)\n",
    "    for annotation in border_indices:\n",
    "        start = annotation[0]\n",
    "        end = annotation[1]\n",
    "        label = annotation[2]\n",
    "        label = label.upper()\n",
    "        label_start_token = None\n",
    "        label_end_token = None\n",
    "        curr_token_index = 0\n",
    "        i = 0\n",
    "        while (i < len(text)):\n",
    "            if (text[i] == ' '):\n",
    "                i += 1\n",
    "            else:\n",
    "                curr_word = ''\n",
    "                if (i == start):\n",
    "                    label_start_token = curr_token_index\n",
    "                    while (i < end):\n",
    "                        current_word = ''\n",
    "                        if (text[i] == ' '):\n",
    "                            while (text[i] == ' '):\n",
    "                                i += 1\n",
    "                        else: \n",
    "                            while (i < len(text) and text[i] != ' '):\n",
    "                                current_word += text[i]\n",
    "                                i += 1\n",
    "                            if (tokens[curr_token_index] == current_word):\n",
    "                                curr_token_index += 1\n",
    "                    label_end_token = curr_token_index\n",
    "                else: \n",
    "                    while (i < len(text) and text[i] != ' '):\n",
    "                        curr_word += text[i]\n",
    "                        i += 1\n",
    "                    if (tokens[curr_token_index] == curr_word):\n",
    "                        curr_token_index += 1\n",
    "        if (label_end_token == None):\n",
    "            label_end_token = len(tokens) - 1\n",
    "        if (label_start_token == None):\n",
    "            continue\n",
    "        for i in range(label_start_token, label_end_token):\n",
    "            if i == label_start_token:\n",
    "                labels[i] = 'B_' + label\n",
    "            else:\n",
    "                labels[i] = 'I_' + label\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio(data):\n",
    "    processed_data = {}\n",
    "    for i in range(len(data)):\n",
    "        id = data[i]['id']\n",
    "        annotations = data[i]['annotations']\n",
    "        text = data[i]['data']['text']\n",
    "        text = clean_text(text)\n",
    "        border_indices = border_index(annotations)\n",
    "        text, border_indices = border_spacing(text, border_indices)\n",
    "        labels = bio_encoding(text, border_indices)\n",
    "        processed_data[id] = {'text': text, 'labels': labels}\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = convert_to_bio(train)\n",
    "processed_val = convert_to_bio(val)\n",
    "processed_test = convert_to_bio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the processed data\n",
    "with open('NER_train.json', 'w') as file:\n",
    "    json.dump(processed_train, file, indent=4)\n",
    "with open('NER_val.json', 'w') as file:\n",
    "    json.dump(processed_val, file, indent=4)\n",
    "with open('NER_test.json', 'w') as file:\n",
    "    json.dump(processed_test, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER_train.json') as file:\n",
    "    train_data = json.load(file)\n",
    "with open('NER_val.json') as file:\n",
    "    val_data = json.load(file)\n",
    "with open('NER_test.json') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting data distribution of number of tokens in each sentence\n",
    "import matplotlib.pyplot as plt\n",
    "label_counts = []\n",
    "for key in train_data.keys():\n",
    "    label_counts.append(len(train_data[key]['labels']))\n",
    "plt.hist(label_counts, bins=30, alpha=0.5, color='b', edgecolor='black', linewidth=1.2, histtype='bar', align='mid', orientation='vertical', rwidth=0.8, label='Number of tokens')\n",
    "plt.title('Distribution of number of tokens in each sentence')\n",
    "plt.xlabel('Number of tokens')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = [], [], []\n",
    "for i in train_data:\n",
    "    train.append([train_data[i]['text'], train_data[i]['labels']])\n",
    "for i in val_data:\n",
    "    val.append([val_data[i]['text'], val_data[i]['labels']])\n",
    "for i in test_data:\n",
    "    test.append([test_data[i]['text'], test_data[i]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 8019\n",
      "Validation data size: 1416\n",
      "Test data size: 949\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size: {len(train)}')\n",
    "print(f'Validation data size: {len(val)}')\n",
    "print(f'Test data size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 37866\n",
      "Words and their counts: [('Therefore,', 97), ('while', 164), ('interpreting', 6), ('statutory', 76), ('provisions,', 10)]\n"
     ]
    }
   ],
   "source": [
    "data = train + val + test\n",
    "# Finding number of unique words in the dataset\n",
    "word_count = {}\n",
    "for i in range(len(data)):\n",
    "    words = data[i][0].split()\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "print(f\"Number of unique words in the dataset: {len(word_count)}\")\n",
    "print(f\"Words and their counts: {list(word_count.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset after adding 'PAD' and 'UNK': 37868\n"
     ]
    }
   ],
   "source": [
    "word_list = list(word_count.keys())\n",
    "# adding 'PAD' and 'UNK' to the word list\n",
    "word_list.append('PAD')\n",
    "word_list.append('UNK')\n",
    "word_count['PAD'] = 0\n",
    "word_count['UNK'] = 0\n",
    "print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-to-index: [('Therefore,', 0), ('while', 1), ('interpreting', 2), ('statutory', 3), ('provisions,', 4)]\n",
      "Index-to-word: [(0, 'Therefore,'), (1, 'while'), (2, 'interpreting'), (3, 'statutory'), (4, 'provisions,')]\n"
     ]
    }
   ],
   "source": [
    "# Word-to-index and index-to-word mapping from the dataset\n",
    "word_to_index = {word:idx for idx, word in enumerate(word_list)}\n",
    "index_to_word = {idx:word for word, idx in word_to_index.items()}\n",
    "print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n",
    "print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in the dataset: 27\n",
      "Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n",
      "Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n",
      "Label-to-index: [('O', 0), ('B_CASE_NUMBER', 1), ('I_CASE_NUMBER', 2), ('B_ORG', 3), ('I_ORG', 4), ('B_OTHER_PERSON', 5), ('I_OTHER_PERSON', 6), ('B_STATUTE', 7), ('I_STATUTE', 8), ('B_PROVISION', 9), ('I_PROVISION', 10), ('B_COURT', 11), ('I_COURT', 12), ('B_WITNESS', 13), ('B_PRECEDENT', 14), ('I_PRECEDENT', 15), ('B_DATE', 16), ('B_PETITIONER', 17), ('I_PETITIONER', 18), ('I_WITNESS', 19), ('B_GPE', 20), ('B_RESPONDENT', 21), ('I_RESPONDENT', 22), ('I_DATE', 23), ('B_JUDGE', 24), ('I_JUDGE', 25), ('I_GPE', 26)]\n",
      "Index-to-label: [(0, 'O'), (1, 'B_CASE_NUMBER'), (2, 'I_CASE_NUMBER'), (3, 'B_ORG'), (4, 'I_ORG'), (5, 'B_OTHER_PERSON'), (6, 'I_OTHER_PERSON'), (7, 'B_STATUTE'), (8, 'I_STATUTE'), (9, 'B_PROVISION'), (10, 'I_PROVISION'), (11, 'B_COURT'), (12, 'I_COURT'), (13, 'B_WITNESS'), (14, 'B_PRECEDENT'), (15, 'I_PRECEDENT'), (16, 'B_DATE'), (17, 'B_PETITIONER'), (18, 'I_PETITIONER'), (19, 'I_WITNESS'), (20, 'B_GPE'), (21, 'B_RESPONDENT'), (22, 'I_RESPONDENT'), (23, 'I_DATE'), (24, 'B_JUDGE'), (25, 'I_JUDGE'), (26, 'I_GPE')]\n"
     ]
    }
   ],
   "source": [
    "# finding all the unique labels in the dataset\n",
    "label_count = {}\n",
    "for i in range(len(data)):\n",
    "    labels = data[i][1]\n",
    "    for label in labels:\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 1\n",
    "        else:\n",
    "            label_count[label] += 1\n",
    "print(f\"Number of unique labels in the dataset: {len(label_count)}\")\n",
    "print(f\"Labels and their counts: {list(label_count.items())}\")\n",
    "print(f\"Labels and their counts: {list(label_count.items())}\")\n",
    "label_to_idx = {label:idx for idx, label in enumerate(label_count.keys())}\n",
    "idx_to_label = {idx:label for label, idx in label_to_idx.items()}\n",
    "print(f\"Label-to-index: {list(label_to_idx.items())}\")\n",
    "print(f\"Index-to-label: {list(idx_to_label.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word_embeddings: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "glove_vectors = GloVe(name='6B', dim=300)\n",
    "word_embeddings = np.zeros((len(word_list), 300))\n",
    "for i in range(len(word_list)):\n",
    "    word = word_list[i]\n",
    "    idx = word_to_index[word]\n",
    "    if word in glove_vectors.stoi:\n",
    "        word_embeddings[idx] = glove_vectors[word]\n",
    "    else:\n",
    "        word_embeddings[idx] = glove_vectors['unk']\n",
    "print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "        Padding the sequences to the maximum length sequence in the batch\n",
    "        Args:\n",
    "            batch: list of individual elements of the dataset\n",
    "        Returns:\n",
    "            {'text' : padded_texts, 'labels' : padded_labels}\n",
    "    \"\"\"\n",
    "    texts, labels = [item['text'] for item in batch], [item['labels'] for item in batch]\n",
    "    max_len = max([len(text) for text in texts])\n",
    "    padded_texts, padded_labels = [], []\n",
    "    for i in range(len(texts)):\n",
    "        text, label = texts[i], labels[i]\n",
    "        # padding text and label sequences\n",
    "        text = text + [word_to_index['PAD']] * (max_len - len(text))\n",
    "        label = label + [label_to_idx['O']] * (max_len - len(label))\n",
    "        padded_texts.append(text)\n",
    "        padded_labels.append(label)\n",
    "    return {'text': torch.tensor(padded_texts), 'labels': torch.tensor(padded_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Custom Dataset to load the Laptop Review dataset\n",
    "        Args:\n",
    "            data: list of tuples (text, labels)\n",
    "            vocab_size: size of the vocabulary\n",
    "            embedding_size: size of the word embeddings\n",
    "            word_to_index: word-to-index mapping\n",
    "            index_to_word: index-to-word mapping\n",
    "            label_to_idx: label-to-index mapping\n",
    "    \"\"\"\n",
    "    def __init__(self, data, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx):\n",
    "        self.data = data\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = index_to_word\n",
    "        self.label_to_idx = label_to_idx \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text, labels = self.data[idx][0], self.data[idx][1]\n",
    "        words = text.split()\n",
    "        # converting words and labels to indices\n",
    "        word_indices = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index['UNK'] for word in words]\n",
    "        label_indices = [self.label_to_idx[label] for label in labels]\n",
    "        sample = {'text' : word_indices, 'labels' : label_indices}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = NERDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLoVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37868 37868 300 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3830722025.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "        Model architecture to perform Sequence Labeling on the Laptop Review dataset. RNN, LSTM or GRU model is initialized based on the model configuration parameters.\n",
    "        Args: \n",
    "            vocab_size: size of the vocabulary\n",
    "            embed_size: size of the word embeddings\n",
    "            hidden_size: size of the hidden state\n",
    "            pretrained_embeddings: pre-trained word embeddings\n",
    "            model_config: dictionary containing model configuration parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, pretrained_embeddings, model_config):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings=pretrained_embeddings, freeze=True)\n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], nonlinearity=model_config['activation'], batch_first=True, dropout=model_config['dropout'])\n",
    "        if (model_config['model'] == 'LSTM'):\n",
    "            self.rnn = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n",
    "        if (model_config['model'] == 'GRU'):\n",
    "            self.rnn = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=model_config['num_hidden'], batch_first=True, dropout=model_config['dropout'])\n",
    "        self.fc = nn.Linear(hidden_size, 27)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "# Initialize the model\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()\n",
    "print(vocab_size, len(word_vectors), embed_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            text, labels = data['text'], data['labels']\n",
    "            output, hidden = model(text)\n",
    "            output = output.view(-1, 27)\n",
    "            labels = labels.view(-1)\n",
    "            loss += criterion(output, labels).item()\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += torch.argmax(output, 1).tolist()\n",
    "    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return accuracy, macro_f1, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            text, labels = data['text'], data['labels']\n",
    "            outputs, hidden = model(text)\n",
    "            outputs = outputs.view(-1, 27)\n",
    "            labels = labels.view(-1)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            y_true += labels.tolist()\n",
    "            y_pred += torch.argmax(outputs, 1).tolist()\n",
    "    accuracy = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    from sklearn.metrics import classification_report\n",
    "    classification_report = classification_report(y_true, y_pred)\n",
    "    return accuracy, precision, macro_f1, loss, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN + GloVe for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\4161685679.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2305332467.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model1_glove.pth\"\n",
      "c:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9301\n",
      "Test precision: 0.9201\n",
      "Test macro F1: 0.3511\n",
      "Test loss: 9.0012\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     57483\n",
      "           1       0.57      0.21      0.31       121\n",
      "           2       0.64      0.35      0.46       344\n",
      "           3       0.13      0.07      0.09       159\n",
      "           4       0.22      0.23      0.23       310\n",
      "           5       0.38      0.21      0.27       276\n",
      "           6       0.28      0.24      0.26       195\n",
      "           7       0.65      0.44      0.53       222\n",
      "           8       0.54      0.43      0.48       383\n",
      "           9       0.67      0.62      0.65       258\n",
      "          10       0.72      0.54      0.62       439\n",
      "          11       0.50      0.18      0.26       178\n",
      "          12       0.49      0.25      0.33       326\n",
      "          13       0.38      0.10      0.16        58\n",
      "          14       0.48      0.37      0.42       177\n",
      "          15       0.76      0.52      0.62      1793\n",
      "          16       0.86      0.76      0.81       222\n",
      "          17       0.25      0.11      0.15         9\n",
      "          18       0.50      0.09      0.15        11\n",
      "          19       0.20      0.15      0.17        54\n",
      "          20       0.53      0.24      0.33       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.20      0.22      0.21         9\n",
      "          23       0.68      0.79      0.73       102\n",
      "          24       0.05      0.12      0.07         8\n",
      "          25       0.04      0.14      0.07         7\n",
      "          26       0.50      0.09      0.15        47\n",
      "\n",
      "    accuracy                           0.93     63379\n",
      "   macro avg       0.45      0.31      0.35     63379\n",
      "weighted avg       0.92      0.93      0.92     63379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model1_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + GloVe for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\531312971.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3520937091.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model2_glove.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9227\n",
      "Test precision: 0.9164\n",
      "Test macro F1: 0.3240\n",
      "Test loss: 13.9706\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     57483\n",
      "           1       0.38      0.21      0.27       121\n",
      "           2       0.39      0.32      0.35       344\n",
      "           3       0.09      0.06      0.07       159\n",
      "           4       0.17      0.12      0.14       310\n",
      "           5       0.25      0.20      0.22       276\n",
      "           6       0.18      0.23      0.20       195\n",
      "           7       0.56      0.48      0.52       222\n",
      "           8       0.49      0.41      0.44       383\n",
      "           9       0.65      0.62      0.63       258\n",
      "          10       0.65      0.53      0.58       439\n",
      "          11       0.34      0.23      0.27       178\n",
      "          12       0.36      0.35      0.35       326\n",
      "          13       0.33      0.16      0.21        58\n",
      "          14       0.50      0.38      0.43       177\n",
      "          15       0.70      0.54      0.61      1793\n",
      "          16       0.79      0.75      0.77       222\n",
      "          17       0.06      0.11      0.08         9\n",
      "          18       0.07      0.09      0.08        11\n",
      "          19       0.27      0.22      0.24        54\n",
      "          20       0.42      0.28      0.34       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.08      0.22      0.12         9\n",
      "          23       0.67      0.68      0.67       102\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.23      0.11      0.14        47\n",
      "\n",
      "    accuracy                           0.92     63379\n",
      "   macro avg       0.36      0.31      0.32     63379\n",
      "weighted avg       0.92      0.92      0.92     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model2_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU + GloVe for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\1939184259.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'GloVe',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2024439700.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model3_glove.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9215\n",
      "Test precision: 0.9133\n",
      "Test macro F1: 0.3130\n",
      "Test loss: 17.2918\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     57483\n",
      "           1       0.32      0.24      0.27       121\n",
      "           2       0.40      0.33      0.36       344\n",
      "           3       0.13      0.10      0.11       159\n",
      "           4       0.18      0.14      0.15       310\n",
      "           5       0.29      0.20      0.24       276\n",
      "           6       0.20      0.15      0.18       195\n",
      "           7       0.52      0.48      0.50       222\n",
      "           8       0.48      0.41      0.44       383\n",
      "           9       0.62      0.61      0.61       258\n",
      "          10       0.59      0.50      0.54       439\n",
      "          11       0.33      0.26      0.29       178\n",
      "          12       0.41      0.35      0.37       326\n",
      "          13       0.19      0.09      0.12        58\n",
      "          14       0.47      0.34      0.39       177\n",
      "          15       0.71      0.45      0.55      1793\n",
      "          16       0.74      0.77      0.76       222\n",
      "          17       0.05      0.11      0.07         9\n",
      "          18       0.11      0.18      0.13        11\n",
      "          19       0.22      0.15      0.18        54\n",
      "          20       0.34      0.32      0.33       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.08      0.22      0.12         9\n",
      "          23       0.58      0.72      0.64       102\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.12      0.11      0.11        47\n",
      "\n",
      "    accuracy                           0.92     63379\n",
      "   macro avg       0.33      0.30      0.31     63379\n",
      "weighted avg       0.91      0.92      0.92     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\GloVe\\\\t1_model3_glove.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = [], [], []\n",
    "for i in train_data:\n",
    "    train.append([train_data[i]['text'], train_data[i]['labels']])\n",
    "for i in val_data:\n",
    "    val.append([val_data[i]['text'], val_data[i]['labels']])\n",
    "for i in test_data:\n",
    "    test.append([test_data[i]['text'], test_data[i]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 8019\n",
      "Validation data size: 1416\n",
      "Test data size: 949\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size: {len(train)}')\n",
    "print(f'Validation data size: {len(val)}')\n",
    "print(f'Test data size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 37866\n",
      "Words and their counts: [('Therefore,', 97), ('while', 164), ('interpreting', 6), ('statutory', 76), ('provisions,', 10)]\n"
     ]
    }
   ],
   "source": [
    "data = train + val + test\n",
    "# Finding number of unique words in the dataset\n",
    "word_count = {}\n",
    "for i in range(len(data)):\n",
    "    words = data[i][0].split()\n",
    "    for word in words:\n",
    "        if word not in word_count:\n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1\n",
    "print(f\"Number of unique words in the dataset: {len(word_count)}\")\n",
    "print(f\"Words and their counts: {list(word_count.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset after adding 'PAD' and 'UNK': 37868\n"
     ]
    }
   ],
   "source": [
    "word_list = list(word_count.keys())\n",
    "# adding 'PAD' and 'UNK' to the word list\n",
    "word_list.append('PAD')\n",
    "word_list.append('UNK')\n",
    "word_count['PAD'] = 0\n",
    "word_count['UNK'] = 0\n",
    "print(f\"Number of unique words in the dataset after adding 'PAD' and 'UNK': {len(word_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-to-index: [('Therefore,', 0), ('while', 1), ('interpreting', 2), ('statutory', 3), ('provisions,', 4)]\n",
      "Index-to-word: [(0, 'Therefore,'), (1, 'while'), (2, 'interpreting'), (3, 'statutory'), (4, 'provisions,')]\n",
      "Number of unique labels in the dataset: 27\n",
      "Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n",
      "Labels and their counts: [('O', 294339), ('B_CASE_NUMBER', 1161), ('I_CASE_NUMBER', 3975), ('B_ORG', 1600), ('I_ORG', 2945), ('B_OTHER_PERSON', 2929), ('I_OTHER_PERSON', 2252), ('B_STATUTE', 2026), ('I_STATUTE', 3659), ('B_PROVISION', 2642), ('I_PROVISION', 4326), ('B_COURT', 1471), ('I_COURT', 2854), ('B_WITNESS', 939), ('B_PRECEDENT', 1528), ('I_PRECEDENT', 13435), ('B_DATE', 2106), ('B_PETITIONER', 473), ('I_PETITIONER', 384), ('I_WITNESS', 810), ('B_GPE', 1581), ('B_RESPONDENT', 329), ('I_RESPONDENT', 448), ('I_DATE', 1480), ('B_JUDGE', 575), ('I_JUDGE', 398), ('I_GPE', 327)]\n",
      "Label-to-index: [('O', 0), ('B_CASE_NUMBER', 1), ('I_CASE_NUMBER', 2), ('B_ORG', 3), ('I_ORG', 4), ('B_OTHER_PERSON', 5), ('I_OTHER_PERSON', 6), ('B_STATUTE', 7), ('I_STATUTE', 8), ('B_PROVISION', 9), ('I_PROVISION', 10), ('B_COURT', 11), ('I_COURT', 12), ('B_WITNESS', 13), ('B_PRECEDENT', 14), ('I_PRECEDENT', 15), ('B_DATE', 16), ('B_PETITIONER', 17), ('I_PETITIONER', 18), ('I_WITNESS', 19), ('B_GPE', 20), ('B_RESPONDENT', 21), ('I_RESPONDENT', 22), ('I_DATE', 23), ('B_JUDGE', 24), ('I_JUDGE', 25), ('I_GPE', 26)]\n",
      "Index-to-label: [(0, 'O'), (1, 'B_CASE_NUMBER'), (2, 'I_CASE_NUMBER'), (3, 'B_ORG'), (4, 'I_ORG'), (5, 'B_OTHER_PERSON'), (6, 'I_OTHER_PERSON'), (7, 'B_STATUTE'), (8, 'I_STATUTE'), (9, 'B_PROVISION'), (10, 'I_PROVISION'), (11, 'B_COURT'), (12, 'I_COURT'), (13, 'B_WITNESS'), (14, 'B_PRECEDENT'), (15, 'I_PRECEDENT'), (16, 'B_DATE'), (17, 'B_PETITIONER'), (18, 'I_PETITIONER'), (19, 'I_WITNESS'), (20, 'B_GPE'), (21, 'B_RESPONDENT'), (22, 'I_RESPONDENT'), (23, 'I_DATE'), (24, 'B_JUDGE'), (25, 'I_JUDGE'), (26, 'I_GPE')]\n"
     ]
    }
   ],
   "source": [
    "# Word-to-index and index-to-word mapping from the dataset\n",
    "word_to_index = {word:idx for idx, word in enumerate(word_list)}\n",
    "index_to_word = {idx:word for word, idx in word_to_index.items()}\n",
    "print(f\"Word-to-index: {list(word_to_index.items())[:5]}\")\n",
    "print(f\"Index-to-word: {list(index_to_word.items())[:5]}\")\n",
    "# finding all the unique labels in the dataset\n",
    "label_count = {}\n",
    "for i in range(len(data)):\n",
    "    labels = data[i][1]\n",
    "    for label in labels:\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 1\n",
    "        else:\n",
    "            label_count[label] += 1\n",
    "print(f\"Number of unique labels in the dataset: {len(label_count)}\")\n",
    "print(f\"Labels and their counts: {list(label_count.items())}\")\n",
    "print(f\"Labels and their counts: {list(label_count.items())}\")\n",
    "label_to_idx = {label:idx for idx, label in enumerate(label_count.keys())}\n",
    "idx_to_label = {idx:label for label, idx in label_to_idx.items()}\n",
    "print(f\"Label-to-index: {list(label_to_idx.items())}\")\n",
    "print(f\"Index-to-label: {list(idx_to_label.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word_embeddings: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = np.zeros((len(word_list), 300))\n",
    "for i in range(len(word_list)):\n",
    "    word = word_list[i]\n",
    "    idx = word_to_index[word]\n",
    "    if word in glove_vectors.stoi:\n",
    "        word_embeddings[idx] = fasttext_vectors[word]\n",
    "    else:\n",
    "        word_embeddings[idx] = fasttext_vectors['unk']\n",
    "print(f\"Shape of word_embeddings: {word_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = NERDataset(test, vocab_size, embedding_size, word_to_index, index_to_word, label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + FastText for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\1635589053.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model1_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9326\n",
      "Test precision: 0.9235\n",
      "Test macro F1: 0.3468\n",
      "Test loss: 8.5034\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     57483\n",
      "           1       0.44      0.22      0.30       121\n",
      "           2       0.54      0.40      0.46       344\n",
      "           3       0.14      0.04      0.07       159\n",
      "           4       0.27      0.14      0.18       310\n",
      "           5       0.36      0.21      0.27       276\n",
      "           6       0.24      0.24      0.24       195\n",
      "           7       0.59      0.54      0.56       222\n",
      "           8       0.53      0.49      0.51       383\n",
      "           9       0.70      0.61      0.65       258\n",
      "          10       0.74      0.54      0.62       439\n",
      "          11       0.41      0.25      0.31       178\n",
      "          12       0.47      0.34      0.40       326\n",
      "          13       0.20      0.02      0.03        58\n",
      "          14       0.51      0.45      0.48       177\n",
      "          15       0.73      0.67      0.70      1793\n",
      "          16       0.84      0.77      0.80       222\n",
      "          17       0.14      0.11      0.12         9\n",
      "          18       0.15      0.27      0.19        11\n",
      "          19       0.62      0.09      0.16        54\n",
      "          20       0.50      0.36      0.42       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.06      0.22      0.09         9\n",
      "          23       0.63      0.76      0.69       102\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.44      0.09      0.14        47\n",
      "\n",
      "    accuracy                           0.93     63379\n",
      "   macro avg       0.42      0.33      0.35     63379\n",
      "weighted avg       0.92      0.93      0.93     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model1_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + FastText for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\742294922.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Fasttext',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\817277496.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model2_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9233\n",
      "Test precision: 0.9152\n",
      "Test macro F1: 0.3294\n",
      "Test loss: 14.5547\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     57483\n",
      "           1       0.38      0.18      0.25       121\n",
      "           2       0.43      0.28      0.34       344\n",
      "           3       0.15      0.11      0.13       159\n",
      "           4       0.16      0.15      0.16       310\n",
      "           5       0.31      0.21      0.25       276\n",
      "           6       0.20      0.17      0.19       195\n",
      "           7       0.50      0.48      0.49       222\n",
      "           8       0.46      0.46      0.46       383\n",
      "           9       0.58      0.64      0.61       258\n",
      "          10       0.61      0.55      0.58       439\n",
      "          11       0.41      0.27      0.32       178\n",
      "          12       0.44      0.31      0.36       326\n",
      "          13       0.16      0.07      0.10        58\n",
      "          14       0.56      0.32      0.41       177\n",
      "          15       0.69      0.52      0.59      1793\n",
      "          16       0.75      0.76      0.76       222\n",
      "          17       0.17      0.11      0.13         9\n",
      "          18       0.12      0.09      0.11        11\n",
      "          19       0.30      0.17      0.21        54\n",
      "          20       0.48      0.33      0.39       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.09      0.22      0.13         9\n",
      "          23       0.58      0.71      0.64       102\n",
      "          24       0.08      0.25      0.12         8\n",
      "          25       0.03      0.14      0.05         7\n",
      "          26       0.27      0.13      0.17        47\n",
      "\n",
      "    accuracy                           0.92     63379\n",
      "   macro avg       0.37      0.32      0.33     63379\n",
      "weighted avg       0.92      0.92      0.92     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model2_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU + FastText for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2305356057.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'FastText',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\1791481303.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model3_fasttext.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9260\n",
      "Test precision: 0.9153\n",
      "Test macro F1: 0.3200\n",
      "Test loss: 16.8684\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     57483\n",
      "           1       0.39      0.23      0.29       121\n",
      "           2       0.49      0.35      0.41       344\n",
      "           3       0.08      0.03      0.05       159\n",
      "           4       0.19      0.12      0.15       310\n",
      "           5       0.27      0.18      0.22       276\n",
      "           6       0.23      0.21      0.22       195\n",
      "           7       0.57      0.42      0.48       222\n",
      "           8       0.52      0.35      0.42       383\n",
      "           9       0.62      0.59      0.60       258\n",
      "          10       0.66      0.52      0.58       439\n",
      "          11       0.35      0.21      0.26       178\n",
      "          12       0.40      0.31      0.35       326\n",
      "          13       0.24      0.14      0.18        58\n",
      "          14       0.57      0.29      0.38       177\n",
      "          15       0.78      0.49      0.60      1793\n",
      "          16       0.81      0.77      0.79       222\n",
      "          17       0.06      0.11      0.08         9\n",
      "          18       0.12      0.18      0.14        11\n",
      "          19       0.23      0.13      0.17        54\n",
      "          20       0.33      0.21      0.26       183\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.06      0.22      0.09         9\n",
      "          23       0.62      0.74      0.68       102\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.09      0.29      0.13         7\n",
      "          26       0.17      0.13      0.15        47\n",
      "\n",
      "    accuracy                           0.93     63379\n",
      "   macro avg       0.36      0.30      0.32     63379\n",
      "weighted avg       0.92      0.93      0.92     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Fasttext\\\\t1_model3_fasttext.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word embeddings: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = []\n",
    "for word in word_list:\n",
    "    try:\n",
    "        word_embeddings.append(wv[word])\n",
    "    except:\n",
    "        word_embeddings.append(wv['unk'])\n",
    "word_embeddings = np.array(word_embeddings)\n",
    "print(f\"Shape of word embeddings: {word_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of word vectors: (37868, 300)\n"
     ]
    }
   ],
   "source": [
    "# List of word vectors\n",
    "word_vectors = [word_embeddings[word_to_index[word]] for word in word_list]\n",
    "word_vectors = np.array(word_vectors)\n",
    "print(f\"Shape of word vectors: {word_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + Word2Vec for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'RNN',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2028122749.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model1_Word2vec.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9517\n",
      "Test precision: 0.9485\n",
      "Test macro F1: 0.5221\n",
      "Test loss: 9.7472\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     57483\n",
      "           1       0.40      0.26      0.31       121\n",
      "           2       0.61      0.47      0.53       344\n",
      "           3       0.43      0.31      0.36       159\n",
      "           4       0.43      0.29      0.35       310\n",
      "           5       0.55      0.57      0.56       276\n",
      "           6       0.59      0.59      0.59       195\n",
      "           7       0.69      0.60      0.64       222\n",
      "           8       0.75      0.68      0.71       383\n",
      "           9       0.90      0.86      0.88       258\n",
      "          10       0.86      0.77      0.82       439\n",
      "          11       0.83      0.73      0.78       178\n",
      "          12       0.84      0.73      0.78       326\n",
      "          13       0.44      0.48      0.46        58\n",
      "          14       0.50      0.37      0.42       177\n",
      "          15       0.85      0.63      0.72      1793\n",
      "          16       0.80      0.78      0.79       222\n",
      "          17       0.25      0.44      0.32         9\n",
      "          18       0.24      0.45      0.31        11\n",
      "          19       0.55      0.39      0.46        54\n",
      "          20       0.43      0.45      0.44       183\n",
      "          21       0.22      0.40      0.29         5\n",
      "          22       0.17      0.22      0.19         9\n",
      "          23       0.69      0.67      0.68       102\n",
      "          24       0.08      0.25      0.12         8\n",
      "          25       0.27      0.57      0.36         7\n",
      "          26       0.23      0.23      0.23        47\n",
      "\n",
      "    accuracy                           0.95     63379\n",
      "   macro avg       0.54      0.53      0.52     63379\n",
      "weighted avg       0.95      0.95      0.95     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model1_Word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + Word2Vec for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\2473460402.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'LSTM',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\204597385.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model2_Word2vec.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9531\n",
      "Test precision: 0.9504\n",
      "Test macro F1: 0.5455\n",
      "Test loss: 10.7841\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     57483\n",
      "           1       0.41      0.30      0.34       121\n",
      "           2       0.63      0.48      0.55       344\n",
      "           3       0.37      0.31      0.34       159\n",
      "           4       0.48      0.32      0.38       310\n",
      "           5       0.58      0.58      0.58       276\n",
      "           6       0.58      0.57      0.58       195\n",
      "           7       0.73      0.65      0.69       222\n",
      "           8       0.80      0.67      0.73       383\n",
      "           9       0.87      0.86      0.87       258\n",
      "          10       0.87      0.74      0.80       439\n",
      "          11       0.86      0.77      0.81       178\n",
      "          12       0.85      0.75      0.80       326\n",
      "          13       0.45      0.40      0.42        58\n",
      "          14       0.49      0.41      0.45       177\n",
      "          15       0.83      0.67      0.74      1793\n",
      "          16       0.82      0.80      0.81       222\n",
      "          17       0.25      0.56      0.34         9\n",
      "          18       0.43      0.55      0.48        11\n",
      "          19       0.55      0.39      0.46        54\n",
      "          20       0.47      0.51      0.49       183\n",
      "          21       0.20      0.40      0.27         5\n",
      "          22       0.14      0.22      0.17         9\n",
      "          23       0.62      0.69      0.65       102\n",
      "          24       0.21      0.62      0.31         8\n",
      "          25       0.21      0.57      0.31         7\n",
      "          26       0.39      0.36      0.37        47\n",
      "\n",
      "    accuracy                           0.95     63379\n",
      "   macro avg       0.56      0.56      0.55     63379\n",
      "weighted avg       0.95      0.95      0.95     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model2_Word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU + Word2Vec for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\3869732436.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vectors = torch.tensor(word_vectors)\n"
     ]
    }
   ],
   "source": [
    "model_config = dict(\n",
    "    task = 1, \n",
    "    model = 'GRU',\n",
    "    embed_size = 300,\n",
    "    embedding = 'Word2Vec',\n",
    "    hidden_size = 128,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 32,\n",
    "    epochs = 100, \n",
    "    padding = 'max_post', \n",
    "    loss = 'CrossEntropyLoss',\n",
    "    optimizer = 'Adam',\n",
    "    num_hidden = 1,\n",
    "    dropout = 0, \n",
    "    activation = 'tanh'\n",
    ")\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embed_size = model_config['embed_size'] # Size of the word embeddings\n",
    "hidden_size = model_config['hidden_size'] # Size of the hidden state\n",
    "word_vectors = torch.tensor(word_vectors)\n",
    "word_vectors = word_vectors.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\saras\\AppData\\Local\\Temp\\ipykernel_3120\\308635428.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model3_Word2vec.pth\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9527\n",
      "Test precision: 0.9514\n",
      "Test macro F1: 0.5482\n",
      "Test loss: 12.0151\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     57483\n",
      "           1       0.48      0.43      0.45       121\n",
      "           2       0.63      0.53      0.58       344\n",
      "           3       0.34      0.32      0.33       159\n",
      "           4       0.50      0.40      0.44       310\n",
      "           5       0.57      0.53      0.55       276\n",
      "           6       0.59      0.52      0.55       195\n",
      "           7       0.64      0.65      0.65       222\n",
      "           8       0.79      0.68      0.73       383\n",
      "           9       0.86      0.88      0.87       258\n",
      "          10       0.88      0.76      0.81       439\n",
      "          11       0.81      0.75      0.78       178\n",
      "          12       0.83      0.70      0.76       326\n",
      "          13       0.35      0.50      0.41        58\n",
      "          14       0.49      0.47      0.48       177\n",
      "          15       0.84      0.69      0.76      1793\n",
      "          16       0.73      0.81      0.77       222\n",
      "          17       0.21      0.44      0.29         9\n",
      "          18       0.35      0.55      0.43        11\n",
      "          19       0.40      0.39      0.40        54\n",
      "          20       0.48      0.51      0.50       183\n",
      "          21       0.21      0.60      0.32         5\n",
      "          22       0.17      0.33      0.22         9\n",
      "          23       0.66      0.76      0.71       102\n",
      "          24       0.19      0.50      0.28         8\n",
      "          25       0.38      0.71      0.50         7\n",
      "          26       0.28      0.26      0.27        47\n",
      "\n",
      "    accuracy                           0.95     63379\n",
      "   macro avg       0.54      0.58      0.55     63379\n",
      "weighted avg       0.95      0.95      0.95     63379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, word_vectors, model_config)\n",
    "model_path = \"Trained_Models\\Task 1\\Word2vec\\\\t1_model3_Word2vec.pth\"\n",
    "#load the model\n",
    "temp = torch.load(model_path)\n",
    "model.load_state_dict(temp)\n",
    "accuracy, precision, macro_f1, loss, classification_report = evaluation(model, test_dataloader, criterion)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\\nTest precision: {precision:.4f}\\nTest macro F1: {macro_f1:.4f}\\nTest loss: {loss:.4f}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
