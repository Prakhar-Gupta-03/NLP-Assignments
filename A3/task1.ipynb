{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('train.csv')\n",
    "valid_data = pd.read_table('dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>setence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2.0</td>\n",
       "      <td>New UN peacekeeping chief named for Central Af...</td>\n",
       "      <td>UN takes over peacekeeping in Central African ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Oil falls in Asian trade</td>\n",
       "      <td>Oil prices down in Asian trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Israeli forces detain Palestinian MP in Hebron</td>\n",
       "      <td>Israeli forces detain 2 Palestinians in overni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Israeli police clash with Palestinian proteste...</td>\n",
       "      <td>Israel Police Clash With Palestinians in Jerus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 killed, 4 injured in Los Angeles shootings</td>\n",
       "      <td>Five killed in Saudi Arabia shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Scientists prove there is water on Mars</td>\n",
       "      <td>Has Nasa discovered water on Mars?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Pranab stresses need to strive for peace by na...</td>\n",
       "      <td>WTO: India regrets action of developed nations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Volkswagen skids into red in wake of pollution...</td>\n",
       "      <td>Volkswagen's \"gesture of goodwill\" to diesel o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Obama is right: Africa deserves better leadership</td>\n",
       "      <td>Obama waiting for midterm to name attorney gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New video shows US police officers beating men...</td>\n",
       "      <td>New York police officer critically wounded in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                           setence1  \\\n",
       "1460    2.0  New UN peacekeeping chief named for Central Af...   \n",
       "1461    5.0                           Oil falls in Asian trade   \n",
       "1462    3.0     Israeli forces detain Palestinian MP in Hebron   \n",
       "1463    3.0  Israeli police clash with Palestinian proteste...   \n",
       "1464    0.0       3 killed, 4 injured in Los Angeles shootings   \n",
       "1465    2.0            Scientists prove there is water on Mars   \n",
       "1466    0.0  Pranab stresses need to strive for peace by na...   \n",
       "1467    2.0  Volkswagen skids into red in wake of pollution...   \n",
       "1468    0.0  Obama is right: Africa deserves better leadership   \n",
       "1469    0.0  New video shows US police officers beating men...   \n",
       "\n",
       "                                              sentence2  \n",
       "1460  UN takes over peacekeeping in Central African ...  \n",
       "1461                     Oil prices down in Asian trade  \n",
       "1462  Israeli forces detain 2 Palestinians in overni...  \n",
       "1463  Israel Police Clash With Palestinians in Jerus...  \n",
       "1464               Five killed in Saudi Arabia shooting  \n",
       "1465                 Has Nasa discovered water on Mars?  \n",
       "1466     WTO: India regrets action of developed nations  \n",
       "1467  Volkswagen's \"gesture of goodwill\" to diesel o...  \n",
       "1468  Obama waiting for midterm to name attorney gen...  \n",
       "1469  New York police officer critically wounded in ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5711, 3)\n",
      "score\n",
      "0.000    367\n",
      "4.000    351\n",
      "3.000    308\n",
      "5.000    265\n",
      "3.800    263\n",
      "        ... \n",
      "0.067      1\n",
      "0.727      1\n",
      "1.700      1\n",
      "1.778      1\n",
      "4.330      1\n",
      "Name: count, Length: 139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_data['score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score        0\n",
      "sentence1    0\n",
      "sentence2    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if any missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# some values were missing in sentence2 column, so did the below (sentence1 didnt split properly)\n",
    "\n",
    "# iterate through the rows in dataframe which have missing values\n",
    "for index, row in train_data[train_data.isnull().any(axis=1)].iterrows():\n",
    "    if pd.isnull(row['sentence2']):\n",
    "        # split the sentence1 into words into 2 parts based on \\t and assign to sentence1 and sentence2\n",
    "        sentence1, sentence2 = row['sentence1'].split('\\t')\n",
    "        score = row['score']\n",
    "        # assign to the row\n",
    "        train_data.at[index, 'sentence1'] = sentence1\n",
    "        train_data.at[index, 'sentence2'] = sentence2\n",
    "        train_data.at[index, 'score'] = score\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
