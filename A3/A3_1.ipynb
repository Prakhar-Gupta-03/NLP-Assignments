{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: torch in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (2.2.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.1.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "   ---------------------------------------- 0.0/841.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 41.0/841.5 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 450.6/841.5 kB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 841.5/841.5 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.1-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.1 torchmetrics-1.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torch\n",
    "! pip install transformers\n",
    "! pip install tqdm \n",
    "! pip install pandas\n",
    "! pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torchmetrics.regression import PearsonCorrCoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_table(file_path)\n",
    "    # check if any missing values\n",
    "    print(data.isnull().sum())\n",
    "    key = data.keys()\n",
    "    # some values were missing in sentence2 column, so did the below (sentence1 didnt split properly)\n",
    "    # iterate through the rows in dataframe which have missing values\n",
    "    for index, row in data[data.isnull().any(axis=1)].iterrows():\n",
    "        if pd.isnull(row[key[2]]):\n",
    "            if(len(row[key[1]].split('\\t')) > 2 or len(row[key[1]].split('\\t')) < 2):\n",
    "                data.drop(index, inplace=True)\n",
    "                continue\n",
    "            # split the sentence1 into words into 2 parts based on \\t and assign to sentence1 and sentence2\n",
    "            sentence1, sentence2 = row[key[1]].split('\\t')\n",
    "            score = row[key[0]]\n",
    "            # assign to the row\n",
    "            data.at[index, key[1]] = sentence1\n",
    "            data.at[index, key[2]] = sentence2\n",
    "            data.at[index, key[0]] = score\n",
    "    #rescale every score in data from 0-5 to 0-1\n",
    "    data[key[0]] = data[key[0]]/5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score        0\n",
      "sentence1    0\n",
      "sentence2    5\n",
      "dtype: int64\n",
      "score        0\n",
      "sentence1    0\n",
      "sentence2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data('train.csv')\n",
    "valid_data = load_data('dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0.4</td>\n",
       "      <td>New UN peacekeeping chief named for Central Af...</td>\n",
       "      <td>UN takes over peacekeeping in Central African ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Oil falls in Asian trade</td>\n",
       "      <td>Oil prices down in Asian trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0.6</td>\n",
       "      <td>Israeli forces detain Palestinian MP in Hebron</td>\n",
       "      <td>Israeli forces detain 2 Palestinians in overni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0.6</td>\n",
       "      <td>Israeli police clash with Palestinian proteste...</td>\n",
       "      <td>Israel Police Clash With Palestinians in Jerus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 killed, 4 injured in Los Angeles shootings</td>\n",
       "      <td>Five killed in Saudi Arabia shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>0.4</td>\n",
       "      <td>Scientists prove there is water on Mars</td>\n",
       "      <td>Has Nasa discovered water on Mars?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Pranab stresses need to strive for peace by na...</td>\n",
       "      <td>WTO: India regrets action of developed nations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>0.4</td>\n",
       "      <td>Volkswagen skids into red in wake of pollution...</td>\n",
       "      <td>Volkswagen's \"gesture of goodwill\" to diesel o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Obama is right: Africa deserves better leadership</td>\n",
       "      <td>Obama waiting for midterm to name attorney gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New video shows US police officers beating men...</td>\n",
       "      <td>New York police officer critically wounded in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                          sentence1  \\\n",
       "1460    0.4  New UN peacekeeping chief named for Central Af...   \n",
       "1461    1.0                           Oil falls in Asian trade   \n",
       "1462    0.6     Israeli forces detain Palestinian MP in Hebron   \n",
       "1463    0.6  Israeli police clash with Palestinian proteste...   \n",
       "1464    0.0       3 killed, 4 injured in Los Angeles shootings   \n",
       "1465    0.4            Scientists prove there is water on Mars   \n",
       "1466    0.0  Pranab stresses need to strive for peace by na...   \n",
       "1467    0.4  Volkswagen skids into red in wake of pollution...   \n",
       "1468    0.0  Obama is right: Africa deserves better leadership   \n",
       "1469    0.0  New video shows US police officers beating men...   \n",
       "\n",
       "                                              sentence2  \n",
       "1460  UN takes over peacekeeping in Central African ...  \n",
       "1461                     Oil prices down in Asian trade  \n",
       "1462  Israeli forces detain 2 Palestinians in overni...  \n",
       "1463  Israel Police Clash With Palestinians in Jerus...  \n",
       "1464               Five killed in Saudi Arabia shooting  \n",
       "1465                 Has Nasa discovered water on Mars?  \n",
       "1466     WTO: India regrets action of developed nations  \n",
       "1467  Volkswagen's \"gesture of goodwill\" to diesel o...  \n",
       "1468  Obama waiting for midterm to name attorney gen...  \n",
       "1469  New York police officer critically wounded in ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 3)\n",
      "score\n",
      "0.0000    367\n",
      "0.8000    351\n",
      "0.6000    308\n",
      "1.0000    265\n",
      "0.7600    263\n",
      "         ... \n",
      "0.0134      1\n",
      "0.1454      1\n",
      "0.3400      1\n",
      "0.3556      1\n",
      "0.8660      1\n",
      "Name: count, Length: 139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_data['score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining device variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1A: using BERT to perform regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, data, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['sentence1'] + ' [SEP] ' + self.data.iloc[idx]['sentence2']\n",
    "        inputs = self.tokenizer(text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        inputs['labels'] = torch.tensor(self.data.iloc[idx]['score'], dtype=torch.float)\n",
    "        inputs = {key: inputs[key].squeeze() for key in inputs}\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the dataset and dataloader class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(tokenizer, train_data, max_length)\n",
    "valid_dataset = TextDataset(tokenizer, valid_data, max_length)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "sep_token = '[SEP]'\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m      2\u001b[0m pearson \u001b[38;5;241m=\u001b[39m PearsonCorrCoef()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "pearson = PearsonCorrCoef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs.loss, outputs.logits\n",
    "    \n",
    "model = Model(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining train and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, epochs=1, valid_loader=None):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm.tqdm(loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss, preds = model(input_ids, attention_mask, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch: {epoch + 1}, Training loss: {total_loss / len(loader)}')\n",
    "        if(valid_loader is not None):\n",
    "            evaluate(model, valid_loader)\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predicted = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            loss, preds = model(input_ids, attention_mask, labels)\n",
    "            total_loss += loss.item()\n",
    "            for i in preds:\n",
    "                i = i.cpu()\n",
    "                predicted = torch.cat((predicted, i))\n",
    "            for i in labels:\n",
    "                i = i.cpu()\n",
    "                i = torch.tensor([i])\n",
    "                all_labels = torch.cat((all_labels, i))\n",
    "    print(f'Validation loss: {total_loss / len(loader)}, Pearson correlation: {pearson(predicted, all_labels)}')\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/714 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/714 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, epochs, valid_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask, labels)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     14\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, epochs=5, valid_loader=valid_loader)\n",
    "# evaluate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "score        0\n",
      "setence1     0\n",
      "sentence2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#load data from sample_demo.csv\n",
    "test_data = load_data('sample_demo.csv')\n",
    "test_dataset = TextDataset(tokenizer, test_data, max_length)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m evaluate(model, test_loader)\n",
      "File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
