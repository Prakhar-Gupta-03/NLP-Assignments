{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (2.2.0)\n","Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (4.39.1)\n","Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.21.4)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: colorama in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: tqdm in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (4.66.2)\n","Requirement already satisfied: colorama in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm) (0.4.6)\n","Requirement already satisfied: pandas in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (2.2.1)\n","Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: torchmetrics in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (1.3.2)\n","Requirement already satisfied: numpy>1.20.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging>17.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: torch>=1.10.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (2.2.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchmetrics) (0.11.1)\n","Requirement already satisfied: setuptools in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.1.1)\n","Requirement already satisfied: typing-extensions in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n","Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n","Requirement already satisfied: fsspec in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (4.39.1)\n","Requirement already satisfied: tqdm in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (2.2.0)\n","Requirement already satisfied: numpy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n","Requirement already satisfied: scipy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (1.12.0)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (0.21.4)\n","Requirement already satisfied: Pillow in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (10.2.0)\n","Requirement already satisfied: filelock in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n","Requirement already satisfied: requests in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n","Requirement already satisfied: sympy in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n","Requirement already satisfied: colorama in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\saras\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n","   ---------------------------------------- 0.0/163.3 kB ? eta -:--:--\n","   -- ------------------------------------- 10.2/163.3 kB ? eta -:--:--\n","   ---------------------------------------- 163.3/163.3 kB 2.5 MB/s eta 0:00:00\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.6.1\n"]}],"source":["! pip install torch\n","! pip install transformers\n","! pip install tqdm \n","! pip install pandas\n","! pip install torchmetrics\n","! pip install -U sentence-transformers"]},{"cell_type":"code","execution_count":337,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T18:47:38.192174Z","iopub.status.busy":"2024-03-27T18:47:38.191793Z","iopub.status.idle":"2024-03-27T18:47:38.197215Z","shell.execute_reply":"2024-03-27T18:47:38.196152Z","shell.execute_reply.started":"2024-03-27T18:47:38.192142Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import tqdm\n","import pandas as pd\n","from torchmetrics.regression import PearsonCorrCoef\n","from sentence_transformers import SentenceTransformer, util, InputExample, losses, models, evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the data"]},{"cell_type":"code","execution_count":338,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:24.096808Z","iopub.status.busy":"2024-03-27T19:00:24.095951Z","iopub.status.idle":"2024-03-27T19:00:24.105159Z","shell.execute_reply":"2024-03-27T19:00:24.104096Z","shell.execute_reply.started":"2024-03-27T19:00:24.096779Z"},"trusted":true},"outputs":[],"source":["def load_data(file_path):\n","    data = pd.read_table(file_path)\n","    # check if any missing values\n","    print(data.isnull().sum())\n","    key = data.keys()\n","    # some values were missing in sentence2 column, so did the below (sentence1 didnt split properly)\n","    # iterate through the rows in dataframe which have missing values\n","    for index, row in data[data.isnull().any(axis=1)].iterrows():\n","        if pd.isnull(row[key[2]]):\n","            if(len(row[key[1]].split('\\t')) > 2 or len(row[key[1]].split('\\t')) < 2):\n","                data.drop(index, inplace=True)\n","                continue\n","            # split the sentence1 into words into 2 parts based on \\t and assign to sentence1 and sentence2\n","            sentence1, sentence2 = row[key[1]].split('\\t')\n","            score = row[key[0]]\n","            # assign to the row\n","            data.at[index, key[1]] = sentence1\n","            data.at[index, key[2]] = sentence2\n","            data.at[index, key[0]] = score\n","    #rescale every score in data from 0-5 to 0-1\n","    data[key[0]] = data[key[0]]/5\n","    return data"]},{"cell_type":"code","execution_count":339,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:24.552045Z","iopub.status.busy":"2024-03-27T19:00:24.551179Z","iopub.status.idle":"2024-03-27T19:00:24.599486Z","shell.execute_reply":"2024-03-27T19:00:24.598450Z","shell.execute_reply.started":"2024-03-27T19:00:24.552010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["score        0\n","sentence1    0\n","sentence2    5\n","dtype: int64\n","score        0\n","sentence1    0\n","sentence2    2\n","dtype: int64\n"]}],"source":["train_data = load_data('train.csv')\n","valid_data = load_data('dev.csv')"]},{"cell_type":"code","execution_count":340,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:25.004231Z","iopub.status.busy":"2024-03-27T19:00:25.003542Z","iopub.status.idle":"2024-03-27T19:00:25.015522Z","shell.execute_reply":"2024-03-27T19:00:25.014649Z","shell.execute_reply.started":"2024-03-27T19:00:25.004199Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1460</th>\n","      <td>0.4</td>\n","      <td>New UN peacekeeping chief named for Central Af...</td>\n","      <td>UN takes over peacekeeping in Central African ...</td>\n","    </tr>\n","    <tr>\n","      <th>1461</th>\n","      <td>1.0</td>\n","      <td>Oil falls in Asian trade</td>\n","      <td>Oil prices down in Asian trade</td>\n","    </tr>\n","    <tr>\n","      <th>1462</th>\n","      <td>0.6</td>\n","      <td>Israeli forces detain Palestinian MP in Hebron</td>\n","      <td>Israeli forces detain 2 Palestinians in overni...</td>\n","    </tr>\n","    <tr>\n","      <th>1463</th>\n","      <td>0.6</td>\n","      <td>Israeli police clash with Palestinian proteste...</td>\n","      <td>Israel Police Clash With Palestinians in Jerus...</td>\n","    </tr>\n","    <tr>\n","      <th>1464</th>\n","      <td>0.0</td>\n","      <td>3 killed, 4 injured in Los Angeles shootings</td>\n","      <td>Five killed in Saudi Arabia shooting</td>\n","    </tr>\n","    <tr>\n","      <th>1465</th>\n","      <td>0.4</td>\n","      <td>Scientists prove there is water on Mars</td>\n","      <td>Has Nasa discovered water on Mars?</td>\n","    </tr>\n","    <tr>\n","      <th>1466</th>\n","      <td>0.0</td>\n","      <td>Pranab stresses need to strive for peace by na...</td>\n","      <td>WTO: India regrets action of developed nations</td>\n","    </tr>\n","    <tr>\n","      <th>1467</th>\n","      <td>0.4</td>\n","      <td>Volkswagen skids into red in wake of pollution...</td>\n","      <td>Volkswagen's \"gesture of goodwill\" to diesel o...</td>\n","    </tr>\n","    <tr>\n","      <th>1468</th>\n","      <td>0.0</td>\n","      <td>Obama is right: Africa deserves better leadership</td>\n","      <td>Obama waiting for midterm to name attorney gen...</td>\n","    </tr>\n","    <tr>\n","      <th>1469</th>\n","      <td>0.0</td>\n","      <td>New video shows US police officers beating men...</td>\n","      <td>New York police officer critically wounded in ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      score                                          sentence1  \\\n","1460    0.4  New UN peacekeeping chief named for Central Af...   \n","1461    1.0                           Oil falls in Asian trade   \n","1462    0.6     Israeli forces detain Palestinian MP in Hebron   \n","1463    0.6  Israeli police clash with Palestinian proteste...   \n","1464    0.0       3 killed, 4 injured in Los Angeles shootings   \n","1465    0.4            Scientists prove there is water on Mars   \n","1466    0.0  Pranab stresses need to strive for peace by na...   \n","1467    0.4  Volkswagen skids into red in wake of pollution...   \n","1468    0.0  Obama is right: Africa deserves better leadership   \n","1469    0.0  New video shows US police officers beating men...   \n","\n","                                              sentence2  \n","1460  UN takes over peacekeeping in Central African ...  \n","1461                     Oil prices down in Asian trade  \n","1462  Israeli forces detain 2 Palestinians in overni...  \n","1463  Israel Police Clash With Palestinians in Jerus...  \n","1464               Five killed in Saudi Arabia shooting  \n","1465                 Has Nasa discovered water on Mars?  \n","1466     WTO: India regrets action of developed nations  \n","1467  Volkswagen's \"gesture of goodwill\" to diesel o...  \n","1468  Obama waiting for midterm to name attorney gen...  \n","1469  New York police officer critically wounded in ...  "]},"execution_count":340,"metadata":{},"output_type":"execute_result"}],"source":["valid_data.tail(10)"]},{"cell_type":"code","execution_count":341,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:25.476615Z","iopub.status.busy":"2024-03-27T19:00:25.476175Z","iopub.status.idle":"2024-03-27T19:00:25.487699Z","shell.execute_reply":"2024-03-27T19:00:25.486465Z","shell.execute_reply.started":"2024-03-27T19:00:25.476583Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(5709, 3)\n","score\n","0.0000    367\n","0.8000    351\n","0.6000    308\n","1.0000    265\n","0.7600    263\n","         ... \n","0.0134      1\n","0.1454      1\n","0.3400      1\n","0.3556      1\n","0.8660      1\n","Name: count, Length: 139, dtype: int64\n"]}],"source":["print(train_data.shape)\n","print(train_data['score'].value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["### Defining device variable"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:26.299861Z","iopub.status.busy":"2024-03-27T19:00:26.299491Z","iopub.status.idle":"2024-03-27T19:00:26.305333Z","shell.execute_reply":"2024-03-27T19:00:26.304306Z","shell.execute_reply.started":"2024-03-27T19:00:26.299832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1A: using BERT to perform regression"]},{"cell_type":"markdown","metadata":{},"source":["### Creating a dataset class"]},{"cell_type":"code","execution_count":198,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:27.531177Z","iopub.status.busy":"2024-03-27T19:00:27.530382Z","iopub.status.idle":"2024-03-27T19:00:27.538943Z","shell.execute_reply":"2024-03-27T19:00:27.538035Z","shell.execute_reply.started":"2024-03-27T19:00:27.531141Z"},"trusted":true},"outputs":[],"source":["class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, data, max_length):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text = self.data.iloc[idx]['sentence1'] + ' [SEP] ' + self.data.iloc[idx]['sentence2']\n","        inputs = self.tokenizer(text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors='pt')\n","        inputs['labels'] = torch.tensor(self.data.iloc[idx]['score'], dtype=torch.float)\n","        inputs = {key: inputs[key].squeeze() for key in inputs}\n","        return inputs"]},{"cell_type":"code","execution_count":199,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:27.860788Z","iopub.status.busy":"2024-03-27T19:00:27.860424Z","iopub.status.idle":"2024-03-27T19:00:27.865282Z","shell.execute_reply":"2024-03-27T19:00:27.864184Z","shell.execute_reply.started":"2024-03-27T19:00:27.860757Z"},"trusted":true},"outputs":[],"source":["max_length = 50"]},{"cell_type":"code","execution_count":200,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:28.935600Z","iopub.status.busy":"2024-03-27T19:00:28.935209Z","iopub.status.idle":"2024-03-27T19:00:30.152252Z","shell.execute_reply":"2024-03-27T19:00:30.151414Z","shell.execute_reply.started":"2024-03-27T19:00:28.935569Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load pre-trained model\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","sep_token = '[SEP]'\n","\n","# Load pre-trained model tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the dataset and dataloader class:"]},{"cell_type":"code","execution_count":242,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:28.587533Z","iopub.status.busy":"2024-03-27T19:00:28.587150Z","iopub.status.idle":"2024-03-27T19:00:28.593427Z","shell.execute_reply":"2024-03-27T19:00:28.592191Z","shell.execute_reply.started":"2024-03-27T19:00:28.587503Z"},"trusted":true},"outputs":[],"source":["train_dataset = TextDataset(tokenizer, train_data, max_length)\n","valid_dataset = TextDataset(tokenizer, valid_data, max_length)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:30.154574Z","iopub.status.busy":"2024-03-27T19:00:30.154160Z","iopub.status.idle":"2024-03-27T19:00:30.162478Z","shell.execute_reply":"2024-03-27T19:00:30.161616Z","shell.execute_reply.started":"2024-03-27T19:00:30.154538Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","pearson = PearsonCorrCoef()"]},{"cell_type":"markdown","metadata":{},"source":["### wandb setup"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:45.968734Z","iopub.status.busy":"2024-03-27T19:00:45.967763Z","iopub.status.idle":"2024-03-27T19:01:01.020383Z","shell.execute_reply":"2024-03-27T19:01:01.019472Z","shell.execute_reply.started":"2024-03-27T19:00:45.968699Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login(relogin=True)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:15.795182Z","iopub.status.busy":"2024-03-27T19:01:15.794175Z","iopub.status.idle":"2024-03-27T19:01:15.799723Z","shell.execute_reply":"2024-03-27T19:01:15.798774Z","shell.execute_reply.started":"2024-03-27T19:01:15.795143Z"},"trusted":true},"outputs":[],"source":["model_config = dict(\n","    task = 1,\n","    part = 'A',\n","    model_name = 'bert-base-uncased',\n","    max_length = 50,\n","    batch_size = 8,\n","    learning_rate = 1e-5,\n","    optimizer = 'Adam',\n","    criterion = 'MSELoss',\n","    epochs = 5\n",")"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:16.660924Z","iopub.status.busy":"2024-03-27T19:01:16.660214Z","iopub.status.idle":"2024-03-27T19:01:51.635317Z","shell.execute_reply":"2024-03-27T19:01:51.634309Z","shell.execute_reply.started":"2024-03-27T19:01:16.660889Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"939f911f846346029d7ebab7321bf109","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112954300001043, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240327_190116-tm3vov2c</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/nlp-assignments/assignment-3/runs/tm3vov2c' target=\"_blank\">proud-bird-8</a></strong> to <a href='https://wandb.ai/nlp-assignments/assignment-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/nlp-assignments/assignment-3' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/nlp-assignments/assignment-3/runs/tm3vov2c' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-3/runs/tm3vov2c</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp-assignments/assignment-3/runs/tm3vov2c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a5c41211570>"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project='assignment-3', entity= 'nlp-assignments', config=model_config)"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the model architecture:"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:51.637508Z","iopub.status.busy":"2024-03-27T19:01:51.637157Z","iopub.status.idle":"2024-03-27T19:01:51.768173Z","shell.execute_reply":"2024-03-27T19:01:51.767327Z","shell.execute_reply.started":"2024-03-27T19:01:51.637470Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Model(\n","  (model): BertForSequenceClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=1, bias=True)\n","  )\n",")"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["class Model(torch.nn.Module):\n","    def __init__(self, model):\n","        super(Model, self).__init__()\n","        self.model = model\n","\n","    def forward(self, input_ids, attention_mask, labels):\n","        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n","        return outputs.loss, outputs.logits\n","    \n","model = Model(model)\n","model.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Defining train and evaluation loops"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:51.769835Z","iopub.status.busy":"2024-03-27T19:01:51.769561Z","iopub.status.idle":"2024-03-27T19:01:51.783449Z","shell.execute_reply":"2024-03-27T19:01:51.782487Z","shell.execute_reply.started":"2024-03-27T19:01:51.769810Z"},"trusted":true},"outputs":[],"source":["def train(model, loader, optimizer, epochs=1, valid_loader=None):\n","    # wandb.define_metric('epoch')\n","    # wandb.define_metric('training_loss', step_metric='epoch')\n","    # wandb.define_metric('validation_loss', step_metric='epoch')\n","    # wandb.define_metric('Pearson Correlation', step_metric='epoch')\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in tqdm.tqdm(loader):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            optimizer.zero_grad()\n","            loss, preds = model(input_ids, attention_mask, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        print(f'Epoch: {epoch + 1}, Training loss: {total_loss / len(loader)}')\n","        epoch_log = {}\n","        if(valid_loader is not None):\n","            loss, corr = evaluate(model, valid_loader)\n","        #     epoch_log['validation_loss'] = loss\n","        #     epoch_log['Pearson Correlation'] = corr\n","        # epoch_log['epoch'] = epoch\n","        # epoch_log['training_loss'] = total_loss / len(loader)\n","        # wandb.log(epoch_log)\n","    return total_loss / len(loader)\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    total_loss = 0\n","    predicted = torch.tensor([])\n","    all_labels = torch.tensor([])\n","    with torch.no_grad():\n","        for batch in tqdm.tqdm(loader):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            loss, preds = model(input_ids, attention_mask, labels)\n","            total_loss += loss.item()\n","            for i in preds:\n","                i = i.cpu()\n","                predicted = torch.cat((predicted, i))\n","            for i in labels:\n","                i = i.cpu()\n","                i = torch.tensor([i])\n","                all_labels = torch.cat((all_labels, i))\n","    print(f'Validation loss: {total_loss / len(loader)}, Pearson correlation: {pearson(predicted, all_labels)}')\n","    return total_loss / len(loader), pearson(predicted, all_labels).item()"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:51.785571Z","iopub.status.busy":"2024-03-27T19:01:51.785289Z","iopub.status.idle":"2024-03-27T19:06:30.435702Z","shell.execute_reply":"2024-03-27T19:06:30.434605Z","shell.execute_reply.started":"2024-03-27T19:01:51.785547Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 714/714 [00:51<00:00, 13.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Training loss: 0.06139531917283077\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [00:05<00:00, 35.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.034116377368184694, Pearson correlation: 0.8023785948753357\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 714/714 [00:50<00:00, 14.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Training loss: 0.020675181214246347\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [00:05<00:00, 35.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.02697314087898754, Pearson correlation: 0.8386620879173279\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 714/714 [00:50<00:00, 14.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Training loss: 0.010633578259042655\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [00:05<00:00, 35.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.026718384039628763, Pearson correlation: 0.8420818448066711\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 714/714 [00:50<00:00, 14.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Training loss: 0.005479094146731954\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [00:05<00:00, 35.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.02651181103568018, Pearson correlation: 0.8404891490936279\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 714/714 [00:50<00:00, 14.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Training loss: 0.003137762849714805\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [00:05<00:00, 35.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.030492372087040996, Pearson correlation: 0.8379072546958923\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["0.003137762849714805"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["train(model, train_loader, optimizer, epochs=5, valid_loader=valid_loader)\n","# evaluate(model, valid_loader)"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:06:37.391023Z","iopub.status.busy":"2024-03-27T19:06:37.390751Z","iopub.status.idle":"2024-03-27T19:06:37.395142Z","shell.execute_reply":"2024-03-27T19:06:37.394318Z","shell.execute_reply.started":"2024-03-27T19:06:37.390998Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:06:38.519923Z","iopub.status.busy":"2024-03-27T19:06:38.518841Z","iopub.status.idle":"2024-03-27T19:06:39.487463Z","shell.execute_reply":"2024-03-27T19:06:39.486343Z","shell.execute_reply.started":"2024-03-27T19:06:38.519876Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '1A_model.pt')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["id           0\n","\n","score        0\n","\n","setence1     0\n","\n","sentence2    0\n","\n","dtype: int64\n"]}],"source":["#load data from sample_demo.csv\n","test_data = load_data('/kaggle/input/nlp-a3/sample_demo.csv')\n","test_dataset = TextDataset(tokenizer, test_data, max_length)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'model.pt'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m evaluate(model, test_loader)\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pt'"]}],"source":["model.load_state_dict(torch.load('model.pt'))\n","evaluate(model, test_loader)"]},{"cell_type":"markdown","metadata":{},"source":["### Part 1B"]},{"cell_type":"code","execution_count":356,"metadata":{},"outputs":[],"source":["# Load the BERT base model\n","bert_model = models.Transformer('bert-base-uncased')\n","\n","# Define the pooling layer\n","pooling_model = models.Pooling(bert_model.get_word_embedding_dimension())\n","\n","# Create the Sentence Transformer model\n","model = SentenceTransformer(modules=[bert_model, pooling_model])\n"]},{"cell_type":"code","execution_count":357,"metadata":{},"outputs":[],"source":["class SentenceDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sentence1 = self.data.iloc[idx, 1]\n","        sentence2 = self.data.iloc[idx, 2]\n","        score = self.data.iloc[idx, 0]\n","        return [sentence1, sentence2], score\n","    "]},{"cell_type":"code","execution_count":358,"metadata":{},"outputs":[],"source":["def validation(model, valid_loader):\n","    model.eval()\n","    all_scores = []\n","    all_targets = []\n","    with torch.no_grad():\n","        for batch in tqdm.tqdm(valid_loader):\n","            sentences, targets = batch\n","            # print(len(sentences[0]), len(targets))\n","            for i in range(len(targets)):\n","                sentence1_features = model.encode(sentences[0][i], convert_to_tensor=True)\n","                sentence2_features = model.encode(sentences[1][i], convert_to_tensor=True)\n","                score = util.pytorch_cos_sim(sentence1_features, sentence2_features)\n","                all_scores.append(score.item())\n","                all_targets.append(targets[i])\n","    return pearson(torch.tensor(all_scores), torch.tensor(all_targets))"]},{"cell_type":"code","execution_count":359,"metadata":{},"outputs":[],"source":["train_dataset = SentenceDataset(train_data)\n","valid_dataset = SentenceDataset(valid_data)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=False)\n","\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"]},{"cell_type":"code","execution_count":360,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 184/184 [03:44<00:00,  1.22s/it]\n"]},{"data":{"text/plain":["tensor(0.5855)"]},"execution_count":360,"metadata":{},"output_type":"execute_result"}],"source":["validation(model, valid_loader)"]},{"cell_type":"markdown","metadata":{},"source":["### Part 1C"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":350,"metadata":{},"outputs":[],"source":["class SentenceDataset(torch.utils.data.Dataset):\n","    # def __init__(self, data, max_length):\n","    #     self.data = data\n","    #     self.max_length = max_length\n","\n","    # def __len__(self):\n","    #     return len(self.data)\n","\n","    # def __getitem__(self, idx):\n","    #     return self.data.iloc[idx]['sentence1'], self.data.iloc[idx]['sentence2'], self.data.iloc[idx]['score'] \n","    def __init__(self, tokenizer, data, max_length):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sentence1 = self.data.iloc[idx]['sentence1']\n","        sentence2 = self.data.iloc[idx]['sentence2']\n","        score = self.data.iloc[idx]['score']\n","        #tokenize\n","        inputs = self.tokenizer(sentence1, sentence2, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors='pt')\n","        inputs['labels'] = torch.tensor(score, dtype=torch.float)\n","        inputs = {key: inputs[key].squeeze() for key in inputs}\n","        return inputs\n"]},{"cell_type":"code","execution_count":351,"metadata":{},"outputs":[],"source":["transformed_train_data = [InputExample(texts=[train_data.iloc[i]['sentence1'], train_data.iloc[i]['sentence2']], label=train_data.iloc[i]['score']) for i in range(len(train_data))]\n","transformed_valid_data = [InputExample(texts=[valid_data.iloc[i]['sentence1'], valid_data.iloc[i]['sentence2']], label=valid_data.iloc[i]['score']) for i in range(len(valid_data))]"]},{"cell_type":"code","execution_count":352,"metadata":{},"outputs":[],"source":["def get_data(data):\n","    sentence1 = data['sentence1'].tolist()\n","    sentence2 = data['sentence2'].tolist()\n","    score = data['score'].tolist()\n","    return sentence1, sentence2, torch.tensor(score)"]},{"cell_type":"code","execution_count":353,"metadata":{},"outputs":[],"source":["def evaluate_sentence(model, dataloader):\n","    model.eval()\n","    predicted = torch.tensor([])\n","    all_labels = torch.tensor([])\n","    for i in tqdm.tqdm(dataloader):\n","        sentences_features, labels = i\n","        sentences_features = {key: value.to(device) for key, value in sentences_features.items()}\n","        labels = labels.to(device)\n","        with torch.no_grad():\n","            outputs = model(**sentences_features, labels=labels)\n","        for i in outputs.logits:    \n","            i = i.cpu()\n","            predicted = torch.cat((predicted, i))\n","        for i in labels:\n","            i = i.cpu()\n","            all_labels = torch.cat((all_labels, i))\n","    print(f'Pearson correlation: {pearson(predicted, all_labels)}')\n","    return pearson(predicted, all_labels).item()"]},{"cell_type":"code","execution_count":354,"metadata":{},"outputs":[],"source":["class CosineLoss(torch.nn.Module):\n","    def __init__(self, model, loss_fct= torch.nn.MSELoss(), cos_score_transformation= torch.nn.Identity()):\n","        super(CosineLoss, self).__init__()\n","        self.model = model\n","        self.loss_fct = loss_fct\n","        self.cos_score_transformation = cos_score_transformation\n","\n","    def forward(self, sentence1, sentence2, score):\n","        sentence1 = self.model.encode(sentence1, convert_to_tensor=True, device=device)\n","        sentence2 = self.model.encode(sentence2, convert_to_tensor=True, device=device)\n","        output = self.cos_score_transformation(torch.cosine_similarity(sentence1, sentence2))\n","        return self.loss_fct(output, score)"]},{"cell_type":"code","execution_count":355,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/184 [00:00<?, ?it/s]\n"]},{"ename":"AttributeError","evalue":"'list' object has no attribute 'items'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[355], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# evaluator = evaluation.EmbeddingSimilarityEvaluator(valid_loader)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m pearson_1b \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# wandb.init(project='assignment-3', entity= 'nlp-assignments', config=model_config)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# model.fit(train_objectives=[(train_loader, loss)], epochs=5, optimizer_params={'lr': 1e-5})\u001b[39;00m\n","Cell \u001b[1;32mIn[353], line 7\u001b[0m, in \u001b[0;36mevaluate_sentence\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(dataloader):\n\u001b[0;32m      6\u001b[0m     sentences_features, labels \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m----> 7\u001b[0m     sentences_features \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentences_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()}\n\u001b[0;32m      8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"]}],"source":["train_dataset = SentenceDataset(tokenizer, train_data, max_length)\n","valid_dataset = SentenceDataset(tokenizer, valid_data, max_length)\n","\n","# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=False)\n","train_loader = torch.utils.data.DataLoader(transformed_train_data, shuffle=True, batch_size=8)\n","valid_loader = torch.utils.data.DataLoader(transformed_valid_data, shuffle=False, batch_size=8)\n","train_loader.collate_fn = model.smart_batching_collate\n","valid_loader.collate_fn = model.smart_batching_collate\n","\n","word_embedding_model = models.Transformer('bert-base-uncased')\n","pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n","model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","loss = losses.CosineSimilarityLoss(model)\n","train_loss = CosineSimilarityLoss(model=model)\n","valid_loss = CosineSimilarityLoss(model=model)\n","# evaluator = evaluation.EmbeddingSimilarityEvaluator(valid_loader)\n","\n","model.to(device)\n","pearson_1b = evaluate_sentence(model, valid_loader)\n","# wandb.init(project='assignment-3', entity= 'nlp-assignments', config=model_config)\n","\n","# model.fit(train_objectives=[(train_loader, loss)], epochs=5, optimizer_params={'lr': 1e-5})\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.10537926107645035\n"]}],"source":["print(pearson_1b)"]},{"cell_type":"markdown","metadata":{},"source":["### Part 1C"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/714 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["('GOP candidate Romney to call to arm Syrian rebels', '3 suspected extremists were released on bail.', 'Two dogs are playing around in the dirt.', 'How would Martin not know that that was not the case?', 'Lay had argued that handing over the documents would be a violation of his Fifth Amendment rights against self-incrimination.', 'Ex-Virginia governor Bob McDonnell charged with corruption', 'photo of a television screen showing a movie.', 'a white dog running in the snow')\n","('US helping get arms to Syria rebels', '1 suspected extremist was provisionally released without bail.', 'A dancer posing for the camera in a red and white dress.', 'How would Martin or anyone else know his intentions based on his actions?', 'Lay had refused to turn over the papers, asserting his Fifth Amendment right against self-incrimination.', \"Virginia's ex-Gov. Bob McDonnell, wife charged with corruption\", 'The wall-mounted flat-screen TV is showing a movie.', 'The dogs are running in the snow.')\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/714 [00:00<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[191], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m             pearson \u001b[38;5;241m=\u001b[39m evaluate_sentence(model, valid_loader)\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPearson correlation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpearson\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[191], line 10\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(model, train_loader, loss_fn, optimizer, epochs, valid_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(sentence1, sentence2, score)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["def trainer(model, train_loader, loss_fn, optimizer, epochs=2, valid_loader = None):\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        for i in tqdm.tqdm(train_loader):\n","            sentence1, sentence2, score = i\n","            embeddings = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n","            output = self.cos_score_transformation(torch.cosine_similarity(embeddings[0], embeddings[1]))\n","            score = torch.tensor(score, dtype=torch.float).to(device)\n","            loss = loss_fn(sentence1, sentence2, score)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        print(f'Epoch: {epoch + 1}, Training loss: {total_loss / len(train_loader)}')\n","        if(valid_loader is not None):\n","            pearson = evaluate_sentence(model, valid_loader)\n","            print(f'Pearson correlation: {pearson}')\n","    \n","trainer(model, train_loader, loss, optimizer, epochs=2, valid_loader=valid_loader)"]},{"cell_type":"code","execution_count":295,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]])}, {'input_ids': tensor([[  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]])}]\n","tensor([0.6208, 0.5664, 0.5365, 0.6643], grad_fn=<SumBackward1>) tensor([0.8000, 0.3000, 0.3000, 0.8000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n","Epoch:  10%|█         | 1/10 [00:00<00:07,  1.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0]])}, {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0]])}]\n","tensor([0.6017, 0.5778, 0.6144, 0.5989], grad_fn=<SumBackward1>) tensor([0.3000, 0.8000, 0.8000, 0.3000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n","Epoch:  20%|██        | 2/10 [00:01<00:05,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1]])}, {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1]])}]\n","tensor([0.5945, 0.5982, 0.6136, 0.6013], grad_fn=<SumBackward1>) tensor([0.3000, 0.3000, 0.8000, 0.8000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n","Epoch:  30%|███       | 3/10 [00:02<00:04,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2178, 3940,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0]])}, {'input_ids': tensor([[  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101, 15142,  6251,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0]])}]\n","tensor([0.7006, 0.6271, 0.5876, 0.5627], grad_fn=<SumBackward1>) tensor([0.8000, 0.8000, 0.3000, 0.3000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n","Epoch:  40%|████      | 4/10 [00:02<00:03,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2178, 3940,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0]])}, {'input_ids': tensor([[  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101, 15142,  6251,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0]])}]\n","tensor([0.6482, 0.6376, 0.6369, 0.5850], grad_fn=<SumBackward1>) tensor([0.8000, 0.8000, 0.3000, 0.3000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n","Epoch:  50%|█████     | 5/10 [00:03<00:03,  1.61it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1]])}, {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1]])}]\n","tensor([0.6247, 0.6023, 0.6234, 0.6322], grad_fn=<SumBackward1>) tensor([0.3000, 0.3000, 0.8000, 0.8000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n","Epoch:  60%|██████    | 6/10 [00:03<00:02,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0]])}, {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0]])}]\n","tensor([0.5125, 0.6705, 0.5742, 0.5438], grad_fn=<SumBackward1>) tensor([0.3000, 0.8000, 0.8000, 0.3000])\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n","Iteration:   0%|          | 0/1 [00:00<?, ?it/s]it/s]\n","Epoch:  70%|███████   | 7/10 [00:04<00:01,  1.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102],\n","        [ 101, 2178, 3940,  102,    0],\n","        [ 101, 2026, 2034, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]])}, {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102],\n","        [  101, 15142,  6251,   102,     0],\n","        [  101,  2026,  2117,  6251,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]])}]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[295], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_examples, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mtrain_batch_size)\n\u001b[0;32m     78\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m CosineSimilarityLoss(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1035\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     skip_scheduler \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mget_scale() \u001b[38;5;241m!=\u001b[39m scale_before_step\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1035\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   1037\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[295], line 63\u001b[0m, in \u001b[0;36mCosineSimilarityLoss.forward\u001b[1;34m(self, sentence_features, labels)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentence_features)\n\u001b[1;32m---> 63\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[0;32m     64\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcos_score_transformation(torch\u001b[38;5;241m.\u001b[39mcosine_similarity(embeddings[\u001b[38;5;241m0\u001b[39m], embeddings[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:822\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[1;32m--> 822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:587\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    579\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    580\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    581\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m         output_attentions,\n\u001b[0;32m    585\u001b[0m     )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:513\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    522\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\saras\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:243\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    240\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    242\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(dim_per_head)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    244\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(mask_reshp)\u001b[38;5;241m.\u001b[39mexpand_as(scores)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    245\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(\n\u001b[0;32m    246\u001b[0m     mask, torch\u001b[38;5;241m.\u001b[39mtensor(torch\u001b[38;5;241m.\u001b[39mfinfo(scores\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin)\n\u001b[0;32m    247\u001b[0m )  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","from torch import nn, Tensor\n","from typing import Iterable, Dict\n","\n","\n","class CosineSimilarityLoss(nn.Module):\n","    def __init__(self, model: SentenceTransformer, loss_fct=nn.MSELoss(), cos_score_transformation=nn.Identity()):\n","        \"\"\"\n","        CosineSimilarityLoss expects that the InputExamples consists of two texts and a float label. It computes the\n","        vectors ``u = model(sentence_A)`` and ``v = model(sentence_B)`` and measures the cosine-similarity between the two.\n","        By default, it minimizes the following loss: ``||input_label - cos_score_transformation(cosine_sim(u,v))||_2``.\n","\n","        :param model: SentenceTransformer model\n","        :param loss_fct: Which pytorch loss function should be used to compare the ``cosine_similarity(u, v)`` with the input_label?\n","            By default, MSE is used: ``||input_label - cosine_sim(u, v)||_2``\n","        :param cos_score_transformation: The cos_score_transformation function is applied on top of cosine_similarity.\n","            By default, the identify function is used (i.e. no change).\n","\n","        References:\n","            - `Training Examples > Semantic Textual Similarity <../../examples/training/sts/README.html>`_\n","\n","        Requirements:\n","            1. Sentence pairs with corresponding similarity scores in range `[0, 1]`\n","\n","        Relations:\n","            - :class:`CoSENTLoss` seems to produce a stronger training signal than CosineSimilarityLoss. In our experiments, CoSENTLoss is recommended.\n","            - :class:`AnglELoss` is :class:`CoSENTLoss` with ``pairwise_angle_sim`` as the metric, rather than ``pairwise_cos_sim``. It also produces a stronger training signal than CosineSimilarityLoss.\n","\n","        Inputs:\n","            +--------------------------------+------------------------+\n","            | Texts                          | Labels                 |\n","            +================================+========================+\n","            | (sentence_A, sentence_B) pairs | float similarity score |\n","            +--------------------------------+------------------------+\n","\n","        Example:\n","            ::\n","\n","                from sentence_transformers import SentenceTransformer, InputExample, losses\n","                from torch.utils.data import DataLoader\n","\n","                model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n","                train_examples = [\n","                    InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n","                    InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3)\n","                ]\n","                train_batch_size = 1\n","                train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n","                train_loss = losses.CosineSimilarityLoss(model=model)\n","\n","                model.fit(\n","                    [(train_dataloader, train_loss)],\n","                    epochs=10,\n","                )\n","        \"\"\"\n","        super(CosineSimilarityLoss, self).__init__()\n","        self.model = model\n","        self.loss_fct = loss_fct\n","        self.cos_score_transformation = cos_score_transformation\n","\n","    def forward(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor):\n","        embeddings = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n","        output = self.cos_score_transformation(torch.cosine_similarity(embeddings[0], embeddings[1]))\n","        return self.loss_fct(output, labels.view(-1))\n","\n","\n","model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n","train_examples = [\n","    InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n","    InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3),\n","    InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n","    InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3),\n","]\n","train_batch_size = 4\n","train_dataloader = torch.utils.data.DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n","train_loss = CosineSimilarityLoss(model=model)\n","\n","model.fit(\n","[(train_dataloader, train_loss)],\n","epochs=10,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4681581,"sourceId":7958772,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
