{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 660.6 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.3/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install Sentencepiece\n",
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vartika\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download hugging face datasets\n",
    "import datasets\n",
    "import sentencepiece\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Data = datasets.load_dataset(\"wmt16\",\"de-en\", split=\"train[:50000]\")\n",
    "val_Data = datasets.load_dataset(\"wmt16\",\"de-en\", split=\"validation\")\n",
    "test_Data = datasets.load_dataset(\"wmt16\",\"de-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google-t5/t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 2169\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_Data)\n",
    "# take only 10 samples for testing\n",
    "# validation_data = []\n",
    "# for i in range(10):\n",
    "#     validation_data.append(val_Data[i])\n",
    "# print(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2169/2169 [38:49<00:00,  1.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for validation set: 0.2647026391581188\n"
     ]
    }
   ],
   "source": [
    "translations_validation = []\n",
    "translations_testing = []\n",
    "validation_data = val_Data\n",
    "# testing_data = test_Data\n",
    "\n",
    "\n",
    "# for data in [validation_data, testing_data]:\n",
    "for example in tqdm(validation_data):\n",
    "    # Prepend the prefix for translation task\n",
    "    input_text = \"translate English to German: \" + example[\"translation\"][\"de\"]\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    # Generate translation\n",
    "    translated_ids = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True)\n",
    "    # Decode the translated ids\n",
    "    translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    # if data == validation_data:\n",
    "    translations_validation.append(translated_text)\n",
    "    # else:\n",
    "        # translations_testing.append(translated_text)\n",
    "\n",
    "# Calculate BLEU score for validation and testing translations\n",
    "reference_validation = [example[\"translation\"][\"en\"] for example in validation_data]\n",
    "# reference_testing = [example[\"translation\"][\"en\"] for example in testing_data]\n",
    "\n",
    "bleu_score_validation = corpus_bleu([[ref] for ref in reference_validation], translations_validation)\n",
    "# bleu_score_testing = corpus_bleu([[ref] for ref in reference_testing], translations_testing)\n",
    "\n",
    "print(\"BLEU score for validation set:\", bleu_score_validation)\n",
    "# print(\"BLEU score for testing set:\", bleu_score_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vartika\\anaconda3\\envs\\dl\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vartika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vartika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vartika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'translations_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m meteor \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m meteor_score \u001b[38;5;241m=\u001b[39m meteor\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39m\u001b[43mtranslations_validation\u001b[49m, references\u001b[38;5;241m=\u001b[39mreference_validation)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETEOR score for validation set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, meteor_score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translations_validation' is not defined"
     ]
    }
   ],
   "source": [
    "meteor = datasets.load_metric(\"meteor\")\n",
    "meteor_score = meteor.compute(predictions=translations_validation, references=reference_validation)\n",
    "print(\"METEOR score for validation set:\", meteor_score)\n",
    "\n",
    "# install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use meteor from hugging face evaluate\n",
    "# meteor = datasets.load_metric(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install bert_score\n",
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Score\n",
    "from bert_score import score\n",
    "P, R, F1 = score(translations_validation, reference_validation, lang=\"en\", verbose=True)\n",
    "print(\"BERT Score for validation set:\", F1.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}, {'translation': {'de': 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.', 'en': 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'}}, {'translation': {'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\"}}, {'translation': {'de': 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.', 'en': 'You have requested a debate on this subject in the course of the next few days, during this part-session.'}}, {'translation': {'de': 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.', 'en': \"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\"}}, {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}, {'translation': {'de': '(Das Parlament erhebt sich zu einer Schweigeminute.)', 'en': \"(The House rose and observed a minute' s silence)\"}}, {'translation': {'de': 'Frau Präsidentin, zur Geschäftsordnung.', 'en': 'Madam President, on a point of order.'}}, {'translation': {'de': 'Wie Sie sicher aus der Presse und dem Fernsehen wissen, gab es in Sri Lanka mehrere Bombenexplosionen mit zahlreichen Toten.', 'en': 'You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.'}}, {'translation': {'de': 'Zu den Attentatsopfern, die es in jüngster Zeit in Sri Lanka zu beklagen gab, zählt auch Herr Kumar Ponnambalam, der dem Europäischen Parlament erst vor wenigen Monaten einen Besuch abgestattet hatte.', 'en': 'One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.'}}]\n",
      "[{'translation': {'de': 'Die Premierminister Indiens und Japans trafen sich in Tokio.', 'en': 'India and Japan prime ministers meet in Tokyo'}}, {'translation': {'de': 'Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.', 'en': \"India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\"}}, {'translation': {'de': 'Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.', 'en': 'Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.'}}, {'translation': {'de': 'Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.', 'en': 'High on the agenda are plans for greater nuclear co-operation.'}}, {'translation': {'de': 'Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.', 'en': 'India is also reportedly hoping for a deal on defence collaboration between the two nations.'}}, {'translation': {'de': 'Polizei von Karratha verhaftet 20-Jährigen nach schneller Motorradjagd', 'en': 'Karratha police arrest 20-year-old after high speed motorcycle chase'}}, {'translation': {'de': 'Ein Motorrad wurde beschlagnahmt, nachdem der Fahrer es mit 125 km/h in einer 70 km/h-Zone und durch Buschland gefahren hatte, um der Polizei in Bilbara zu entkommen.', 'en': 'A motorcycle has been seized after it was ridden at 125km/h in a 70km/h zone and through bushland to escape police in the Pilbara.'}}, {'translation': {'de': 'Verkehrspolizisten in Karratha versuchten heute morgen, ein blaues Motorrad zu stoppen, nachdem sie es dabei beobachtet hatten, wie es mit 125 km/h eine Tankstelle auf der Bathdate Road verließ.', 'en': 'Traffic police on patrol in Karratha this morning tried to pull over a blue motorcycle when they spotted it reaching 125km/h as it pulled out of a service station on Bathgate Road.'}}, {'translation': {'de': 'Die Polizei berichtet, dass der Fahrer die Haltesignale dann ignorierte und weiter auf der Burgess Road fuhr, bevor er in das Buschland abbog, wo die Beamten es aus den Augen verloren.', 'en': 'Police say the rider then failed to stop and continued on to Burgess Road before turning into bushland, causing the officers to lose sight of it.'}}, {'translation': {'de': 'Das Motorrad sowie eine Person, die der Beschreibung des Fahrers entsprach wurden später bei einem Haus im Walcott Way in Bulgarra gesehen.', 'en': 'The motorcycle and a person matching the description of the rider was then spotted at a house on Walcott Way in Bulgarra.'}}]\n",
      "[{'translation': {'de': 'Obama empfängt Netanyahu', 'en': 'Obama receives Netanyahu'}}, {'translation': {'de': 'Das Verhältnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich.', 'en': 'The relationship between Obama and Netanyahu is not exactly friendly.'}}, {'translation': {'de': 'Die beiden wollten über die Umsetzung der internationalen Vereinbarung sowie über Teherans destabilisierende Maßnahmen im Nahen Osten sprechen.', 'en': \"The two wanted to talk about the implementation of the international agreement and about Teheran's destabilising activities in the Middle East.\"}}, {'translation': {'de': 'Bei der Begegnung soll es aber auch um den Konflikt mit den Palästinensern und die diskutierte Zwei-Staaten-Lösung gehen.', 'en': 'The meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution.'}}, {'translation': {'de': 'Das Verhältnis zwischen Obama und Netanyahu ist seit Jahren gespannt.', 'en': 'Relations between Obama and Netanyahu have been strained for years.'}}, {'translation': {'de': 'Washington kritisiert den andauernden Siedlungsbau Israels und wirft Netanyahu mangelnden Willen beim Friedensprozess vor.', 'en': 'Washington criticises the continuous building of settlements in Israel and accuses Netanyahu of a lack of initiative in the peace process.'}}, {'translation': {'de': 'Durch den von Obama beworbenen Deal um das iranische Atomprogramm hat sich die Beziehung der beiden weiter verschlechtert.', 'en': \"The relationship between the two has further deteriorated because of the deal that Obama negotiated on Iran's atomic programme, .\"}}, {'translation': {'de': 'Im März hatte Netanyahu auf Einladung der Republikaner vor dem US-Kongress eine umstrittene Rede gehalten, die teils als Affront gegen Obama gewertet wurde.', 'en': 'In March, at the invitation of the Republicans, Netanyahu made a controversial speech to the US Congress, which was partly seen as an affront to Obama.'}}, {'translation': {'de': 'Die Rede war mit Obama nicht abgesprochen, ein Treffen hatte dieser mit Hinweis auf die seinerzeit bevorstehende Wahl in Israel abgelehnt.', 'en': 'The speech had not been agreed with Obama, who had rejected a meeting with reference to the election that was at that time impending in Israel.'}}, {'translation': {'de': 'In einem Notruf gesteht Professor, seine Freundin erschossen zu haben', 'en': 'In 911 Call, Professor Admits to Shooting Girlfriend'}}]\n"
     ]
    }
   ],
   "source": [
    "# take only 10 samples of training data for testing\n",
    "t_data = []\n",
    "for i in range(10):\n",
    "    t_data.append(train_Data[i])\n",
    "\n",
    "v_Data = []\n",
    "for i in range(10):\n",
    "    v_Data.append(val_Data[i])\n",
    "\n",
    "te_data = []\n",
    "for i in range(10):\n",
    "    te_data.append(test_Data[i])\n",
    "\n",
    "\n",
    "print(t_data)\n",
    "print(v_Data)\n",
    "print(te_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vartika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93910fe221dc43c2a2530457c2c318ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vartika\\anaconda3\\envs\\dl\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vartika\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475317944f1a4b75816331ab15e6395e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2283c498ac99418db57efd491500a92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"de\" \n",
    "target_lang = \"en\"\n",
    "prefix = \"translate German to English: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba21d2f893c4514803cf13fa553c99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vartika\\anaconda3\\envs\\dl\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6556352109044582af6760e57e2101ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt_data = train_Data.map(preprocess_function, batched=True)\n",
    "pt_data_v = val_Data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e5fd2a3934459e9a656ba85b6c48cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b25a251c3e41b4b232da4e2d03be2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f13b2f6aa34d6b99e731962e20f7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.5-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (69.2.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vartika\\anaconda3\\envs\\dl\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.5-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "   ---------------------------------------- 0.0/195.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 195.4/195.4 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
      "   ---------------------------------------- 0.0/264.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 264.6/264.6 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl (11 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.42 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.43.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.5\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = dict(task = \"2C\",\n",
    "                    model_name = \"t5-small\",\n",
    "                    learning_rate = 2e-5,\n",
    "                    per_device_train_batch_size = 16,\n",
    "                    per_device_eval_batch_size = 16,\n",
    "                    weight_decay = 0.01,\n",
    "                    num_train_epochs = 5,\n",
    "                    save_total_limit = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7qeve0r6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50306ab9ccef42b3aeb6ffe563b029f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.19101471727343144, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">t5-small_task2C</strong> at: <a href='https://wandb.ai/nlp-assignments/assignment-3/runs/7qeve0r6/workspace' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-3/runs/7qeve0r6/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240328_002057-7qeve0r6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7qeve0r6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b19ec4c0c3476eaa9bbaf378acc524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777779226502, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Vartika\\Documents\\GitHub\\NLP-Assignments\\A3\\wandb\\run-20240328_002837-t5kryn9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp-assignments/assignment-3/runs/t5kryn9m/workspace' target=\"_blank\">t5-small_task2C</a></strong> to <a href='https://wandb.ai/nlp-assignments/assignment-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp-assignments/assignment-3' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp-assignments/assignment-3/runs/t5kryn9m/workspace' target=\"_blank\">https://wandb.ai/nlp-assignments/assignment-3/runs/t5kryn9m/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp-assignments/assignment-3/runs/t5kryn9m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16016680350>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(relogin=True)\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"assignment-3\", entity=\"nlp-assignments\", name=\"t5-small_task2C\", config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    report_to=\"wandb\",\n",
    "    logging_dir='./logs',\n",
    "    # fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=pt_data,\n",
    "    eval_dataset=pt_data_v,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# save the model\n",
    "trainer.save_model(\"fine_tuned_t5_small_task2C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the saved model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"fine_tuned_t5_small_task2C\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_t5_small_task2C\")\n",
    "\n",
    "# Preprocess the testing data\n",
    "t_data = test_Data.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "results = trainer.predict(t_data)\n",
    "print(results.metrics)\n",
    "\n",
    "# Calculate BLEU score for validation and testing translations\n",
    "reference_testing = [example[\"translation\"][\"en\"] for example in te_data]\n",
    "translations_testing = results.predictions\n",
    "bleu_score_testing = corpus_bleu([[ref] for ref in reference_testing], translations_testing)\n",
    "print(\"BLEU score for testing set:\", bleu_score_testing)\n",
    "\n",
    "meteor = datasets.load_metric(\"meteor\")\n",
    "meteor_score = meteor.compute(predictions=translations_testing, references=reference_testing)\n",
    "print(\"METEOR score for testing set:\", meteor_score)\n",
    "\n",
    "# Bert Score\n",
    "from bert_score import score\n",
    "P, R, F1 = score(translations_testing, reference_testing, lang=\"en\", verbose=True)\n",
    "print(\"BERT Score for testing set:\", F1.mean().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
