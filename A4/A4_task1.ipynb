{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('train_file.json')\n",
    "val_data = pd.read_json('val_file.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6740\n",
      "843\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utterance_3492</td>\n",
       "      <td>[Phoebe, Eric, Phoebe, Eric, Phoebe]</td>\n",
       "      <td>[surprise, fear, surprise, sadness, disgust]</td>\n",
       "      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>utterance_3952</td>\n",
       "      <td>[Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...</td>\n",
       "      <td>[disgust, disgust, anger, sadness, surprise, a...</td>\n",
       "      <td>[Dad, please don't pick your teeth out here!, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utterance_3198</td>\n",
       "      <td>[Older Scientist, Ross, Ross, Joey, Ross, Ross...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, ...</td>\n",
       "      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterance_2834</td>\n",
       "      <td>[Monica, Monica, Monica]</td>\n",
       "      <td>[neutral, surprise, neutral]</td>\n",
       "      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utterance_453</td>\n",
       "      <td>[Kate, The Director, Kate]</td>\n",
       "      <td>[joy, sadness, sadness]</td>\n",
       "      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          episode                                           speakers  \\\n",
       "0  utterance_3492               [Phoebe, Eric, Phoebe, Eric, Phoebe]   \n",
       "1  utterance_3952  [Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...   \n",
       "2  utterance_3198  [Older Scientist, Ross, Ross, Joey, Ross, Ross...   \n",
       "3  utterance_2834                           [Monica, Monica, Monica]   \n",
       "4   utterance_453                         [Kate, The Director, Kate]   \n",
       "\n",
       "                                            emotions  \\\n",
       "0       [surprise, fear, surprise, sadness, disgust]   \n",
       "1  [disgust, disgust, anger, sadness, surprise, a...   \n",
       "2  [neutral, neutral, neutral, neutral, neutral, ...   \n",
       "3                       [neutral, surprise, neutral]   \n",
       "4                            [joy, sadness, sadness]   \n",
       "\n",
       "                                          utterances  \\\n",
       "0  [You-you\n",
       "you had sex with Ursula?!, Uh, a litt...   \n",
       "1  [Dad, please don't pick your teeth out here!, ...   \n",
       "2  [Dr. Geller, there's a seat over here., Thank ...   \n",
       "3  [So, how'd the lasagne go over?, Really?!, Good.]   \n",
       "4  [Become a drama critic!, I am hurt!  A plague ...   \n",
       "\n",
       "                                            triggers  \n",
       "0                          [1.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]  \n",
       "3                                    [0.0, 0.0, 1.0]  \n",
       "4                                    [0.0, 0.0, 1.0]  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join utterances with @ sign\n",
    "train_data['utterances'] = train_data['utterances'].apply(lambda x: '@'.join(x))\n",
    "train_data['speakers'] = train_data['speakers'].apply(lambda x: '@'.join(x))\n",
    "val_data['utterances'] = val_data['utterances'].apply(lambda x: '@'.join(x))\n",
    "val_data['speakers'] = val_data['speakers'].apply(lambda x: '@'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates \n",
    "train_data = train_data.drop_duplicates(subset=['speakers', 'utterances'], keep='first')\n",
    "val_data = val_data.drop_duplicates(subset=['speakers', 'utterances'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['utterances'] = train_data['utterances'].apply(lambda x: x.split('@'))\n",
    "train_data['speakers'] = train_data['speakers'].apply(lambda x: x.split('@'))\n",
    "val_data['utterances'] = val_data['utterances'].apply(lambda x: x.split('@'))\n",
    "val_data['speakers'] = val_data['speakers'].apply(lambda x: x.split('@'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index as we dropped rows\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You-youyou had sex with Ursula?!\n",
      "Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and\n",
      "You didn't notice she was wearing different clothes?!\n",
      "Well I was just so excited to see you.\n",
      "Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.\n"
     ]
    }
   ],
   "source": [
    "# print((train_data['utterances'][0]))\n",
    "n = len(train_data['utterances'][0])\n",
    "for i in range(n):\n",
    "    print((train_data['utterances'][0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_mapping = {}\n",
    "# unicode_mapping['\\u0085'] = '...' \n",
    "# unicode_mapping['\\u0091'] = \"'\"\n",
    "# unicode_mapping['\\u0092'] = \"'\"\n",
    "# unicode_mapping['\\u0093'] = '\"'\n",
    "# unicode_mapping['\\u0094'] = '\"'\n",
    "# unicode_mapping['\\u0097'] = '--'\n",
    "\n",
    "# unicode_mapping['\\u2014'] = '--'\n",
    "# unicode_mapping['\\u2019'] = \"'\"\n",
    "# unicode_mapping['\\u2026'] = '...'\n",
    "\n",
    "# unicode_mapping['\\u00e9'] = 'e'\n",
    "\n",
    "unicode_mapping['\\x85'] = '...' \n",
    "unicode_mapping['\\x91'] = \"'\"\n",
    "unicode_mapping['\\x92'] = \"'\"\n",
    "unicode_mapping['\\x93'] = '\"'\n",
    "unicode_mapping['\\x94'] = '\"'\n",
    "unicode_mapping['\\x97'] = '--'\n",
    "\n",
    "unicode_mapping['\\u2014'] = '--'\n",
    "unicode_mapping['\\u2019'] = \"'\"\n",
    "unicode_mapping['\\u2026'] = '...'\n",
    "\n",
    "unicode_mapping['\\xe9'] = 'e'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing unicode characters in the data\n",
    "def clean_utterance(utterance_list):\n",
    "    '''\t\n",
    "    This function takes a list of utterances and replaces the unicode with the proper characters.\n",
    "    '''\n",
    "    cleaned_utterances_list = []\n",
    "    for utterance in utterance_list:\n",
    "        for key in unicode_mapping:\n",
    "            utterance = utterance.replace(key, unicode_mapping[key])\n",
    "        cleaned_utterances_list.append(utterance)\n",
    "    return cleaned_utterances_list\n",
    "\n",
    "# clean the train data\n",
    "n_train = len(train_data['utterances'])\n",
    "for i in train_data.index:\n",
    "    temp = train_data.loc[i].copy()\n",
    "    cleaned_utterances = clean_utterance(temp['utterances'])\n",
    "    temp['utterances'] = cleaned_utterances\n",
    "    train_data.loc[i] = temp\n",
    "\n",
    "# clean the val data\n",
    "n_val = len(val_data['utterances'])\n",
    "for i in val_data.index:\n",
    "    temp = val_data.loc[i].copy()\n",
    "    cleaned_utterances = clean_utterance(temp['utterances'])\n",
    "    temp['utterances'] = cleaned_utterances\n",
    "    val_data.loc[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You-you...you had sex with Ursula?!', 'Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and', \"You didn't notice she was wearing different clothes?!\", 'Well I was just so excited to see you.', \"Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['utterances'][0])\n",
    "# print(len(train_data['utterances'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utterance_3492</td>\n",
       "      <td>[Phoebe, Eric, Phoebe, Eric, Phoebe]</td>\n",
       "      <td>[surprise, fear, surprise, sadness, disgust]</td>\n",
       "      <td>[You-you...you had sex with Ursula?!, Uh, a li...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>utterance_3952</td>\n",
       "      <td>[Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...</td>\n",
       "      <td>[disgust, disgust, anger, sadness, surprise, a...</td>\n",
       "      <td>[Dad, please don't pick your teeth out here!, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utterance_3198</td>\n",
       "      <td>[Older Scientist, Ross, Ross, Joey, Ross, Ross...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral, ...</td>\n",
       "      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterance_2834</td>\n",
       "      <td>[Monica, Monica, Monica]</td>\n",
       "      <td>[neutral, surprise, neutral]</td>\n",
       "      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utterance_453</td>\n",
       "      <td>[Kate, The Director, Kate]</td>\n",
       "      <td>[joy, sadness, sadness]</td>\n",
       "      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          episode                                           speakers  \\\n",
       "0  utterance_3492               [Phoebe, Eric, Phoebe, Eric, Phoebe]   \n",
       "1  utterance_3952  [Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...   \n",
       "2  utterance_3198  [Older Scientist, Ross, Ross, Joey, Ross, Ross...   \n",
       "3  utterance_2834                           [Monica, Monica, Monica]   \n",
       "4   utterance_453                         [Kate, The Director, Kate]   \n",
       "\n",
       "                                            emotions  \\\n",
       "0       [surprise, fear, surprise, sadness, disgust]   \n",
       "1  [disgust, disgust, anger, sadness, surprise, a...   \n",
       "2  [neutral, neutral, neutral, neutral, neutral, ...   \n",
       "3                       [neutral, surprise, neutral]   \n",
       "4                            [joy, sadness, sadness]   \n",
       "\n",
       "                                          utterances  \\\n",
       "0  [You-you...you had sex with Ursula?!, Uh, a li...   \n",
       "1  [Dad, please don't pick your teeth out here!, ...   \n",
       "2  [Dr. Geller, there's a seat over here., Thank ...   \n",
       "3  [So, how'd the lasagne go over?, Really?!, Good.]   \n",
       "4  [Become a drama critic!, I am hurt!  A plague ...   \n",
       "\n",
       "                                            triggers  \n",
       "0                          [1.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2                [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]  \n",
       "3                                    [0.0, 0.0, 1.0]  \n",
       "4                                    [0.0, 0.0, 1.0]  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 5)\n"
     ]
    }
   ],
   "source": [
    "print(val_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
