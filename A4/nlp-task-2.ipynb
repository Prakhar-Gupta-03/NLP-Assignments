{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8105128,"sourceType":"datasetVersion","datasetId":4786948},{"sourceId":8105140,"sourceType":"datasetVersion","datasetId":4786957}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#install torch\n%pip install torch==2.2.0 torchvision torchaudio\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:47:02.951506Z","iopub.execute_input":"2024-04-18T20:47:02.952440Z","iopub.status.idle":"2024-04-18T20:47:04.824087Z","shell.execute_reply.started":"2024-04-18T20:47:02.952405Z","shell.execute_reply":"2024-04-18T20:47:04.822810Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/__main__.py\", line 24, in <module>\n    sys.exit(_main())\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 79, in main\n    return command.main(cmd_args)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n    return self._main(args)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 114, in _main\n    options, args = self.parse_args(args)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 96, in parse_args\n    return self.parser.parse_args(args)\n  File \"/opt/conda/lib/python3.10/optparse.py\", line 1371, in parse_args\n    values = self.get_default_values()\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/parser.py\", line 279, in get_default_values\n    self.config.load()\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/configuration.py\", line 124, in load\n    self._load_config_files()\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/configuration.py\", line 262, in _load_config_files\n    parser = self._load_file(variant, fname)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/configuration.py\", line 269, in _load_file\n    parser = self._construct_parser(fname)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/configuration.py\", line 278, in _construct_parser\n    parser = configparser.RawConfigParser()\n  File \"/opt/conda/lib/python3.10/configparser.py\", line 612, in __init__\n    self._converters = ConverterMapping(self)\n  File \"/opt/conda/lib/python3.10/configparser.py\", line 1325, in __init__\n    for getter in dir(self._parser):\nKeyboardInterrupt\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport torch\nimport pandas as pd\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import RobertaTokenizer, RobertaModel, RobertaConfig\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm, trange","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:17.840558Z","iopub.execute_input":"2024-04-19T08:09:17.841375Z","iopub.status.idle":"2024-04-19T08:09:17.847049Z","shell.execute_reply.started":"2024-04-19T08:09:17.841340Z","shell.execute_reply":"2024-04-19T08:09:17.846096Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"train = json.load(open('/kaggle/input/data-json/train_file.json'))\ntest = json.load(open('/kaggle/input/data-json/val_file.json'))\n\nprint('train:', len(train))\nprint('test:', len(test))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:18.330986Z","iopub.execute_input":"2024-04-19T08:09:18.331713Z","iopub.status.idle":"2024-04-19T08:09:18.420481Z","shell.execute_reply.started":"2024-04-19T08:09:18.331676Z","shell.execute_reply":"2024-04-19T08:09:18.419440Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"train: 6740\ntest: 843\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## BERT ENCODINGS","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:19.094708Z","iopub.execute_input":"2024-04-19T08:09:19.095584Z","iopub.status.idle":"2024-04-19T08:09:19.099785Z","shell.execute_reply.started":"2024-04-19T08:09:19.095547Z","shell.execute_reply":"2024-04-19T08:09:19.098778Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"## DATALOADERS","metadata":{}},{"cell_type":"markdown","source":"# Convert json to csv","metadata":{}},{"cell_type":"code","source":"dialogue_ids = []\nspeaker = []\nemotion = []\nutterance = []\nerf_label = []\n\nfor i in range(len(train)):\n    dialogue_ids.append(train[i]['episode'])\n    speaker.append(train[i]['speakers'])\n    emotion.append(train[i]['emotions'])\n    utterance.append(train[i]['utterances'])\n    erf_label.append(train[i]['triggers'])\n    # for j in range(len(train[i]['speakers'])):\n    #     dialogue_ids.append(train[i]['episode'])\n    #     speaker.append(train[i]['speakers'][j])\n    #     emotion.append(train[i]['emotions'][j])\n    #     utterance.append(train[i]['utterances'][j])\n    #     erf_label.append(train[i]['triggers'][j])\ndf_train = pd.DataFrame(list(zip(dialogue_ids, speaker, emotion, utterance, erf_label)), columns =['Dialogue_ID', 'Speaker', 'Emotion', 'Utterance', 'ERF_Label'])\n# save this dataframe to a csv file\ndf_train.to_csv('train.csv', index=False)\ndialogue_ids = []\nspeaker = []\nemotion = []\nutterance = []\nerf_label = []\n\nfor i in range(len(test)):\n    dialogue_ids.append(train[i]['episode'])\n    speaker.append(train[i]['speakers'])\n    emotion.append(train[i]['emotions'])\n    utterance.append(train[i]['utterances'])\n    erf_label.append(train[i]['triggers'])\n    # for j in range(len(test[i]['speakers'])):\n    #     dialogue_ids.append(test[i]['episode'])\n    #     speaker.append(test[i]['speakers'][j])\n    #     emotion.append(test[i]['emotions'][j])\n    #     utterance.append(test[i]['utterances'][j])\n    #     erf_label.append(test[i]['triggers'][j])\ndf_test = pd.DataFrame(list(zip(dialogue_ids, speaker, emotion, utterance, erf_label)), columns =['Dialogue_ID', 'Speaker', 'Emotion', 'Utterance', 'ERF_Label'])\n# save this dataframe to a csv file\ndf_test.to_csv('test.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:20.334207Z","iopub.execute_input":"2024-04-19T08:09:20.334586Z","iopub.status.idle":"2024-04-19T08:09:20.652005Z","shell.execute_reply.started":"2024-04-19T08:09:20.334555Z","shell.execute_reply":"2024-04-19T08:09:20.651155Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:20.738081Z","iopub.execute_input":"2024-04-19T08:09:20.738408Z","iopub.status.idle":"2024-04-19T08:09:20.757472Z","shell.execute_reply.started":"2024-04-19T08:09:20.738379Z","shell.execute_reply":"2024-04-19T08:09:20.756600Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"      Dialogue_ID                                            Speaker  \\\n0  utterance_3492               [Phoebe, Eric, Phoebe, Eric, Phoebe]   \n1  utterance_3952  [Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...   \n2  utterance_3198  [Older Scientist, Ross, Ross, Joey, Ross, Ross...   \n3  utterance_2834                           [Monica, Monica, Monica]   \n4   utterance_453                         [Kate, The Director, Kate]   \n\n                                             Emotion  \\\n0       [surprise, fear, surprise, sadness, disgust]   \n1  [disgust, disgust, anger, sadness, surprise, a...   \n2  [neutral, neutral, neutral, neutral, neutral, ...   \n3                       [neutral, surprise, neutral]   \n4                            [joy, sadness, sadness]   \n\n                                           Utterance  \\\n0  [You-you\nyou had sex with Ursula?!, Uh, a litt...   \n1  [Dad, please don't pick your teeth out here!, ...   \n2  [Dr. Geller, there's a seat over here., Thank ...   \n3  [So, how'd the lasagne go over?, Really?!, Good.]   \n4  [Become a drama critic!, I am hurt!  A plague ...   \n\n                                           ERF_Label  \n0                          [1.0, 1.0, 0.0, 0.0, 0.0]  \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n2                [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]  \n3                                    [0.0, 0.0, 1.0]  \n4                                    [0.0, 0.0, 1.0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue_ID</th>\n      <th>Speaker</th>\n      <th>Emotion</th>\n      <th>Utterance</th>\n      <th>ERF_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>utterance_3492</td>\n      <td>[Phoebe, Eric, Phoebe, Eric, Phoebe]</td>\n      <td>[surprise, fear, surprise, sadness, disgust]</td>\n      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>utterance_3952</td>\n      <td>[Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...</td>\n      <td>[disgust, disgust, anger, sadness, surprise, a...</td>\n      <td>[Dad, please don't pick your teeth out here!, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>utterance_3198</td>\n      <td>[Older Scientist, Ross, Ross, Joey, Ross, Ross...</td>\n      <td>[neutral, neutral, neutral, neutral, neutral, ...</td>\n      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>utterance_2834</td>\n      <td>[Monica, Monica, Monica]</td>\n      <td>[neutral, surprise, neutral]</td>\n      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>utterance_453</td>\n      <td>[Kate, The Director, Kate]</td>\n      <td>[joy, sadness, sadness]</td>\n      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:21.208047Z","iopub.execute_input":"2024-04-19T08:09:21.208769Z","iopub.status.idle":"2024-04-19T08:09:21.227087Z","shell.execute_reply.started":"2024-04-19T08:09:21.208738Z","shell.execute_reply":"2024-04-19T08:09:21.225881Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"      Dialogue_ID                                            Speaker  \\\n0  utterance_3492               [Phoebe, Eric, Phoebe, Eric, Phoebe]   \n1  utterance_3952  [Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...   \n2  utterance_3198  [Older Scientist, Ross, Ross, Joey, Ross, Ross...   \n3  utterance_2834                           [Monica, Monica, Monica]   \n4   utterance_453                         [Kate, The Director, Kate]   \n\n                                             Emotion  \\\n0       [surprise, fear, surprise, sadness, disgust]   \n1  [disgust, disgust, anger, sadness, surprise, a...   \n2  [neutral, neutral, neutral, neutral, neutral, ...   \n3                       [neutral, surprise, neutral]   \n4                            [joy, sadness, sadness]   \n\n                                           Utterance  \\\n0  [You-you\nyou had sex with Ursula?!, Uh, a litt...   \n1  [Dad, please don't pick your teeth out here!, ...   \n2  [Dr. Geller, there's a seat over here., Thank ...   \n3  [So, how'd the lasagne go over?, Really?!, Good.]   \n4  [Become a drama critic!, I am hurt!  A plague ...   \n\n                                           ERF_Label  \n0                          [1.0, 1.0, 0.0, 0.0, 0.0]  \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n2                [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]  \n3                                    [0.0, 0.0, 1.0]  \n4                                    [0.0, 0.0, 1.0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue_ID</th>\n      <th>Speaker</th>\n      <th>Emotion</th>\n      <th>Utterance</th>\n      <th>ERF_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>utterance_3492</td>\n      <td>[Phoebe, Eric, Phoebe, Eric, Phoebe]</td>\n      <td>[surprise, fear, surprise, sadness, disgust]</td>\n      <td>[You-youyou had sex with Ursula?!, Uh, a litt...</td>\n      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>utterance_3952</td>\n      <td>[Monica, Monica, Phoebe, Joey, Joey, Joey, Rac...</td>\n      <td>[disgust, disgust, anger, sadness, surprise, a...</td>\n      <td>[Dad, please don't pick your teeth out here!, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>utterance_3198</td>\n      <td>[Older Scientist, Ross, Ross, Joey, Ross, Ross...</td>\n      <td>[neutral, neutral, neutral, neutral, neutral, ...</td>\n      <td>[Dr. Geller, there's a seat over here., Thank ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>utterance_2834</td>\n      <td>[Monica, Monica, Monica]</td>\n      <td>[neutral, surprise, neutral]</td>\n      <td>[So, how'd the lasagne go over?, Really?!, Good.]</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>utterance_453</td>\n      <td>[Kate, The Director, Kate]</td>\n      <td>[joy, sadness, sadness]</td>\n      <td>[Become a drama critic!, I am hurt!  A plague ...</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unicode_mapping = {}\nunicode_mapping['\\x85'] = '...' \nunicode_mapping['\\x91'] = \"'\"\nunicode_mapping['\\x92'] = \"'\"\nunicode_mapping['\\x93'] = '\"'\nunicode_mapping['\\x94'] = '\"'\nunicode_mapping['\\x97'] = '--'\n\nunicode_mapping['\\u2014'] = '--'\nunicode_mapping['\\u2019'] = \"'\"\nunicode_mapping['\\u2026'] = '...'\n\nunicode_mapping['\\xe9'] = 'e'\n\ndef clean_utterance(utterance_list):\n    '''\t\n    This function takes a list of utterances and replaces the unicode with the proper characters.\n    '''\n    cleaned_utterances_list = []\n    for utterance in utterance_list:\n        for key in unicode_mapping:\n            utterance = utterance.replace(key, unicode_mapping[key])\n        cleaned_utterances_list.append(utterance)\n    return cleaned_utterances_list\n\ntrain_uttr = df_train['Utterance'].apply(lambda x: clean_utterance(x))\ndf_train['Utterance'] = train_uttr\ntest_uttr = df_test['Utterance'].apply(lambda x: clean_utterance(x))\ndf_test['Utterance'] = test_uttr\nfor i in range(len(df_train)):\n    for j in range(len(df_train['ERF_Label'][i])):\n        if df_train['ERF_Label'][i][j] != 1.0 and df_train['ERF_Label'][i][j] != 0.0:\n            df_train['ERF_Label'][i][j] = -1.0\n    \n    # for j in range(len(df_test['ERF_Label'][i])):\n    #     if df_test['ERF_Label'][i][j] == 'None':\n    #         df_test['ERF_Label'][i][j] = -1\n\nfor i in range(len(df_test)):\n    for j in range(len(df_test['ERF_Label'][i])):\n        if df_test['ERF_Label'][i][j] != 1.0 and df_test['ERF_Label'][i][j] != 0.0:\n            df_test['ERF_Label'][i][j] = -1.0","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:21.502631Z","iopub.execute_input":"2024-04-19T08:09:21.503272Z","iopub.status.idle":"2024-04-19T08:09:22.911843Z","shell.execute_reply.started":"2024-04-19T08:09:21.503239Z","shell.execute_reply":"2024-04-19T08:09:22.910821Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print(df_train['Utterance'][0])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:22.913781Z","iopub.execute_input":"2024-04-19T08:09:22.914060Z","iopub.status.idle":"2024-04-19T08:09:22.919303Z","shell.execute_reply.started":"2024-04-19T08:09:22.914038Z","shell.execute_reply":"2024-04-19T08:09:22.918404Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"['You-you...you had sex with Ursula?!', 'Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and', \"You didn't notice she was wearing different clothes?!\", 'Well I was just so excited to see you.', \"Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"# max length episode\nmax_len = 0\nfor i in range(len(df_train)):\n    max_len = max(max_len, len(df_train['Utterance'][i]))\nprint(max_len)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:22.920489Z","iopub.execute_input":"2024-04-19T08:09:22.920849Z","iopub.status.idle":"2024-04-19T08:09:22.998936Z","shell.execute_reply.started":"2024-04-19T08:09:22.920818Z","shell.execute_reply":"2024-04-19T08:09:22.998064Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"24\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\nfrom transformers import AutoTokenizer, AutoModel\nimport torch.nn as nn\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:23.000554Z","iopub.execute_input":"2024-04-19T08:09:23.000860Z","iopub.status.idle":"2024-04-19T08:09:23.217263Z","shell.execute_reply.started":"2024-04-19T08:09:23.000837Z","shell.execute_reply":"2024-04-19T08:09:23.216438Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    #model consists of a EmoBERTa model and a linear layer for sequence labeling task\n    def __init__(self, num_classes=2):\n        super(Model, self).__init__()\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        self.fc = nn.Linear(768, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids, attention_mask)\n        out = outputs[0]\n        out = out[:, 0, :]\n        out = self.fc(out)\n        # make sure output is either 0 or 1\n        out = torch.sigmoid(out)\n        out = torch.round(out)\n        return out\nclass Dataset(Dataset):\n    def __init__(self, data, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = self.process(data, tokenizer)\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data['input'])\n\n    def __getitem__(self, index):\n        #tokenize the input\n        input = self.data['input'][index]\n        target = self.data['target'][index]\n#         if target == 'None':\n#             target = -1\n#         print(target)\n        encoding = self.tokenizer(input, return_tensors='pt', padding='max_length', max_length=self.max_len, truncation=True)\n        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'target':torch.tensor(target)}\n        \n    def process(self, data, tokenizer):\n        new_data = {'input': [], 'target': []}\n        for i in range(len(data)):\n            newinput = data.loc[i].copy()\n            stringlist = []\n            for j in range(len(newinput['Utterance'])):\n                stringlist.append(newinput['Speaker'][j] + ': ' + newinput['Utterance'][j] + \":\" + newinput['Emotion'][j])\n            for j in range(len(newinput['Utterance'])):\n                #join till jth utterance\n                temp = ' '.join(stringlist[:j])\n                temp += '</s></s>'\n                #add jth utterance\n                temp += newinput['Speaker'][j] + ': ' + newinput['Utterance'][j] + \":\" + newinput['Emotion'][j]\n                temp += '</s></s>'\n                #add later Utterence\n                temp += ' '.join(stringlist[j+1:])\n                temp = '<s> ' + temp + '</s>'\n                new_data['input'].append(temp)\n                target = newinput['ERF_Label'][j]\n                # print(target)\n                new_data['target'].append(target)\n        return new_data\n            \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:23.218724Z","iopub.execute_input":"2024-04-19T08:09:23.219013Z","iopub.status.idle":"2024-04-19T08:09:23.235388Z","shell.execute_reply.started":"2024-04-19T08:09:23.218986Z","shell.execute_reply":"2024-04-19T08:09:23.234453Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = []\n    attention_mask = []\n    target = []\n    for b in batch:\n        input_ids.append(b['input_ids'])\n        attention_mask.append(b['attention_mask'])\n        target.append(b['target'])\n    input_ids = torch.stack(input_ids)\n    attention_mask = torch.stack(attention_mask)\n    target = torch.stack(target)\n    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target': target}","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:23.608008Z","iopub.execute_input":"2024-04-19T08:09:23.608811Z","iopub.status.idle":"2024-04-19T08:09:23.614832Z","shell.execute_reply.started":"2024-04-19T08:09:23.608775Z","shell.execute_reply":"2024-04-19T08:09:23.613787Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# take 10 samples only\n# df_train = df_train[:100]\n# df_test = df_test[:100]\n\ntrain_Dataset = Dataset(df_train, tokenizer, 2)\ntrain_loader = DataLoader(train_Dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n\ntest_Dataset = Dataset(df_test, tokenizer, 2)\ntest_loader = DataLoader(test_Dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n\nmodel = Model(1)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nprint(len(train_loader), len(test_loader))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:24.036095Z","iopub.execute_input":"2024-04-19T08:09:24.036467Z","iopub.status.idle":"2024-04-19T08:09:27.493356Z","shell.execute_reply.started":"2024-04-19T08:09:24.036436Z","shell.execute_reply":"2024-04-19T08:09:27.492346Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1843 229\n","output_type":"stream"}]},{"cell_type":"code","source":"print(device)\ndef train(model,train_loader,test_loader,criterion,optimizer,num_class,epochs):\n    train_losses = []\n    test_losses = []\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader):\n            \n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            target = batch['target'].to(device)\n            # print(input_ids)\n#             print(input_ids.shape, attention_mask.shape, target.shape)\n            optimizer.zero_grad()\n            output = model(input_ids, attention_mask)\n#             print(output[0], target)\n            #make output\n            # output = output.unsqueeze(0) \n#             print(output.shape, target.shape)\n#             loss = criterion(output, target)\n            loss = criterion(output.view(-1), target)\n#             print(loss.item())\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        # break\n        train_loss /= len(train_loader)\n        train_losses.append(train_loss)\n        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}')\n        model.eval() \n        test_loss = 0\n        with torch.no_grad():\n            for batch in tqdm(test_loader):\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                target = batch['target'].to(device)\n                # print(input_ids)\n                # print(input_ids.shape, attention_mask.shape, target.shape)\n                optimizer.zero_grad()\n                output = model(input_ids, attention_mask)\n                # print(output, target)\n                #make output\n                # output = output.unsqueeze(0) \n                # print(output.shape, target.shape)\n                # break \n#                 loss = criterion(output, target)\n                loss = criterion(output.view(-1), target)\n                f1_micro = f1_score(target.cpu().numpy(), output.cpu().numpy(), average='micro')\n                f1_macro = f1_score(target.cpu().numpy(), output.cpu().numpy(), average='macro')\n                f1_weighted = f1_score(target.cpu().numpy(), output.cpu().numpy(), average='weighted')\n                test_loss += loss.item()\n            test_loss /= len(test_loader)\n            test_losses.append(test_loss)\n            print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss},F1 micro:{f1_micro}, F1 macro:{f1_macro},F1 weighted:{f1_weighted}')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:27.495580Z","iopub.execute_input":"2024-04-19T08:09:27.495868Z","iopub.status.idle":"2024-04-19T08:09:27.510851Z","shell.execute_reply.started":"2024-04-19T08:09:27.495843Z","shell.execute_reply":"2024-04-19T08:09:27.509913Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train(model,train_loader,test_loader,criterion,optimizer,18,5)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:09:27.511934Z","iopub.execute_input":"2024-04-19T08:09:27.512205Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 1843/1843 [02:12<00:00, 13.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Train Loss: 17.543844316164826\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 229/229 [00:09<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5, Test Loss: 17.945683185710656,F1 micro:0.7857142857142857, F1 macro:0.44,F1 weighted:0.6914285714285714\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1843/1843 [02:11<00:00, 14.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Train Loss: 17.545411249896592\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 229/229 [00:08<00:00, 26.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5, Test Loss: 17.94568329398809,F1 micro:0.7857142857142857, F1 macro:0.44,F1 weighted:0.6914285714285714\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1843/1843 [02:10<00:00, 14.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Train Loss: 17.548074731086817\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 229/229 [00:08<00:00, 25.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5, Test Loss: 17.945683275247767,F1 micro:0.7857142857142857, F1 macro:0.44,F1 weighted:0.6914285714285714\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 902/1843 [01:04<01:07, 14.01it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}